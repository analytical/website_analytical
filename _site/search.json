[
  {
    "objectID": "test2.html",
    "href": "test2.html",
    "title": "test2",
    "section": "",
    "text": "mean(rnorm(100))\n\n[1] -0.1350651"
  },
  {
    "objectID": "test2.html#cómo-estás",
    "href": "test2.html#cómo-estás",
    "title": "test2",
    "section": "",
    "text": "mean(rnorm(100))\n\n[1] -0.1350651"
  },
  {
    "objectID": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/index.html",
    "href": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/index.html",
    "title": "Validación de los cálculos de incertidumbre en química analítica con el método Monte Carlo. Parte II",
    "section": "",
    "text": "En el post anterior describimos brevemente en qué consiste el método de Monte Carlo y cómo utilizarlo para estimar la incertidumbre de medición. Finalizamos comparando la estimación de acuerdo a la guía GUM con el método de Monte Carlo siguiendo estrictamente las directrices del test de diferencias numéricas propuesto por el Suplmento 1 de la GUM.\nLlevamos a cabo el test de validación “a mano”, es decir, ingresamos todas las instrucciones en código R. Si bien no fue difícil, existen librerías especializadas en R que permiten realizar todos los cálculos de incertidumbre y validarlos utilizando funciones ya incorporadas.\nEn Rexisten dos librerías especializadas en cálculo de incertidumbre de métodos de medición físico-químicos:\nMe inclinaré por metRology principalmente porque tiene el soporte de los dos centros de metrología más imporantes a nivel mundial y, ya que fue desarrollada en sus inicios por Steve Ellison, tiene un pequeño sesgo hacia la metrología química."
  },
  {
    "objectID": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/index.html#ejemplo-de-validación-de-cálculos-con-librería-metrology",
    "href": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/index.html#ejemplo-de-validación-de-cálculos-con-librería-metrology",
    "title": "Validación de los cálculos de incertidumbre en química analítica con el método Monte Carlo. Parte II",
    "section": "Ejemplo de validación de cálculos con librería metRology",
    "text": "Ejemplo de validación de cálculos con librería metRology\nDesarrollaremos un ejemplo más extenso sobre cálculo de incertidumbre en química analítica utilizando esta librería. Iremos paso a paso, cualquier duda en la implementación nada más escríbala en los comentarios más abajo. Sin embargo, no detallaremos cómo obtener las incertidumbres de cada uno de los factores involucrados en la ecuación de medición, sino que simplemente será un dato conocido para este ejemplo. En un futuro post, desarollaremos un ejemplo completo de principio a fin, por ahora nos centraremos en utilizar metRologycomo herramienta práctica.\nEn este ejemplo, calcularemos la incertidumbre de un método de determinación de cobre en mineral de cobre, con digestión ácida y cuantificación mediante espetroscopía de abosrción atómica AAS. Los detalles del método analítico están fuera del alcance de este post, pero pueden ser consultados en la norma chilena NCh 3392:2016.\n\nSeguiremos estrictamente las directrices de la GUM, por lo tanto, queda fuera de esta evaluación cualquier corrección de sesgo y/o recuperación. La discusión sobre si se debiera, o no, incorporar el sesgo en la incertidumbre es un tema que abordaremos en otro post.\n\n\nEl primer paso para estimar la incertidumbre de este método es escribir la ecuación de medición:\n\n\\[\\begin{equation}\n  \\text{Cu}[\\text{%}]=\\frac{\\text{C}_{\\text{calib}}\\cdot V \\cdot D}{m\\cdot 10000}\n  (\\#eq:medicion)\n\\end{equation}\\]\ndonde \\(\\text{C}_{\\text{calib}}\\) es la concentración de la muestra digerida interpolada en la curva de calibración \\([\\mu\\text{g}\\,\\text{mL}^{-1}]\\), \\(m\\) es la masa de la muestra [g], \\(V\\,[\\text{mL}]\\) es el volumen del aforo final y \\(D\\) es un factor de dilución volumétrico, utilizado cuando es necesario. Para simplificar el problema, asumiremos que no hay dilución antes de la lectura por AAS, por lo tanto, \\(D = 1\\) y \\(u_{D} = 0\\).\n\nIdentificación de las fuentes de incertidumbre\n\nA continuación se enumeran las fuentes de incertidumbre asociadas a cada uno de los factores de la ecuación @ref(eq:medicion) y se describe brevemente los métodos estadísticos y de juicio experto utilizados para obtener las incertidumbres estándar correpospondientes:\n\n\\(\\text{C}_{\\text{calib}}\\): La incertidumbre estándar de la concentración de una muestra problema \\(u_{\\text{C}_\\text{calib}}\\) obtenida de una curva de calibración lineal \\(y = a + bx\\) es calculada a partir de la siguiente expresión:\n\n\\[\\begin{equation}\nu_{\\text{C}_{\\text{calib}}}=\\frac{s_{y/x}}{b}\\sqrt{\\frac{1}{m}+\\frac{1}{n}+\n\\frac{(C_{\\text{calib}}-\\overline{C})^2}{\\sum(C_{i}-\\overline{C})^2}}\n\\label{eq:ucurva}\n\\end{equation}\\]\ndonde \\(s_{y/x}\\) es la desviación estándar de la regresión, \\(m\\) es el número de replicados independientes de la muestra problema efectivamente analizados, \\(n\\) es el número de calibrantes, \\(C_{\\text{calib}}\\) es la concentración de la muestra problema obtenida por interpolación en la curva de calibración, \\(\\overline{C}\\) es el promedio de la concentraciones de los calibrantes. Estos parámetros pueden ser obtenidos directamente del análisis estadístico de la curva de calibración lineal. Cabe destacar que cuando se utiliza el método de mínimos cuadrados ordinarios para estimar la pendiente e intercepto de la curva, esta metodología no incorpora la incertirtumbre de la concentración de los calibrantes.\n{{% callout warning %}} Puede profundizar sobre la incertidumbre de calibración en el siguiente post{{% /callout %}}\n\n\\(V\\): La incertidumbre del volumen de aforo \\(u_{\\text{V}}\\) es estimada a partir de la combinación de tres fuentes:\n\n\\(u_{\\text{tol}}\\) La incertidumbre informada por el fabricante en el certificado original del lote de producción o aquella impresa en el material de vidrio. Esta incertidumbre es de Tipo B.\n\\(u_{\\text{rep}}\\) Incertidumbre debido a la repetibilidad de llenado del aforo del material de vidrio. Esta incertidumbre (Tipo A) es evaluada mediante métodos estadísticos a través de la replicación (\\(n\\)) del llenado del material con agua destilada y el registro gravimétrico de la cantidad de agua. La incertidumbre estándar se expresa como la desviación estándar de los \\(n\\) replicados.\n\\(u_{\\text{temp}}\\) La incertidumbre debido a la diferencia de temperatura registrada durante la calibración del material de vidrio y aquella que se registra durante los análisis de rutina. Esta incertidumbre expandida es expresada en la ecuación @ref(eq:uvol):\n\n\n\\[\\begin{equation}\n  U_{\\text{temp}}= V\\cdot \\gamma_{\\text{H}_{2}\\text{O}} \\cdot \\Delta T\n  (\\#eq:uvol)\n\\end{equation}\\]\ndonde \\(V\\) es el volumen certificado del material de vidrio, \\(\\gamma_{\\text{H}_{2}\\text{O}} = 2.1\\cdot 10^{-4}\\,\\text{°C}^{-1}\\) es el coeficiente de expansión del agua y \\(\\Delta T\\) es la variabilidad de la temperatura de trabajo del laboratorio en relación a la tempreratura de calibración del material. Finalmente, se obtiene asume una distribución rectangular de la variable obteniéndose una incertidumbre estándar \\(u_{\\text{temp}}=U_{\\text{temp}}/\\sqrt{3}\\) mL.\nEsta expresión debe utilizarse cuando exista un certificado de calibración que informe la temperatura de referencia registrada durante el proceso de certificación el cual puede provenir del mismo fabricante o de alguna institución metrológica nacional que certifique este tipo material. Generalmente la temperatura de calibración se espcifica a 20°C.\nLa incertidumbre combinada estándar del volumen del aforo se obtiene a través de la siguiente expresión:\n\\[\\begin{equation}\nu_{\\text{V}} = \\sqrt{u_{\\text{tol}}^2+u_{\\text{rep}}^2+u_{\\text{temp}}^2}\n\\end{equation}\\]\n\n\\(m\\) : La incertidudmbre de la masa de la muestra es obtenida directamente del certificado de la balanza emitido por el nodo de metrología física nacional u otro proveedor de calibración.\n\n\nCuantificación de los componentes de incertidumbre\n\nComo mencionamos anteriormente, no llevaremos a cabo la estimación de incertidumbre de cada uno de lo componentes, sino que asumiremos que estos datos ya están disponibles. Dedicaremos otro post a desarrollar un ejemplo completo de principio a fin.\n\nCálculo de la incertidumbre combinada total\n\nAplicando las directrices de la GUM y en base a la ecuación de medición @ref(eq:medicion), la incertidumbre estándar de la concentración de Cu por este método analítico es obtenida a partir de:\n\\[\\begin{equation}\nu_{\\text{Cu}} = \\text{Cu}\\sqrt{\\left(\\frac{u_{\\text{C}_\\text{calib}}}{\\text{C}_{\\text{calib}}}\\right)^2+\n\\left(\\frac{u_{\\text{m}}}{m}\\right)^2+\n\\left(\\frac{u_{\\text{V}}}{V}\\right)^2}\n(\\#eq:ufinal)\n\\end{equation}\\]\nLa tabla @ref(tab:udata) muestra las incertidumbres estándares de cada uno de los componentes de la ecuación @ref(eq:ufinal):\n\n\n\nValores e incertidumbres estándar de cada componente\n\n\nComponente\nValor\nu\nUnidades\n\n\n\n\nConcentracion calibracion\n13.82\n0.24\nug/mL\n\n\nVolumen aforo\n250.00\n0.14\nmL\n\n\nMasa muestra\n0.99160\n0.00005\ng\n\n\n\n\n\n\n\nOk, vamos entonces a utilizar la librería metRology para evaluar la incertidumbre del % de Cu.\n{{% callout warning %}} Debe, en primer lugar, instalar la librería mediante el comando install.packages('metRology'){{% /callout %}}\nUna vez instalada debe ingresar el siguiente código R:\n\nlibrary(metRology)  # Carga la librería metRology\n\n# Ingresar los valores de cada variable input (Tabla 1)\n\nCu.calib &lt;- 13.82 # Concentración interpolada en la curva de calibración [ug/mL]\nV &lt;- 250          # Volumen de aforo [mL]\nm &lt;- 0.9916       # Masa de la muestra [g]\nD &lt;- 1            # Factor de dilución (D = 1 implica no hay dilución)\n\n# Ingresar las incertidumbres estándar de cada variable input (Tabla 1)\n# Se mantienen, obviamente, las mismas unidades\n\nu.Cu.calib &lt;- 0.24\nu.V &lt;- 0.14\nu.m &lt;- 0.00005\nu.D &lt;- 0\n\n# Ingresamos la ecuación de medición y la guardamos con el nombre C.Cu\n# mediante el comando 'expression'\n\nC.Cu &lt;- expression(Cu.calib*V*D/(m*10000))\n\n# Guardemos en una lista los valores de cada variable input, la llamaremos\n# x.Cu\n\nx.Cu &lt;- list(Cu.calib = Cu.calib, V = V , D = D, m = m)\n\n# Guardemos en un vector las incertidumbres estándares de cada variable input\n# ¡¡en el mismo orden que fueron ingresadas en x.Cu!!\n# Llamaremos a este vector u.x.Cu\n\nu.x.Cu &lt;- c(u.Cu.calib, u.V, u.D, u.m)\n\n¡Estamos listos! Ahora metRologyhará todo el trabajo con el comando uncert, Ud. debe elegir cuál método de estimación desea utilizar, las opciones son:\n\nGUM\nMonte Carlo\nKragten: Método numérico basado en una aproximación de las derivadas parciales propuestas por GUM. Es una excelente alternativa y muy sencilla de implementar en Excel también.\nNUM y k2 son otras aproximaciones numéricas de derivadas parciales.\n\n\nCálculo de incertidumbre de acuerdo a GUM:\n\n\n# Ingresamos ¡en este orden! los siguientes parámetros del comando uncert\n# Ecuación de medición C.Cu\n# Lista de valores inputs x.Cu\n# Vector de incertidumbres estándar u.x.Cu\n# ¿Con cuál método quiere calcular la incertidumbre? En este caso GUM\n\nu.Cu.GUM &lt;- uncert(C.Cu, x.Cu, u.x.Cu, method = 'GUM')\n\nLa información que entrega uncertes muy completa, sin embargo, para nuestro propósito sólo debemos fijarnos en el resultado que aparece al final del análisis, es decir: \\(y = 0.3484268\\) % Cu y \\(u(y) = 0.006054\\) % Cu.\n\n\n\nUncertainty evaluation\n\nCall:\n  uncert.expression(obj = C.Cu, x = x.Cu, u = u.x.Cu, method = \"GUM\")\n\nExpression: Cu.calib * V * D/(m * 10000)\n\nEvaluation method:  GUM \n\nUncertainty budget:\n         x        u       c            u.c          \nCu.calib  13.8200 0.24000  0.025211779  6.050827e-03\nV        250.0000 0.14000  0.001393707  1.951190e-04\nD          1.0000 0.00000  0.348426785  0.000000e+00\nm          0.9916 0.00005 -0.351378363 -1.756892e-05\n\n   y:  0.3484268\nu(y):  0.006053998 \n\n\nAdemás de los cálculos de incertidumbre, la opción method = 'GUM' entrega 4 gráficos muy interesantes, siendo el más importante el de Contribuciones combinadas, el cual se muestra en la figura @ref(fig:plotGUM). En este gráfico queda en evidencia que el factor que más aporta a la incertidumbre total (evaluada por GUM) es la curva de calibración.\n\n\n\n\n\nGráfico de contribución a la incertidumbre total\n\n\n\n\n\nCálculo de incertidumbre de acuerdo a Monte Carlo:\n\nEsencialmente es el mismo comando que utilizamos para GUM, sólo que seleccionaremos method = 'MC'. Sin embargo, este método tiene varias opciones adicionales muy interesantes:\n\nCon la opción distrib Ud. puede asignar a cada variable su respectiva distribución de probabilidad: Normal, uniforme, triangular o Student. Por defecto, asume que todas son normales.\nCon la opción B indica el número de simulaciones. Por defecto B = 200. Le sugiero cambiar a B = 10000.\n\n\n# Guardaremos los cálculos en el objeto u.Cu.MC\n\nset.seed(123) # Sólo para que Ud. obtenga los mismos resultados\n\nu.Cu.MC &lt;- uncert(C.Cu, x.Cu, u.x.Cu, method = 'MC', B = 10000)\n\nEl método de Monte Carlo entrega el siguiente análisis:\n\n\n\nUncertainty evaluation\n\nCall:\n  uncert.expression(obj = C.Cu, x = x.Cu, u = u.x.Cu, method = \"MC\",     B = 10000)\n\nExpression: Cu.calib * V * D/(m * 10000)\n\nEvaluation method:  MC \n\nBudget:\n         x        u       c            u.c           distrib\nCu.calib  13.8200 0.24000  0.025211842  6.050842e-03 norm   \nV        250.0000 0.14000  0.001393355  1.950696e-04 norm   \nD          1.0000 0.00000           NA            NA norm   \nm          0.9916 0.00005 -0.351680471 -1.758402e-05 norm   \n         distrib.pars         \nCu.calib mean=13.82, sd=0.24  \nV        mean=250, sd=0.14    \nD        mean=1, sd=0         \nm        mean=0.9916, sd=5e-05\n\n   y:  0.3484268\nu(y):  0.006046603 \n\nMonte Carlo evaluation using 10000 replicates:\n\n   y:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.3252  0.3444  0.3484  0.3484  0.3525  0.3720 \n\n\nEl MMC obtiene \\(y = 0.3484268\\) % Cu y \\(u(y) = 0.0060466\\) % Cu.\nLa tabla @ref(tab:comparacion) muestra la comparación de ambas aproximaciones en la estimación de la incertidumbre estándar:\n\n\n\nCuadro comparativo GUM v/s Monte Carlo % Cu\n\n\nMétodo\nValor calculado\nu\n\n\n\n\nGUM\n0.3484268\n0.0060540\n\n\nMonte Carlo\n0.3484268\n0.0060466\n\n\n\n\n\n\n\nNote la excelente concordancia entre ambas metodologías para esta ecuación de medición asumiendo una distribución normal para todas las variables inputs. En este caso, muy particular, casi sería innecesario validar el método GUM, pero lo haremos de todas maneras para ejemplificar la operación."
  },
  {
    "objectID": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/index.html#validación-de-los-cálculos-gum-con-el-método-de-monte-carlo",
    "href": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/index.html#validación-de-los-cálculos-gum-con-el-método-de-monte-carlo",
    "title": "Validación de los cálculos de incertidumbre en química analítica con el método Monte Carlo. Parte II",
    "section": "Validación de los cálculos GUM con el método de Monte Carlo",
    "text": "Validación de los cálculos GUM con el método de Monte Carlo\nEn el post anterior hicimos el test de validación numérica “a mano”, en esta oportunidad utilizaremos el comando GUM.validate. Lamentablemente este comando tiene una forma distinta de ingresar los parámetros, nada del otro mundo, pero es distinta a uncert:\n\n# Si bien GUM.validate tiene muchas opciones, utilizaremos aquellas\n# que están por defecto en la librería\n\n# Guarde en un vector el nombre de las variables, cada una entre ' '\nvariables &lt;- c('Cu.calib', 'V', 'D', 'm')\n\n# Guarde en un vector x.i los valores de la variables input en el \n# mismo orden que ingresó 'variables' arriba\nx.i &lt;- c(13.82, 250, 1, 0.9916)\n\n# Guarde en un vector u.i las incertidumbres estándar de las variables\n# input, en el mismo orden que ingresó 'variables' arriba\nu.i &lt;- c(0.24, 0.14, 0, 0.00005)\n\n# Guarde los grados de libertad de cada variable input como nu.i. \n# En este ejemplo  asumiremos que todas tienen infinitos grados de \n# libertad (nu = 9999)\n\nnu.i &lt;- c(9999, 9999, 9999, 9999)\n\n# Seleccione que tipo de método utilizó para evaluar cada una de las\n# incertidumbres: Tipo A o tipo B. En este caso sólo la incertidumbre\n# de calibración u.Cu.calib es de tipo A.\n\ntype &lt;- c('A', 'B', 'B', 'B')\n\n# Seleccione que distribuciones de probabilidad asignó a las variables\n# input. En este ejemplo, asumiremos que todas son normales\n\ndistribution &lt;- rep('Normal', 4) # Repetir Normal 4 veces (soy muy flojo)\n\n# Guarde la ecuación de medición entre ''\nec_de_medicion &lt;- 'Cu.calib*V*D/(m*10000)'\n\nListo, ahora validemos los cálculos GUM con el comando GUM.validate:\n\nset.seed(126) # Tu ya sabes\nGUM.validate(var.name = variables, \n             x.i = x.i,\n             u.i = u.i,\n             nu.i = nu.i,\n             type = type,\n             distribution = distribution,\n             measurement.fnc = ec_de_medicion)\n\n[1] 0.958\n\n\n“Bueno ¿Y?” se preguntará Ud.\nBien, para validar el método GUM frente a Monte Carlo, fíjese en el valor que entrega GUM.validate = 0.958 y compárelo con 0.95. Si el valor de GUM.validate \\(&gt; 0.95\\) entonces el método GUM queda validado.\nEn el fondo, GUM.validate evalúa si el intervalo de incertidumbre calculado por GUM alcanza o no la cobertura esperada del 95% (teórica)."
  },
  {
    "objectID": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/index.html#resumiendo",
    "href": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/index.html#resumiendo",
    "title": "Validación de los cálculos de incertidumbre en química analítica con el método Monte Carlo. Parte II",
    "section": "Resumiendo",
    "text": "Resumiendo\n\nEl método de Monte Carlo funciona en casos donde las suposiciones del método GUM no se cumplen, especialmente en ecuaciones de medición no lineales.\nMientras más divergencia de la linealidad tenga el modelo de medición, más discrepancias habrá entre ambos métodos.\nEs posible que cuando incorpore distribuciones rectangulares (uniformes), el histograma de los valores de Monte Carlo esté dominado por este tipo de distribuciones. Verá un achatamiento del histograma.\nYa hablamos que la pureza química (al menos para compuestos muy puros \\(&gt; 95\\%\\)) no es correcto modelarla mediante una distribución Normal (¿\\(99.7 \\pm 0.5\\) %?), sino con una Beta. Lamentablmente, la librería metRologyno posee esta distribución en sus opciones y tendrá que hacer la simulación “a mano”.\nEn general para distribuciones de Monte Carlos muy asimétricas (como la pureza química modelada con Beta), la diferencia entre MC y GUM se verá reflejada en la incertidumbre expandida y no en la estándar.\nQuedan muchas cosas por analizar del método de Monte Carlo, sin embargo, el espíritu de este post es divulgar a la comunidad químico-analítica esta poderosa herramienta más que entrar en los detalles teóricos.\nUsamos el lenguaje Rporque es actualmente el idioma oficial de la estadística. Sin embargo, Ud. puede implementar estos cálculos en cualquier lenguaje e incluso en Excel. Además, existen muchos otros softwares que, aunque no tan flexibles y potentes como R, harán el trabajo. Revise la siguiente lista en Wikipedia.\n\nEspero que este post haya sido de su agrado, todos los comentarios son bienvenidos. Hasta la próxima."
  },
  {
    "objectID": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/index.html#bibliografía",
    "href": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/index.html#bibliografía",
    "title": "Validación de los cálculos de incertidumbre en química analítica con el método Monte Carlo. Parte II",
    "section": "Bibliografía",
    "text": "Bibliografía\n\nEvaluation of measurement data – Guide to the expression of uncertainty in measurement JCGM 100:2008\nEvaluation of measurement data – Supplement 1 to the “Guide to the expression of uncertainty in measurement” – Propagation of distributions using a Monte Carlo method JCGM 101:2008\nStephen L R Ellison metRology: Support for Metrological Applications R package version 0.9-23-2, 2016."
  },
  {
    "objectID": "post/prueba-de-linealidad-de-una-curva-de-calibracion-en-excel/index.html",
    "href": "post/prueba-de-linealidad-de-una-curva-de-calibracion-en-excel/index.html",
    "title": "Prueba de linealidad de una curva de calibración en Excel… Sí ¡En Excel!",
    "section": "",
    "text": "En un post anterior vimos cómo evaluar la hipótesis de linealidad de una curva de calibración. Propusimos dos tests estadísticos formales:\n\nEl test de Mandel (ISO 8466-1)\nEl test de carencia de ajuste (lack-of-fit) (ISO 11095)\n\nlos cuáles nos permiten concluir (o no) que el modelo lineal es adecuado o razonable para nuestros datos de calibración. Nada más, ni nada menos. No cometa el error de afirmar que su calibración es lineal, porque no existe método en el mundo que permita llegar a esa conclusión.\nImplementamos estos tests en lenguaje de programación R que es, actualmente, la lingua franca de la estadística, big data, data science y toda esa pirotecnia. Sin embargo, también es posible implementar fácilmente estos tests en el viejo y querido, pero a veces vapuleado por la comunidad Estadística, Excel. Obviamente, no existe el comando test.de.linealidad, por lo tanto, tendremos que “hacerlo a mano”.\nEn este post implementaremos el Test de Mandel, cuyos detalles puede consultar aquí. El test de carencia de ajuste lo veremos en otro post.\n\nTest de Mandel en Excel\n\nEn primer lugar necesitaremos, obviamente, los datos de calibración. Estos se muestran en Excel en la siguiente figura:\n\n La gráfica de esta calibración se presenta a continuación. Note la evidente no linealidad a alta concentración.\n\n\nBien, como Ud.recordará del post sobre linealidad, para aplicar el test de Mandel debemos ajustar dos modelos: un modelo lineal y otro no lineal. Mencionamos que para darle sentido químico-analítico ajustamos un modelo “no lineal” cuadrático. Yo sé que la tentación es grande para aplicar el botón derecho y Ajustar línea de tendencia, pero mantengamos la calma. Lo haremos de otra forma.\nPara ajustar un modelo cuadrático en Excel hay varias formas, pero en este post utilizaremos las herramientas del menú Análisis de datos:\n\n\n\nComo ajustaremos un modelo cuadrático, necesitamos incorporar la variable \\(X^2\\). Esto es muy sencillo, debemos ubicarnos en la columna B (donde está la \\(Y\\)), presionar botón derecho y seleccionar Insertar, lo cual generará una columna vacía entre \\(X\\) e \\(Y\\) tal como se muestra en la siguiente figura:\n\n A esta nueva columna la llamaremos X^2, y generaremos los valores correspondientes en la celda B2con la fórmula =A2^2:\n\nCopiamos la fórmula hasta la celda B12:\n\n\nAhora ajustaremos el modelo cuadrático. Seleccionemos el menú Datos de la cinta de herramientas, el cual mostrará a la derecha el menú Análisis de datos, hacemos clic y se abrirá el siguiente cuadro:\n\n\nSeleccionamos la opción Regresión, con lo que se abrirá el siguiente diálogo:\n\nEn Rango Y de entrada presionamos la flecha negra que apunta hacia arriba y seleccionamos con el mouse los datos de \\(Y\\), incluyendo la letra \\(Y\\), luego presionamos la flecha que apunta hacia abajo:\n\nEn Rango X de entrada presionamos la flecha negra que apunta hacia arriba y seleccionamos con el mouse las dos columnas: \\(X\\) y \\(X^2\\), incluyendo las etiquetas, luego presionamos la flecha que apunta hacia abajo:\n\nChequeamos los cuadritos Rótulosy Nivel de confianza.\n{{% callout warning %}} Jamás chequee el cuadrito Constante igual a cero, a menos que haya demostrado previamente esta hipótesis{{% /callout %}}\nEn Opciones de salida seleccionamos en Rango de salida la celda E1 (en realidad da igual, es para que tengamos la misma salida).\n ¡Listo! Por ahora no usaremos las otras opciones.\n\nPresiones Aceptary aparecerá el análisis estadístico a partir de la celda E1:\n\n\n\nNo nos detendremos a explicar toda la información estadística de las tablas, iremos directamente al grano: al test de linealidad de Mandel. Ubique en la tabla inferior la fila de la variable X^2 y la columna respectiva denominada Probabilidad. En este ejemplo marqué con rojo la celda del test de Mandel:\n\n 8. Esta celda representa el p-value del test de Mandel. En este ejemplo el p-value = \\(3,6\\times 10^{-11}\\), es decir, bajo la interpretación tradicional de las pruebas de hipótesis, ya que p-value \\(&lt; 0,05\\) concluiríamos que el modelo lineal no es adecuado o razonable para modelar los datos de calibración.\nBueno, queridos lectores espero les haya gustado. Como siempre, pueden dejar sus comentarios/críticas y sugerencias aquí abajo. Hasta la próxima.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "post/post_1/index.html",
    "href": "post/post_1/index.html",
    "title": "post 1",
    "section": "",
    "text": "hist(rnorm(1000))\n\n\n\n\n\n\n\n\n\nmean(35)\n\n[1] 35"
  },
  {
    "objectID": "post/post_1/index.html#comprobado",
    "href": "post/post_1/index.html#comprobado",
    "title": "post 1",
    "section": "",
    "text": "mean(35)\n\n[1] 35"
  },
  {
    "objectID": "post/incertidumbre-de-una-calibracion-no-lineal/index.html",
    "href": "post/incertidumbre-de-una-calibracion-no-lineal/index.html",
    "title": "Incertidumbre de una calibración no lineal",
    "section": "",
    "text": "En un post anterior revisamos cómo estimar la incertidumbre de la concentración de una muestra problema, cuando ésta ha sido obtenida interpolando la señal instrumental en una curva de calibración lineal.\nLa expresión es relativamente simple y vimos también cómo podemos implementarla en el lenguaje de programación R a través del package chemCal.\nSin embargo, la vida no es tan sencilla. Recoradará estimad@ lector@ que está bastante documentada la presencia de desviaciones de la linealidad a altas concentraciones, fenómeno muy conocido en los métodos espectrofotométricos (Ley de Lambert-Beer). La severidad de estas desviaciones varía en función del detector, el analito y otros factores físico-químicos del sistema de medición.\nCuando existen estas desviaciones y deseamos llevar a cabo un test de linealidad, es muy probable que el test rechace el modelo lineal, por lo tanto, no podemos estimar la incertidumbre de calibración asumiendo este modelo. Si bien es cierto podemos reducir el rango lineal y diluir la muestra problema que está fuera del rango, la operación de dilución introduce nuevos errores (incluso errores humanos de transcripción bastante frecuentes).\nUna alternativa válida sería utilizar un modelo de calibración que capture esta no linealidad evitando así la dilución de la muestra, por lo tanto el problema se reduce a:\nSin embargo, de esta pregunta se desprende al mismo tiempo otra interrogante:\nExisten varios modelos de calibración no lineal:\nPor lo tanto, no existe una respuesta completamente correcta desde la prespectiva estadística, pues un modelo cuadrático sería tan válido como un polinomio cúbico. Desde el punto de vista químico podríamos preguntarnos ¿qué sentido químico tiene una curva de calibración polinómica de grado 5? ¿Son interpretables los parámetros del modelo? En un modelo lineal como el de Lambert-Beer: \\(y = \\beta_{0} + \\beta_{1}x\\) la pendiente de la curva de calibración tiene una interpretación química: es el producto entre coeficiente de extinción molar y la longitud de la celda:\n\\[\n\\underbrace{A}_\\text{y} = \\underbrace{\\epsilon \\cdot b}_\\text{$\\beta_{1}$} \\cdot\n\\underbrace{C}_\\text{x}\n(\\#eq:lambert)\n\\] Pero recuerde este sabio consejo de un monstruo de la estadística aplicada:\nPor lo tanto, tenemos que tomar una decisión. Y obviamente, como soy el autor de este humilde post, ya la tomé por Ud. En este artículo estimaremos la incertidumbre de calibración de un modelo polinómico de grado 2, también conocido como modelo cuadrático.\nNota: Desde el punto de vista estrictamente estadístico los modelos polinómicos, como la calibración cuadrática, son también modelos lineales ya que los coeficientes del modelo son lineales\n\\[y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^2 + \\epsilon\\]\nEn cambio, en un modelo del tipo exponencial:\n\\[y = \\beta_{0}\\cdot e^{\\beta_{1}x}\\]\nEl coeficiente \\(\\beta_{1}\\) no es una función lineal."
  },
  {
    "objectID": "post/incertidumbre-de-una-calibracion-no-lineal/index.html#estimación-de-incertidumbre-de-acuerdo-a-iso-8466-2",
    "href": "post/incertidumbre-de-una-calibracion-no-lineal/index.html#estimación-de-incertidumbre-de-acuerdo-a-iso-8466-2",
    "title": "Incertidumbre de una calibración no lineal",
    "section": "Estimación de incertidumbre de acuerdo a ISO 8466-2",
    "text": "Estimación de incertidumbre de acuerdo a ISO 8466-2\nDesde el punto de vista metrológico, la aproximación que indica esta norma es similar a lo que dicta la guía ISO GUM clásica, es decir, estima la incertidumbre a partir de un modelo de medición \\(y = f(x)\\). La “gracia” de esta norma es que nos ahorra tinta, pues la ecuación de incertidumbre ya está “algebraicamente manipulada”. No entraremos en los detalles de las primeras secciones de la norma los cuales estudian el comportamiento de la curvatura, es decir, si será posible encontrar un máximo o un mínimo, lo cual es clave en la utilidad del modelo cuadrático como función de calibración. Esto es importante porque recuerde que una función parabólica tiene dos soluciones, si existiera un máximo o un mínimo en el rango de trabajo, el modelo cuadrático no puede ser utilizado como función de calibración.\nLa siguiente ecuación calcula la incertidumbre expandida \\(I(\\hat{x}) = U_{\\hat{x}}\\) de la concentración de la muestra problema \\(\\hat{x}\\), interpolada en la curva de calibración no lineal \\(y = a + bx + cx^2\\). Corresponde a la ecuación (27) de la norma:\n\\[\nI(\\hat{x}) = \\frac{s_{y} \\cdot t_{n - 3,\\, 95\\%}}{b + 2c\\hat{x}} \\cdot\n            \\sqrt{\\frac{1}{N} + \\frac{1}{\\hat{N}} +\n            \\frac{(\\hat{x} - \\overline{x})^2 \\, Q_{x^4} +\n            \\left(\\hat{x}^2 - \\frac{\\sum x_{i}^{2}}{N} \\right)^2 Q_{xx} -\n            2(\\hat{x} - \\overline{x})\n            \\left(\\hat{x}^2 - \\frac{\\sum x_{i}^{2}}{N} \\right) Q_{x^3}}\n            {Q_{x^4} Q_{xx} - \\left( Q_{x^3} \\right)^2}}\n\\]\ndonde:\n\\[\ns_{y} = \\sqrt{\\frac{\\sum (y_{i} -\\hat{y})^2}{N - 3}}\n\\]\n\n\\(y_{i}\\) es la respuesta experimental observada del estándar \\(i\\), \\(\\hat{y}\\) es la respuesta instrumental que predice el modelo para el mismo estándar \\(i\\), por lo tanto \\(e_{i} = y_{i} - \\hat{y}\\) es el residuo. \\(N\\) es el número de calibrantes. ¿Por qué el denominador es \\(N - 3\\) y no \\(N -2\\) como en la calibración lineal? Porque el modelo cuadrático posee tres parámetros \\(a\\), \\(b\\) y \\(c\\).\n\\(t_{N - 3,\\, 95\\%}\\) es el valor del T de Student con \\(N - 3\\) grados de libertad y un 95% de confianza.\n\\(\\hat{N}\\) es el número de replicados independientes de la muestra problema. Como discutimos en otro post, esto no corresponde a inyectar \\(\\hat{N}\\) veces la misma muestra en el instrumento.\n\\(\\hat{x}\\) es la concentración de la muestra problema interpolada en la curva de calibración no lineal, la cual se obtiene resolviendo la ecuación cuadrática. Como Ud. recordará de sus años mozos esto siginifica que la concentración interpolada se obtiene a partir de:\n\n\\[\\hat{x} = \\frac{-b \\pm \\sqrt{b^2 - 4(a - y_{0})c}}{2c}\\] donde \\(y_{0}\\) es la señal instrumental de la muestra problema.\n\n\\(x_{i}\\) es la concentración del estándar \\(i\\)\n\\(\\overline{x} = \\sum_{i = 1}^{N} x_{i}\\) es el promedio de las concentraciones de los calibrantes.\n\nFinalmente:\n\\[\n\\begin{aligned}\nQ_{xx}  &= \\sum x_{i}^2 - \\frac{\\left(\\sum x_{i}\\right)^2}{N} \\\\\nQ_{x^3} &= \\sum x_{i}^3 - \\left(\\sum x_{i} \\times \\frac{\\sum x_{i}^2}{N}\\right) \\\\\nQ_{x^4} &= \\sum x_{i}^4 - \\frac{\\left(\\sum x_{i}^2\\right)^2}{N}\n\\end{aligned}\n\\]\nOk, nada del otro mundo. Es bien fea, pero sólo son operaciones de aritmética básica. Algunas observaciones:\nComo Ud. recordará en el caso de la calibración lineal, a partir de esta ecuación podemos inferir que si deseamos minimizar la incertidumbre de calibración no lineal podemos :\n\nAumentar el número de calibrantes \\(N\\)\nAumentar el número de replicados independientes de la muestra problema \\(\\hat{N}\\)\nAumentar la sensibilidad del método, que en el caso de la calibración cuadrática está dada por \\(b + 2c\\hat{x}\\), es decir, depende de la concentración de la muestra problema \\(\\hat{x}\\). En cambio, en la calibración lineal la sensibilidad era constante en todo el rango de concentración estudiado y correspondía a la pediente de la curva.\n\nEn el caso de la calibración lineal, la incertidumbre de calibración se minimiza en el centroide de la curva, en el caso del modelo cuadrático esto no siempre es así. Observe en la siguiente figura las bandas de confianza de ambos tipos de calibración:\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nAdvierta que ambos modelos comparten la propiedad que la mayor incertidumbre se encuentra en los extremos. Sin embargo, en la calibración cuadrática, para este conjunto de datos, la menor incertidumbre no está en el centro de la curva.\nOk, a continuación implementaremos la ecuación de incertidumbre en R con los datos del ejemplo de la sección 7 de la norma. La señal instrumental de la muestra problema es \\(y_{0} = 0.084\\) UA:\n\nN &lt;- length(x) # Número de calibrantes\nN.hat &lt;- 1     # Número de replicados de la muestra problema\nQxx &lt;- sum(x^2) - sum(x)^2/N\nQx3 &lt;- sum(x^3) -(sum(x) * sum(x^2)/N)\nQx4 &lt;- sum(x^4) - sum(x^2)^2/N\n\na &lt;- fit.nolineal$coefficients[1]\nb &lt;- fit.nolineal$coefficients[2]\nc &lt;- fit.nolineal$coefficients[3]\n\ns.y &lt;- summary(fit.nolineal)$sigma # Es lo que R denomina Residual standard error\nt &lt;- qt(0.975, N - 3) # El T de Student (¡Ya no se usan tablas!)\n\ny0 &lt;- 0.084 # Es la señal instrumental de la muestra problema\nx.hat &lt;- (-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c) # Concentración de la muestra\n\nIx &lt;- (s.y * t)/(b + 2*c*x.hat) * sqrt(\n  1/N + 1/N.hat + ((x.hat - mean(x))^2*Qx4 + (x.hat^2 - sum(x^2)/N)^2 * Qxx -  \n  2*(x.hat - mean(x))*(x.hat^2 - sum(x^2)/N)*Qx3)/\n  (Qx4 * Qxx - Qx3^2)\n)\n\nIx &lt;- unname(Ix) # Simplemente es para dejar sólo el número\n\nLa concentración de la muestra es \\(\\hat{x} = 12.17\\) mg/L. Al aplicar esta metodología obtenemos una incertidumbre expandida de \\(I(\\hat{x}) = 0.63\\) mg/L, es decir, exactamente la misma que la que indica la norma ISO. Note que si Ud. quisiera combinar esta incertidumbre de calibración con algún otro factor (p.ej: masa de la muestra, volumen de aforo, etc.) debe primero tansformarla en incertidumbre estándar, dividiéndola por el factor de cobertura \\(k\\), que en este caso corresponde al t Student con \\(N - 3\\) grados de libertad al 95% de confianza (k = 2.36):\n\\[\nu_{\\hat{x}} = \\frac{U_{\\hat{x}}}{k} = 0.27\\, \\, \\text{mg/L}\n\\] Por lo tanto, si tuviéramos que informar el resultado de la concentración de la muestra interpolada en la curva de calibración no lineal informaríamos \\(12.17 \\pm 0.63\\) mg/L [nota mental: mmmm… esto de las cifras significativas da para otro post, pero dejémoslo así por ahora. No olvidar borrar este comentario.]\n¿Cómo varía esta incertidumbre de calibración no lineal con la concentración de la muestra? La siguiente figura muestra esta variación:\n\nx &lt;- seq(12, 66, by = 6) # Rango de concentración\nN &lt;- length(x)\nN.hat &lt;- 1\nmu.x &lt;- mean(x) # promedio de las concentraciones de los calibrantes\nsq.x &lt;- sum(x^2) # suma de las concentraciones de los calibrantes al cuadrado\nQxx &lt;- sum(x^2) - sum(x)^2/N\nQx3 &lt;- sum(x^3) -(sum(x) * sum(x^2)/N)\nQx4 &lt;- sum(x^4) - sum(x^2)^2/N\nt &lt;- qt(0.975, N - 3)\n\n# Para graficar la incertidumbre vs concentración, primero debemos crear una\n# función que tome un X (una concentración) y calcule el Y (incertidumbre)\nUx &lt;- function(x) {\n    U &lt;- s.y*t/(b + 2*c*x) * sqrt(\n    1/N + 1/N.hat + ((x - mu.x)^2*Qx4 + (x^2 - sq.x/N)^2 * Qxx -  \n    2*(x - mu.x)*(x^2 - sq.x/N)*Qx3)/\n    (Qx4 * Qxx - Qx3^2))\n    return(unname(U))\n}\n\n# Graficamos concentración (X) vs Incertidumbre (Y)\n\nplot(x, Ux(x), type = 'n',\n     main = 'Concentración vs Incertidumbre de calibración',\n     xlab = 'Concentración [mg/L]',\n     ylab = 'Incertidumbre expandida [mg/L]')\nlines(spline(x, Ux(x)), col = 'red')\n\n\n\n\nSe aprecia que la incertidumbre aumenta con la concentración en una forma no constante para concentraciones mayores a 20 mg/L. Tal como mencionamos anteriormente, el mínimo no se encuentra en el centro del rango de concentración como ocurre con la calibración lineal. Para encontrar el valor exacto de concentración que minimiza la incertidumbre en este rango, usamos el comando optimize:\n\n# Busca el mínimo de la función Ux en el intervalo de 12 a 66 mg/L\noptimize(Ux, interval = c(12, 66))\n\n$minimum\n[1] 20.29164\n\n$objective\n[1] 0.5808116\n\n\nLa concentración que minimiza la incertidumbre es 20.29 mg/L.\nMuy entretenido, pero la vida es corta y debemos ser eficientes por lo tanto, para evitarnos el “tedio” de implementar la fórmula a mano, utilizaremos el package investr el cual calcula exactamente la incertidumbre de calibración de un gran número de modelos de calibración, entre ellos, los modelos cuadráticos:\n\n# y0 es la señal de la muestra problema y0 = 0.084 UA\nlibrary(investr) # Cargamos la librería investr\nx.hat &lt;- invest(fit.nolineal, data = d, y0 = y0, interval = 'Wald')\nx.hat\n\n  estimate      lower      upper         se \n12.1672952 11.5400416 12.7945489  0.2652657 \n\n\ndonde:\n\nestimate es la concentración de la muestra problema\nupper es el extremo superior de la incertidumbre expandida \\(I(\\hat{x})\\)\nlower es el extremo inferior de la incertidumbre expandida \\(I(\\hat{x})\\)\nse es la incertidumbre estándar de calibración \\(u_{\\hat{x}}\\), la cual es exactamente igual a la obtenida por la fórmula anterior \\(u_{\\hat{x}} = \\frac{U_{\\hat{x}}}{k} = 0.27\\, \\, \\text{mg/L}\\)\n\nNote que si quisiéramos obener \\(I(\\hat{x})\\) a partir de esta tabla, tendríamos que hacer la siguiente operación \\(I(\\hat{x}) =\\) upper - estimate:\n\nx.hat$upper - x.hat$estimate\n\n[1] 0.6272536\n\n\nNo podemos usar el package chemCal que utilizamos en un post anterior para estimar la incertidumbre de calibración, porque este package sólo soporta calibraciones lineales."
  },
  {
    "objectID": "post/incertidumbre-de-una-calibracion-no-lineal/index.html#estimación-de-incertidumbre-mediante-guía-iso-gum",
    "href": "post/incertidumbre-de-una-calibracion-no-lineal/index.html#estimación-de-incertidumbre-mediante-guía-iso-gum",
    "title": "Incertidumbre de una calibración no lineal",
    "section": "Estimación de incertidumbre mediante Guía ISO GUM",
    "text": "Estimación de incertidumbre mediante Guía ISO GUM\nYa que la señal instrumental es una función de la concentración, entonces, podemos utilizar la aproximación ISO GUM clásica para estimar la incertidumbre de calibración. Por “clásica” me refiero a utilizar la aproximación de Taylor con las derivadas parciales. Esta guía dice lo siguiente:\n\nExpresar el mensurando como una ecuación de medición a través de una relación funcional con las magnitudes de entrada. En este caso el mensurando es la concentración \\(\\hat{x}\\) cuya ecuación de medición es la solución de la ecuación cuadrática \\(y_{0} = a + b\\hat{x} + c\\hat{x^2}\\) donde \\(y_{0}\\) es la señal de la muestra problema:\n\n\\[\n\\hat{x} = \\frac{-b \\pm \\sqrt{b^2 - 4(a - y_{0})c}}{2c}\n\\] 2. Identificación de las fuentes de incertidumbre. Al observar la ecuación de medición identificamos las siguientes fuentes de incertidumbre:\n\nParámetros del modelo cuadrático: \\(a\\), \\(b\\) y \\(c\\)\nSeñal instrumental de la muestra problema \\(y_{0}\\)\n\n\nEvaluación de las fuentes de incertidumbre:\n\n\nLas incertidumbres estándar de los parámetros del modelo pueden ser obtenidas directamente del ajuste cuadrático fit.nolineal:\n\n\n# parámetros del modelo\na &lt;- fit.nolineal$coeff[1]\nb &lt;- fit.nolineal$coeff[2]\nc &lt;- fit.nolineal$coeff[3]\n\n# las incertidumbres estándar de a, b y c las obtenemos con la función summary\nua &lt;- summary(fit.nolineal)$coefficients[1, 2]\nub &lt;- summary(fit.nolineal)$coefficients[2, 2]\nuc &lt;- summary(fit.nolineal)$coefficients[3, 2]\n\n\nLa incertidumbre estándar de la señal instrumental de la muestra problema también puede obtenerse del ajuste cuadrático y corresponde a la desviación estándar residual:\n\n\nuy0 &lt;- summary(fit.nolineal)$sigma\ny0 &lt;- 0.084 # dato del problema, es decir, la absorbancia de la muestra\n\n\nDeterminación de la incertidumbre estándar combinada \\(u_{\\hat{x}}\\) a través de la expresión:\n\n\\[\nu_{\\hat{x}}^2 = \\left( \\frac{\\partial{\\hat{x}}}{\\partial{y_{0}}}\\right) ^{2} (u_{y_{0}})^{2} +\n\\left( \\frac{\\partial{\\hat{x}}}{\\partial{a}}\\right) ^{2} (u_{a})^{2} +\n\\left( \\frac{\\partial{\\hat{x}}}{\\partial{b}}\\right) ^{2} (u_{b})^{2} +\n\\left( \\frac{\\partial{\\hat{x}}}{\\partial{c}}\\right )^{2} (u_{c})^{2}\n\\]\n“sólo” nos falta obtener las derivadas parciales (aguante ese código \\(\\LaTeX\\)):\n\\[\n\\begin{aligned}\n\\frac{\\partial{\\hat{x}}}{\\partial{y_{0}}} &=\n\\frac{1}{\\sqrt{b^{2} - 4c(a-y_{0})}} \\\\\n\\frac{\\partial{\\hat{x}}}{\\partial{a}} &=\n  \\frac{-1}{\\sqrt{b^{2} - 4c(a-y_{0})}} \\\\\n\\frac{\\partial{\\hat{x}}}{\\partial{b}} &=\n\\frac{-1 + \\frac{b}{\\sqrt{b^{2} - 4c(a-y_{0})}}}{2c} \\\\\n\\frac{\\partial{\\hat{x}}}{\\partial{c}} &=\n  \\frac{-a + y_{0}}{c\\sqrt{b^{2} - 4c(a-y_{0})}} -\n  \\frac{-b + \\sqrt{b^{2} - 4c(a-y_{0})}}{2c^{2}}\n\\end{aligned}\n\\]\n¡Listo! ahora debemos evaluar las expresiones. Pero como soy flojo, prefiero usar el excelente package metRology que hará todo el trabajo por mí:\n\nlibrary(metRology) # cargamos la librería\n\n\nAttaching package: 'metRology'\n\n\nThe following objects are masked from 'package:base':\n\n    cbind, rbind\n\nexpr &lt;- expression((-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c)) # ecuación de medición\nx &lt;- list(a = a, b = b, c = c, y0 = y0) # valores de cada X input\nu &lt;- c(ua, ub, uc, uy0) # incertidumbres estándar de cada X input\nu.GUM &lt;- uncert(expr, x, u, method = 'GUM') # Usamos el método GUM\nu.GUM\n\n\nUncertainty evaluation\n\nCall:\n  uncert.expression(obj = expr, x = x, u = u, method = \"GUM\")\n\nExpression: (-b + sqrt(b^2 - 4 * (a - y0) * c))/(2 * c)\n\nEvaluation method:  GUM \n\nUncertainty budget:\n   x             u            c           u.c        \na  -5.621212e-03 2.474778e-03   -141.6217 -0.35048212\nb   7.670455e-03 1.420320e-04  -1723.1492 -0.24474238\nc  -2.504209e-05 1.787394e-06 -20966.0252 -0.03747454\ny0  8.400000e-02 1.478563e-03    141.6217  0.20939648\n\n   y:  12.16727\nu(y):  0.4774807 \n\n\n¿What? ¿Por qué obtuvimos una incertidumbre estándar de 0.477 y no la que calculamos con la ecuación de la norma ISO 0.265? Por la sencilla razón de que los parámetros de un modelo cuadrático no son independientes, sus covarianzas no son 0. Es más, algunas de las covarianzas son negativas. Observe la siguiente figura que fue obtenida simulando curvas de calibración cuadráticas. En la figura se muestra las correlaciones entre los tres parámetros del modelo no lineal:\n\n# Simularemos p = 200 curvas de calibración cuadráticas a partir de los datos \n# empíricos \n\np &lt;- 200 # Número de simulaciones\na.sim &lt;- numeric(p) # vector que guardará el parámetro a\nb.sim &lt;- numeric(p) # vector que guardará el parámetro b\nc.sim &lt;- numeric(p) # vector que guardará el parámetro c\n\n# Hacemos un loop\nfor(i in 1:p){\n  x.sim &lt;- seq(12, 66, by = 6)\n  y.sim &lt;- a + b*x.sim + c*x.sim^2 + rnorm(length(x.sim), 0, uy0)\n  fit.nolineal.sim &lt;- lm(y.sim ~ x.sim + I(x.sim^2))\n  a.sim[i] &lt;- fit.nolineal.sim$coeff[1]\n  b.sim[i] &lt;- fit.nolineal.sim$coeff[2]\n  c.sim[i] &lt;- fit.nolineal.sim$coeff[3]\n}\n\n# guardamos los parámetros simulados en un data frame que llamamos param.sim\nparam.sim &lt;- data.frame(a.sim, b.sim, c.sim) \n                                                \n# graficamos los parámetros simulados\nplot(param.sim)\n\n\n\n\nSe advierte claramente que existe una correlación negativa entre los parámetros \\(a\\) y \\(b\\), además entre \\(b\\) y \\(c\\). La correlación entre \\(a\\) y \\(c\\) es positiva. En rigor, habría que incorporar las derivadas parciales cruzadas y las covarianzas entre los parámetros. De sólo pensarlo, me dan ganas de procastinar aún más la escritura de este post, así que recurriremos al package metRology.\nLa parte “fácil” es obtener la matriz de covarianzas de los parámetros del modelo con el comando vcov:\n\nv &lt;- vcov(fit.nolineal)\ncolnames(v) &lt;- c('a', 'b', 'c') # solo cosmética para que aparezcan los nombres\nrownames(v) &lt;- c('a', 'b', 'c') # de los parámetros (es opcional)\nv\n\n              a             b             c\na  6.124524e-06 -3.337187e-07  3.910406e-09\nb -3.337187e-07  2.017310e-08 -2.491926e-10\nc  3.910406e-09 -2.491926e-10  3.194776e-12\n\n\nLa diagonal de esta matriz es precisamente la incertidumbre estándar al cuadrado de los parámetros (a.k.a sus varianzas). Si queremos, también podemos expresarla como matriz de correlaciones con el comando cov2cor:\n\nparam.cor &lt;- cov2cor(v)\nparam.cor\n\n           a          b          c\na  1.0000000 -0.9494193  0.8840269\nb -0.9494193  1.0000000 -0.9815865\nc  0.8840269 -0.9815865  1.0000000\n\n\nEn la diagonal de esta matriz obviamente esperamos correlación 1. Se observa claramente la alta correlación entre los parámetros, como dijimos anteriormente, algunas de ellas son negativas.\nLa parte “difícil” es que debemos incorporar la variable señal instrumental de la muestra problema \\(y_{0}\\), la cual obviamente es independiente de los parámetros del modelo:\n\n# Incorporamos la variable y0 que es independiente de los parámetros\nv &lt;- rbind(v, y0 = rep(0, 3)) \nv &lt;- cbind(v, y0 = rep(0, 4))\nv[4, 4] &lt;- uy0^2 # Asignamos al elemento de la 4a fila y 4a columna  \n                 # la varianza de y0\nv\n\n               a             b             c           y0\na   6.124524e-06 -3.337187e-07  3.910406e-09 0.000000e+00\nb  -3.337187e-07  2.017310e-08 -2.491926e-10 0.000000e+00\nc   3.910406e-09 -2.491926e-10  3.194776e-12 0.000000e+00\ny0  0.000000e+00  0.000000e+00  0.000000e+00 2.186147e-06\n\n\nAhora, incorporamos las covarianzas en el cálculo por método GUM:\n\nu.GUM.cov &lt;- uncert(expr, x, cov = v, method = \"GUM\")\nu.GUM.cov\n\n\nUncertainty evaluation\n\nCall:\n  uncert.expression(obj = expr, x = x, method = \"GUM\", cov = v)\n\nExpression: (-b + sqrt(b^2 - 4 * (a - y0) * c))/(2 * c)\n\nEvaluation method:  GUM \n\nUncertainty budget:\n   x             u            c           u.c        \na  -5.621212e-03 2.474778e-03   -141.6217 -0.35048212\nb   7.670455e-03 1.420320e-04  -1723.1492 -0.24474238\nc  -2.504209e-05 1.787394e-06 -20966.0252 -0.03747454\ny0  8.400000e-02 1.478563e-03    141.6217  0.20939648\n\n   y:  12.16727\nu(y):  0.2651904 \n\n\n¡Perfecto!, ahora sí, al incluir las covarianzas obtenemos resultados consistentes con el método descrito en la norma ISO 8466-2."
  },
  {
    "objectID": "post/incertidumbre-de-una-calibracion-no-lineal/index.html#estimación-con-el-método-de-monte-carlo",
    "href": "post/incertidumbre-de-una-calibracion-no-lineal/index.html#estimación-con-el-método-de-monte-carlo",
    "title": "Incertidumbre de una calibración no lineal",
    "section": "Estimación con el Método de Monte Carlo",
    "text": "Estimación con el Método de Monte Carlo\nNo detallaremos aquí cómo funciona el método de Monte Carlo, puede consultarlo en este post y en este otro.\nSería super simple si usamos el package metRology, el problema es que el package lanza un error numérico cuando existen covarianzas negativas. Probé el ejemplo que incluye el manual de metRology y el error se repite. Es un problema al evaluar la suma de las correlaciones. Le consulté al autor Steve Ellison, sin embargo, a la fecha (09 de junio 2020) aún no tengo respuesta, a pesar de que Steve siempre responde las consultas en forma muy expedita. Otros usuarios han tenido un problema similar y se ha abierto un hilo en stackoverflow.\nPor lo tanto, implementamos el método de Monte Carlo “a mano” utilizando el package MASS el cual permite generar muestras aleatorias multivariadas incluyendo las correlaciones:\n\n# No funciona metRology MC así que lo hicimos a mano\nlibrary(MASS) # cargamos la librería\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:patchwork':\n\n    area\n\n# Generamos n muestras aleatorias multivariadas, cuyas medias \n# corresponden a los valores de a, b, c e y0\n# La matriz de covarianza Sigma = v la calculamos anteriormente\n\nset.seed(123) # Para que Ud. obtenga los mismos resultados\nmuestra.MC &lt;- mvrnorm(n = 10000, mu = c(a, b, c, y0), Sigma = v, empirical = T)\ncolnames(muestra.MC) &lt;- c('a', 'b', 'c', 'y0') # solo cosmética\nmuestra.MC &lt;- data.frame(muestra.MC) # lo guardamos como data.frame\nhead(muestra.MC) # muestra las primeras n = 6 simulaciones\n\n             a           b             c         y0\n1 -0.006371785 0.007697494 -2.535336e-05 0.08771566\n2 -0.006657346 0.007727893 -2.572028e-05 0.08385741\n3 -0.005338584 0.007654631 -2.437727e-05 0.08643112\n4 -0.006478276 0.007654191 -2.412670e-05 0.08417975\n5 -0.008126340 0.007832532 -2.697179e-05 0.08478106\n6 -0.005139204 0.007672558 -2.484339e-05 0.08644533\n\n\nCada fila es una simulación. Si, por ejemplo, calculamos el promedio de cada variable simulada, obtenemos un valor similar a los valores empíricos. A mayor número de simulaciones, más nos acercamos a valores que asumimos como verdaderos.\n\napply(muestra.MC, 2, mean) # promedio de cada columna\n\n            a             b             c            y0 \n-5.621212e-03  7.670455e-03 -2.504209e-05  8.400000e-02 \n\n\nBien, lo que tenemos que hacer es que en cada simulación debemos calcular la concentración de la muestra:\n\n# cargaré estas librerías sólo para facilitar la manipulación de los datos\nlibrary(magrittr)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ ggpp::annotate()   masks ggplot2::annotate()\n✖ tidyr::extract()   masks magrittr::extract()\n✖ dplyr::filter()    masks stats::filter()\n✖ dplyr::lag()       masks stats::lag()\n✖ dplyr::select()    masks MASS::select()\n✖ purrr::set_names() masks magrittr::set_names()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Creamos una nueva variable llamada x.hat que corresponde a la concentración de\n# la muestra\nmuestra.MC &lt;- muestra.MC %&gt;% \n  mutate(x.hat = (-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c))\nhead(muestra.MC) # muestra las primeras n = 6 simulaciones\n\n             a           b             c         y0    x.hat\n1 -0.006371785 0.007697494 -2.535336e-05 0.08771566 12.75935\n2 -0.006657346 0.007727893 -2.572028e-05 0.08385741 12.20883\n3 -0.005338584 0.007654631 -2.437727e-05 0.08643112 12.48521\n4 -0.006478276 0.007654191 -2.412670e-05 0.08417975 12.32289\n5 -0.008126340 0.007832532 -2.697179e-05 0.08478106 12.39039\n6 -0.005139204 0.007672558 -2.484339e-05 0.08644533 12.43752\n\n\nLa última columna corresponde a la concentración calculada para cada simulación. Por lo tanto, si queremos obtener la incertidumbre estándar de la concentración, basta calcular la desviación estándar de esa columna:\n\nmu.x.hat.MC &lt;- mean(muestra.MC$x.hat) # valor promedio de concentración\nu.x.hat.MC &lt;- sd(muestra.MC$x.hat) # incertidumbre estándar de la concentración\nu.x.hat.MC\n\n[1] 0.265344\n\n\nSe obtiene una incertidumbre estándar de calibración de 0.265 mg/L, la cual es consistente con los otros métodos estudiados. La siguiente figura muestra el histograma de las concentraciones simuladas:\n\nhist(muestra.MC$x.hat, \n     breaks = 20,\n     main = 'Concentraciones simuladas por Monte Carlo',\n     xlab = 'Concentración [mg/L]')\n\n\n\n\nFinalmente, la siguiente tabla resume los resultados de los tres métodos considerando la incertidumbre estándar de calibración:\n\ntabla &lt;- data.frame(Ix/t, u.GUM$u.y, u.GUM.cov$u.y, u.x.hat.MC)\nknitr::kable(tabla, \n             rownames = NA,\n             col.names = c('ISO', 'GUM', 'GUM/Covarianzas', 'Monte Carlo'),\n             align = 'l')\n\n\n\n\nISO\nGUM\nGUM/Covarianzas\nMonte Carlo\n\n\n\n\n0.2651904\n0.4774807\n0.2651904\n0.265344\n\n\n\n\n\nSe aprecia claramente una excelente concordancia entre los tres métodos. Sin embargo, para que el método GUM entregue resultados correctos, es necesario incorporar las covarianzas entre las variables input.\nEn un próximo post exploraremos el método Bootstrap, un método estadístico por excelencia para estimar incertidumbre sin utilizar un modelo de medición…\n\n¡Dejad que los datos hablen!"
  },
  {
    "objectID": "post/como-detectar-efecto-matriz-metodo-analitico/index.html",
    "href": "post/como-detectar-efecto-matriz-metodo-analitico/index.html",
    "title": "¿Cómo detectar el efecto matriz en un método analítico?",
    "section": "",
    "text": "He vuelto a postear, después de una gira que me llevó por los cinco… mentira, fue por pura pega.\nEl famoso efecto matriz, algo tan etéreo como el criterio analítico. El efecto matriz está íntimamente relacionado con las interferencias de la matriz que de alguna forma aumentan o disminuyen la señal instrumental que, en teoría, es producida sólo por el analito de interés.\nPara evaluar y detectar el efecto matriz, debemos desempolvar algunos papers que nos enseñaron el famoso método de calibración con adición conocida o adición de estándar. En este método, la matriz es nuestro medio de calibración. En vez de preparar los calibrantes en solventes puros o en solución ácida, utilizaremos la misma matriz para preparar (adicionar) el analito. De esta forma, la señal analítica de estos calibrantes, está compuesta de la señal propia del analito así como también de los interferentes, lo que permite corregir/minimizar sus efectos.\nExisten varias formas de implementar el método de adición conocida. Una muy buena referencia es el excelente y pedagógico paper de M. Bader:\nEl método consiste en añadir cantidades conocidas del analito en solvente puro o solución ácida a volúmenes iguales de matriz. Finalmente, medir la respuesta instrumental en una serie de adiciones crecientes tal como lo muestra la figura @ref(fig:mosaplot):\nDiseño experimental de la adición conocida. Cortesía de Lins4y via Wikimedia Commons\nEs necesario que las adiciones de analito generen, en conjunto con la cantidad de analito presente en la muestra original, una concentración tal que aún se encuentre en el rango lineal de calibración. De esta forma se otiene una curva tal como se observa en la figura @ref(fig:adicion):\nPreparación curva método de adición conocida\nLas unidades del eje \\(X\\) pueden establecerse como analito añadido o, tal como lo propone Bader en su paper, como múltiplos de un volumen o cantidad fija del analito. Por lo tanto, en \\(x = 0\\) se obtiene la señal de la muestra problema a la cual no se le ha agregado el analito, es decir, la señal original. En cada una de las adiciones del estándar mediremos la señal instrumental de tal manera de obtener, y así lo esperamos, una relación lineal entre analito agregado \\(x\\) y señal \\(y\\) de la forma:\n\\[\\begin{equation}\n  y = \\beta_{0} + \\beta_{1}x + \\epsilon\n    (\\#eq:calib)\n\\end{equation}\\]\ndonde se asumen los mismos supuestos que discutimos en el caso de la calibración lineal estándar(en solvente puro) y que puede recordar en este post.\nLa concentración de la muestra problema \\(C_{0}\\) se obtiene a partir de la ecuación @ref(eq:c0):\n\\[\\begin{equation}\n  C_{0} = \\frac{\\beta_{0}}{\\beta_{1}}\n  (\\#eq:c0)\n\\end{equation}\\]\nLa incertidumbre de la concentración de la muestra problema \\(u(C_{0})\\) se calcula a partir de la ecuación:\n\\[\\begin{equation}\n  u(C_{0}) = \\frac{\\sigma_{y/x}}{\\beta_{1}}\n  \\sqrt{\\frac{1}{n} + \\frac{\\overline{y}^2}\n  {\\beta_{1}\\sum_{i}^{n} (x_{i} - \\overline{x})^2}}\n    (\\#eq:uc0)\n\\end{equation}\\]\ndonde:\nComo puede apreciar, la expresión de la incertidumbre de calibración para el método de adición conocida es muy similar a la correspondiente calibración estandar que discutimos en un post anterior.\nSi queremos minimizar esta incertidumbre podríamos aumentar el número de adiciones \\(n\\) o aumentar el término \\(\\sum_{i}^{n} (x_{i} - \\overline{x})^2\\). Este último término es interesante, pues nos dice que la incertidumbre de calibración de este método se minimiza utilizando un rango amplio de concentración de adición. Ellison demuestra que, dado que la propiedad de linealidad se mantiene, basta preparar dos puntos de calibración:\nPor ejemplo, si por alguna razón se tuvieran que preparar \\(n = 6\\) adiciones, lo que indica la ecuación @ref(eq:uc0), es que sería mejor preparar tres puntos sin adición (\\(x = 0\\)) y tres en el extremos superior del rango lineal, tal como lo demuestra la figura @ref(fig:doe)\nDiseño de una curva de calibración con adición conocida para minimizar la incertidumbre\nPara evaluar estadísticamente si existe un efecto matriz debemos comparar la curva de calibración estándar (es decir, en solvente orgánico o en solución ácida) con la curva de adición conocida. Si las pendientes de ambas curvas son “iguales” podemos afirmar que no hay evidencia de efecto matriz tal como se muestra en la figura @ref(fig:sinefecto). De modo contrario, si las pendientes de ambas curvas difieren, entonces, existe un efecto matriz significativo, tal como lo indica la figura @ref(fig:conefecto):\nSin efecto matriz: calibración estándar v/s adición conocida\nCon efecto matriz: calibración estándar v/s adición conocida\n¡Excelente pregunta Tu(x3)!\nAunque hay varias aproximaciones para hacer esta comparación, en este post utilizaremos el Análisis de Covarianza (ANCOVA) y lo implementaremos, como no, en lenguaje R. La siguiente tabla muestra los datos de calibración de clorpirifos en vino por GC-NPD, tanto en solvente puro como mediante el método de adición conocida en la muestra de vino:\nTabla datos de calibración clorpirifos\nNote que en la caso de la calibración estándar, las unidades de concentración están expresadas como \\(\\mu\\)g de clorpirifos por mL de solvente. En cambio, en los datos de adición conocida están expresadas como \\(\\mu\\)g de clorpirifos añadidos en los mL de muestra original. Por lo tanto, \\(X = 0\\, \\mu\\text{g}/\\text{mL}_{\\text{vino}}\\) representa la muestra sin adición. La figura @ref(fig:mosa) muestra las curvas de calibración correspondientes.\nCurvas de calibración\nApliquemos, ahora, el análisis de covarianza para evaluar si existen diferencias significativas entre las pendientes.\nPrimero, ajustemos un modelo lineal para cada calibración:\n# Curva de calibración estándar\nx &lt;- c(0, 0.1, 0.2, 0.3, 0.5, 1.0)\ny &lt;- c(0, 80, 159, 245, 410, 795)\nfit.std &lt;- lm(y ~ x)\n\n# Curva de adición conocida\nx.add &lt;- c(0, 0.1, 0.2, 0.3, 0.4, 0.5)\ny.add &lt;- c(75, 159, 240, 328, 410, 498)\nfit.add &lt;- lm(y.add ~ x.add)\n\n# En R la expresión y ~ x significa 'y es modelado por x'\nA continuación se muestran los análisis estadísticos para cada curva:\nsummary(fit.std)\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n     1      2      3      4      5      6 \n-2.489 -2.206 -2.924  3.359  8.924 -4.664 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    2.489      3.420   0.728    0.507    \nx            797.176      7.105 112.193 3.78e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.751 on 4 degrees of freedom\nMultiple R-squared:  0.9997,    Adjusted R-squared:  0.9996 \nF-statistic: 1.259e+04 on 1 and 4 DF,  p-value: 3.785e-08\nsummary(fit.add)\n\n\nCall:\nlm(formula = y.add ~ x.add)\n\nResiduals:\n      1       2       3       4       5       6 \n 1.1429  0.6857 -2.7714  0.7714 -1.6857  1.8571 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   73.857      1.463   50.49 9.21e-07 ***\nx.add        844.571      4.832  174.79 6.43e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.021 on 4 degrees of freedom\nMultiple R-squared:  0.9999,    Adjusted R-squared:  0.9998 \nF-statistic: 3.055e+04 on 1 and 4 DF,  p-value: 6.426e-09\nLa pendiente de la curva de calibración estándar es 797 y la pendiente del método de adición es 845. ¿Es esta diferencia significativa? Esta es la pregunta que responde el ANCOVA. Para implementar este test en Rdebemos hacer una pequeña modificación a nuestra base de datos:\n# Consolidaremos los datos de calibración en una sola tabla llamada 'datos'\ndatos &lt;- data.frame(X = c(x, x.add), \n                    Y = c(y, y.add), \n                    Calibracion = c(rep('Estandar', 6), rep('Adicion', 6)))\nX\nY\nCalibracion\n\n\n\n\n0.0\n0\nEstandar\n\n\n0.1\n80\nEstandar\n\n\n0.2\n159\nEstandar\n\n\n0.3\n245\nEstandar\n\n\n0.5\n410\nEstandar\n\n\n1.0\n795\nEstandar\n\n\n0.0\n75\nAdicion\n\n\n0.1\n159\nAdicion\n\n\n0.2\n240\nAdicion\n\n\n0.3\n328\nAdicion\n\n\n0.4\n410\nAdicion\n\n\n0.5\n498\nAdicion\nUna vez consolidados los datos en una única tabla podemos aplicar el análisis de covarianza en R con los siguientes comandos de la librería car:\nlibrary(car)\n\nLoading required package: carData\n\n# Ajustamos un modelo con interceptos distintos y una pendiente para cada\n# calibración\n\nfit &lt;- lm(Y ~ X + Calibracion + X:Calibracion, data = datos)\nAnova(fit, type = 'II')\n\nAnova Table (Type II tests)\n\nResponse: Y\n              Sum Sq Df   F value    Pr(&gt;F)    \nX             540763  1 29108.930 1.558e-15 ***\nCalibracion    20535  1  1105.398 7.309e-10 ***\nX:Calibracion    310  1    16.699  0.003503 ** \nResiduals        149  8                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nDe la tabla se observa que el p-value de la comparación de las pendientes es \\(Pr(&gt;F) = 0.0035\\) el cual es menor a 0.05 (X:Calibracion), por lo tanto, la diferencia observada entre las pendientes es, desde el punto de vista estadístico, significativa. Esto implica que existe un efecto matriz que no está corregido por la calibración en solvente. En definitiva, para este tipo de muestra, sería apropiado utilizar el método de adición conocida para la determinación de clorpirifos en vino.\nAhora, esta conclusión debe ser complementada con el criterio químico y metrológico. Recuerde que la desventaja del método de adición conocida es que es necesario hacer la adición muestra a muestra. Lo que se concluye del ANCOVA está basado en un criterio puramente estadístico.\nBueno estimado lector, espero haya disfrutado este post.\nEspero sus comentarios. Nos vemos."
  },
  {
    "objectID": "post/como-detectar-efecto-matriz-metodo-analitico/index.html#bibliografía",
    "href": "post/como-detectar-efecto-matriz-metodo-analitico/index.html#bibliografía",
    "title": "¿Cómo detectar el efecto matriz en un método analítico?",
    "section": "Bibliografía",
    "text": "Bibliografía\nEllison SL, Thompson M. Standard additions: myth and reality (2008) Analyst 133(8):992-7."
  },
  {
    "objectID": "post/como-calcular-incertidumbre-calibracion/index.html",
    "href": "post/como-calcular-incertidumbre-calibracion/index.html",
    "title": "Cómo calcular la incertidumbre de una curva de calibración",
    "section": "",
    "text": "Ok, este es el segundo post. Advierto que aún está en rodaje… esto del copywriting no es nada fácil.\n\n¿Qué es y cómo estimar la incertidumbre de una curva de calibración?\n\nLa incertidumbre de calibración, en adelante \\(u(x_{0})\\), es aquella que se propaga cuando obtenemos la concentración de un mensurando al interpolar una señal instrumental (por ejemplo, absorbancia o área cromatográfica) en una curva de calibración. Básicamente, esta incertidumbre sólo da cuenta del error aleatorio del instrumento y no incopora la incertidumbre de los calibrantes, al menos cuando se utiliza el modelo de calibración clásico:\n\\[\\begin{equation}\n  y = \\beta_{0} + \\beta_{1} x + \\epsilon\n    (\\#eq:lin)\n\\end{equation}\\]\ndonde \\(y\\) es la respuesta instrumental, \\(\\beta_{0}\\) es el intercepto, \\(\\beta_{1}\\) es la pendiente y \\(\\epsilon\\) es un error aleatorio Normal que tiene media \\(\\mu_{\\epsilon} = 0\\) y varianza \\(\\sigma_{y/x}^2\\). Note de la ecuación @ref(eq:lin) que lo único aleatorio es \\(\\epsilon\\), por lo tanto, el intercepto \\(\\beta_{0}\\) y la pendiente \\(\\beta_{1}\\) son fijos. Lo que hacemos cuando aplicamos, por ejemplo, el método de los mínimos cuadrados es estimar estos parámetros y, en estadística, todas las estimaciones tienen un error asociado.\nA partir de la ecuación @ref(eq:lin) obtenemos la concentración de una muestra problema \\(x_{0}\\) cuya señal instrumental es \\(y_{0}\\):\n\\[\\begin{equation}\n  x_{0} = \\frac{y_{0} - \\beta_{0}}{\\beta_{1}}\n    (\\#eq:x0)\n\\end{equation}\\]\nSi aplicáramos la guía GUM para obtener la incertidumbre estándar de calibración \\(u(x_{0})\\) sería bastante latoso-engorroso, pues hay unas covarianzas no muy amistosas entre pendiente e intercepto. Afortunadamente \\(u(x_{0})\\) puede aproximarse muy bien a través de la ecuación @ref(eq:ux0):\n\\[\\begin{equation}\n  u(x_{0}) = \\frac{\\sigma_{y/x}}{\\beta_{1}}\n  \\sqrt{\\frac{1}{n} + \\frac{1}{m_{0}} + \\frac{(x_{0} - \\overline{x})^2}\n  {\\sum_{i}^{n} (x_{i} - \\overline{x})^2}}\n    (\\#eq:ux0)\n\\end{equation}\\]\nVamos viendo dijo el ciego:\n\n\\(\\sigma_{y/x}\\) es la desviación estándar del error aleatorio \\(\\epsilon\\)\n\\(n\\) es el número de calibrantes independientes (esto da para otro post)\n\\(m_{0}\\) es el número de replicado independientes de la muestra problema\n\\(\\overline{x}\\) es el promedio de la concentraciones de los calibrantes\n\nEsta incertidumbre se puede observar en la figura @ref(fig:banda), la cual fue obtenida mediante simulación en lenguaje R:\n\nset.seed(123)\nx &lt;- 1:10\ny &lt;- 2 + 5*x + 10*rnorm(length(x), 0, 1)\nd &lt;- data.frame(x, y)\n\nlibrary(ggplot2)\n\nggplot(d, aes(x = x, y = y)) +\n  geom_smooth(method = 'lm') \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nIncertidumbre de calibración\n\n\n\n\n¿Dónde se obtiene la menor incertidumbre de calibración? … ¡Correcto!\n\nEn el centro de la curva se minimiza la incertidumbre de calibración\n\nSi obervamos la ecuación @ref(eq:ux0) podemos minimizar \\(u(x_{0})\\):\n\nAumentando \\(n\\) el número de calibrantes.\nAumentando \\(m_{0}\\)\nDiseñando la curva de calibración de modo que \\(x_{0} = \\bar{x}\\)\nAunque no tan “evidente”, maximizando \\(\\sum_{i}^{n} (x_{i} - \\overline{x})^2\\), es decir, utilizando todo el rango lineal (Nota mental: otro post)\n\n\nAplicación a un caso “real”\nLa tabla @ref(tab:tabla) muestra los datos de una curva de calibración para la determinación de cobre en mineral por AAS, la figura @ref(fig:cal) describe el gráfico de calibración:\n{{% callout note %}} Alguien capo en HTML/CSS que me ayude a poner tabla enfrentada con figura en 2 columnas por favor… y que Dios se lo pague. {{% /callout %}}\n\n\n\nCurva de Calibración Cu\n\n\nCu [ppm]\nUA\n\n\n\n\n1\n0.0344\n\n\n2\n0.0777\n\n\n3\n0.1356\n\n\n4\n0.1607\n\n\n5\n0.2013\n\n\n6\n0.2572\n\n\n7\n0.2846\n\n\n8\n0.3073\n\n\n9\n0.3531\n\n\n10\n0.3955\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nCurva de calibración\n\n\n\n\nOk, hay varias formas de implementar los cálculos de incertidumbre de calibración de la ecuación @ref(eq:ux0). Podríamos utilizar Excel para obtener cada uno de los términos, pero eso lo ilustraremos en otro post. En esta oportunidad utilizaremos el software R. Este software posee varias librerías o packages especializados en el cálculo de incertidumbre en química analítica, por ejemplo: metRology y chemCal. En este post utilizaremos el segundo, pues entrega en forma directa el cálculo de la incertidumbre de calibración:\n{{% callout warning %}} Si no tienes instalado el package chemCal utiliza el comando install.packages('chemCal'). Una vez instalado procede con el siguiente código.{{% /callout %}}\n\n# Creación del modelo de calibración lineal, al que llamaremos fit.lin \n# (En otro post se profundizará sobre otros modelos de calibración en R)\n\nfit.lin &lt;- lm(y ~ x, data = d)\n\n# Simular un valor de respuesta de la muestra problema, es decir, y0.\n# Sólo por conveniencia simularemos que y0 = 0.200 UA, es decir, más o menos\n# en el centro de la curva:\n\ny0 &lt;- 0.200\n\n# Cargar la librería chemCal con el comando 'library':\n\nlibrary(chemCal)\n\n# Calcular la concentración de la muestra problema, x0, a partir de su señal\n# instrumental y0, junto con la incertidumbre estándar de calibración u(x0) e\n# incertidumbre expandida U(x0) con un 95% de confianza:\n\ninverse.predict(fit.lin, newdata = y0)\n\n$Prediction\n[1] 4.970492\n\n$`Standard Error`\n[1] 0.2618792\n\n$Confidence\n[1] 0.6038946\n\n$`Confidence Limits`\n[1] 4.366598 5.574387\n\n\nBien, interpretemos la salida:\n\n$Prediction es la concentración de la muestra problema en [ppm]\n$Standard Error es la incertidumbre estándar de calibración, es decir, la que se obtiene de la ecuación @ref(eq:ux0) expresada, obviamente, en las mismas unidades que los calibrantes [ppm].\n$Confidence es la incertidumbre expandida de calibración \\(U(x0)\\), es decir, \\(U(x0) = k\\cdot u(x0)\\) donde \\(k\\) es el factor de cobertura con el cual se obtiene un intervalo de incertidumbre con cierta confianza (habitualmente 95%). Más de esto en otro post.\n$Confidence Limits es simplemente \\(x0 \\pm U(x0)\\), es decir, \\(5 \\pm 0.6\\) ppm (ojo con las cifras significativas… ahí va otro post).\n\nAlgunas consideraciones importantes:\n\nEsta incertidumbre de calibración \\(u(x0)\\) NO incorpora la incertidumbre de los calibrantes, sólo es un reflejo del error aleatorio instrumental. Punto. Es decir, asume que los calibrantes no tienen incertidumbre… lo cual todos los químicos sabemos que es ¡Farso, farso!\nSi Ud. requiere incorporar también la incertidumbre de los calibrantes, debe utilizar otro modelo lineal de calibración denominado: modelo lineal con error en ambos ejes (otro post).\nYa que esta incertidumbre sólo refleja el componente aleatorio de la calibración, no están incorporados los errores sistemáticos de la preparación de estándares: error en el aforo, no considerar la pureza del reactivo, etc. (Nota mental: otro post… ¿cuántos van?).\nSi, además, el método analítico incluye pesada de la muestra, digestión o extracción, aforo final, factor de dilución, etc. Ud.debe, mediante los mandamientos de la guía GUM, combinar todas estas fuentes de incertidumbre con la de calibración \\(u(x0)\\).\nEn el fondo, como se asume que los calibrantes no tienen incertidumbre, \\(u(x0)\\) reflejaría el comportamiento aleatorio del instrumento cuando se lee la curva “muchas” veces, siempre con los mismos calibrantes. En cada oportunidad, se obtendría una pendiente e intercepto distintos (debido a al error aleatorio \\(\\epsilon\\)), por lo tanto, también una concentración \\(x0\\) distinta cada vez.\n\n{{% callout warning %}} Si está interesad@ en estimar la incertidumbre de una calibración no lineal, lo discutimos paso a paso en el siguiente link. {{% /callout %}}\nBueno espero que este post, en rodaje áun, haya sido de su agrado. Como siempre, siéntase libre de criticarlo. Nos vemos.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analytical",
    "section": "",
    "text": "Finley Malloc is the Chief Data Scientist at Wengo Analytics. When not innovating on data platforms, Finley enjoys spending time unicycling and playing with her pet iguana."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Analytical",
    "section": "Education",
    "text": "Education\nUniversity of California, San Diego | San Diego, CA PhD in Mathematics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Analytical",
    "section": "Experience",
    "text": "Experience\nWengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Spet 2012 - April 2018"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "post 1\n\n\n\n\n\nEn el siguiente nivel podemos\n\n\n\n\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\npost 2\n\n\n\n\n\n\n\n\n\n\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\n¿Cuántos laboratorios de ensayo acreditados por el INN hay en Chile? Versión 2023\n\n\n\n\n\n\n\n\n\n\n\n\n4 min\n\n\n\n\n\n\n  \n\n\n\n\nIncertidumbre de una calibración no lineal\n\n\nMétodo GUM y Monte Carlo – Norma ISO 8466:2\n\n\n\n\n\n\n\n\n\n25 min\n\n\n\n\n\n\n  \n\n\n\n\n¿Cómo detectar el efecto matriz en un método analítico?\n\n\n\n\n\n\n\n\n\n\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nPrueba de linealidad de una curva de calibración en Excel… Sí ¡En Excel!\n\n\n\n\n\n\n\n\n\n\n\n\n4 min\n\n\n\n\n\n\n  \n\n\n\n\nValidación de los cálculos de incertidumbre en química analítica con el método Monte Carlo. Parte II\n\n\n\n\n\n\n\n\n\n\n\n\n15 min\n\n\n\n\n\n\n  \n\n\n\n\nValidación de los cálculos de incertidumbre en química analítica con el método Monte Carlo. Parte I\n\n\n\n\n\n\n\n\n\n\n\n\n16 min\n\n\n\n\n\n\n  \n\n\n\n\n¡Mis datos no son normales! ¿Qué hago?…Cálmese, nunca lo fueron… ni lo serán\n\n\n\n\n\n\n\n\n\n\n\n\n11 min\n\n\n\n\n\n\n  \n\n\n\n\n¿Cuál es la máxima diferencia tolerable entre duplicados de análisis?\n\n\n\n\n\n\n\n\n\n\n\n\n13 min\n\n\n\n\n\n\n  \n\n\n\n\n¿Cómo demuestro que mi curva de calibración es lineal?\n\n\n\n\n\n\n\n\n\n\n\n\n16 min\n\n\n\n\n\n\n  \n\n\n\n\nCómo calcular la incertidumbre de una curva de calibración\n\n\n\n\n\n\n\n\n\n\n\n\n6 min\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "post/acreditados-inn-2023/index.html",
    "href": "post/acreditados-inn-2023/index.html",
    "title": "¿Cuántos laboratorios de ensayo acreditados por el INN hay en Chile? Versión 2023",
    "section": "",
    "text": "Hace ya casi 2 años publiqué un post acerca de cuántos laboratorios de ensayos acreditados existían en Chile el 2021. La publicación generó airadas reacciones, sin embargo, se abrió un interesante debate (esa es la idea).\nEs tiempo de actualizar ese análisis con los datos de 2023. En esta oportunidad llevaremos a cabo el análisis paso a paso en R bajo el concepto de Reproducible Research\nNota: Considerar que algunas razones sociales podrían tener varios laboratorios/alcances acreditados, por lo tanto, este gráfico en realidad cuenta el número de acreditaciones. (¿Clickbait?)\nLa versión de este post es semi-automática, es decir, algunas operaciones serán hechas a mano. Podríamos aplicar web scraping y bajar los datos directamente desde la página web del INN, pero eso qudará para otro post (lo intuye bien querid@ lector@… cuando yo aprenda a hacerlo.)"
  },
  {
    "objectID": "post/acreditados-inn-2023/index.html#dónde-están-los-datos-de-laboratorios-acreditados-por-el-inn",
    "href": "post/acreditados-inn-2023/index.html#dónde-están-los-datos-de-laboratorios-acreditados-por-el-inn",
    "title": "¿Cuántos laboratorios de ensayo acreditados por el INN hay en Chile? Versión 2023",
    "section": "¿Dónde están los datos de laboratorios acreditados por el INN?",
    "text": "¿Dónde están los datos de laboratorios acreditados por el INN?\nBueno, lo primero es dirigirnos al siguiente link para bajar los datos desde la página del INN (son datos públicos por si acaso):\nDirectorio de Acreditados\n\nEn el campo Tipo de ESquema de Acreditación seleccionamos Laboratorios de ensayo:\n\nPresionamos Buscar y obtenderemos el listado completo (incluyendo los laboratorios suspendidos):\n\nLamentablemente, el sitio no tiene ninguna opción para bajar los datos en Excel u otro formato, así que tendremos que hacerlo a la antigua:\n\nBotón derecho y se abrirá el siguiente menú:\n\n\n\nElija Guardar Como y en tipo seleccione Página web (completa) y guárdelo con el nombre acreditados.html (el nombre da igual)\n\n\nListo, hemos bajado los datos y ahora debemos limpiarlos ya que incluso se descargaron los íconos de los certificado en pdf. Tenemos que dejar la tabla limpia para el análisis en R (o para cualquier otro software)"
  },
  {
    "objectID": "post/acreditados-inn-2023/index.html#limpieza-de-la-base-de-datos-en-excel",
    "href": "post/acreditados-inn-2023/index.html#limpieza-de-la-base-de-datos-en-excel",
    "title": "¿Cuántos laboratorios de ensayo acreditados por el INN hay en Chile? Versión 2023",
    "section": "Limpieza de la base de datos en Excel",
    "text": "Limpieza de la base de datos en Excel\nHaremos la limpieza de datos en Excel.\n\nAbra Excel\nAhora abra el archivo archivados.html que guardó (sí, Excel puede abrir este tipo de archivos) y obtendrá algo similar a esto:\n\n\nEl objetivo es llegar a una hoja de Excel plana:\n\n\nSeleccionemos todos los datos inlcuyendo los encabezados de las columnas (N, N Certi, etc), copiar y pegar en una nueva hoja sólo como datos, es decir, nos ubicamos en la celda A1 de la hoja nueva, presionamos botón derecho y seleccionamos Valores (V):\n\n\nY obtendremos lo siguiente:\n\n\nEliminamos la columna B:\n\n\n\nHemos obtenido la tabla que buscábamos:\n\n\n\nLo único que nos falta es modificar un poco los encabezados para eliminar acentos, espacios en blanco, etc. Para que Ud. pueda reproducir este análisis cambie los encabezados por los siguientes:\n\n\n\n¡Listo! hemos limpiado la base de datos, la cual debe lucir más o menos así en el Excel:\n\n\n\nCambiemos el nombre la hoja a datos:\n\n\n\nPor último guardar el libro Excel con el nombre acreditados.xlsx"
  },
  {
    "objectID": "post/acreditados-inn-2023/index.html#análisis-estadístico-en-r",
    "href": "post/acreditados-inn-2023/index.html#análisis-estadístico-en-r",
    "title": "¿Cuántos laboratorios de ensayo acreditados por el INN hay en Chile? Versión 2023",
    "section": "Análisis estadístico en R",
    "text": "Análisis estadístico en R\nAbrimos el software RStudio y generamos un nuevo script:\n\nGuardamos el script con el nombre acreditados.R en el mismo directorio que guardamos la base de datos limpia acreditados.xlsx\nLos siguientes comandos importan la base de datos del INN desde el Excel hasta R:\n\nlibrary(readxl)\nacreditados &lt;- read_excel('acreditados.xlsx', sheet = 'datos')\n\nLa importación ha sido exitosa si observa la siguiente tabla con el comando head()\n\nhead(acreditados)\n\n# A tibble: 6 × 7\n      N N_certificado Organización      Tipo_de_OEC Area  Observaciones Telefono\n  &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;   \n1     1 LE 633        Universidad Aust… Laboratori… Bioe… &lt;NA&gt;          (56 65)…\n2     2 LE 800        Universidad de C… Laboratori… Bioe… &lt;NA&gt;          (56) 22…\n3     3 LE 893        Universidad de C… Laboratori… Bioe… &lt;NA&gt;          (56 65)…\n4     4 LE 1287       Secretaria Regio… Laboratori… Bioe… &lt;NA&gt;          (56 61)…\n5     5 LE 1450       TAAG Genetics S.… Laboratori… Biol… &lt;NA&gt;          (56) 22…\n6     6 LE 1279       Universidad de L… Laboratori… Bioq… &lt;NA&gt;          (56 64)…\n\n\nAhora haremos el gráfico de barras el cual indica el número de laboratorios de ensayo acreditados por el INN al 03 de julio de 2023 clasificados por Area. Por una cuestión de espacios sólo se muestran aquellas áreas con más de 10 laboratorios acreditados:\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(magrittr)\n\nacreditados &lt;- read_excel('acreditados.xlsx', sheet = 'datos')\n\ntabla &lt;- acreditados %&gt;% \n  group_by(Area) %&gt;% \n  summarise(n = n())\n\n# Número de acreditaciones suspendidas\nn.suspendidos &lt;- acreditados %&gt;% \n  filter(!is.na(Observaciones)) %&gt;% \n  count()\n\n# Número de acreditaciones totales (incluyendo las suspendidas)\nn.total &lt;- acreditados %&gt;% \n  count()\n\n\nggplot(tabla %&gt;% filter(n &gt;= 10), aes(x = reorder(Area, n), y = n, label = n)) +\n  geom_bar(stat = \"identity\", fill = 'blue', alpha = 0.7) +\n  ylab('N° de laboratorios de ensayo') +\n  xlab('Área') +\n  labs(title = paste('Acreditaciones en Chile por INN bajo ISO 17025 por área N =', \n                     n.total),\n       subtitle = paste(\"Incluye \", n.suspendidos, \"suspendidos. Sólo se muestran n &gt; 10\"),\n       caption = \"Fuente: https://acreditacion.innonline.cl/\") +\n  theme_bw() +\n  geom_text(size=5,hjust=1.5, col = 'white') +\n  coord_flip()\n\n\n\n\n¡Listo! En un siguiente paso podríamos desagregar por Organización, de tal manera de atribuir las acreditaciones clasificando por razón social ¿Le parece estimad@ lector@?\nSaludos"
  },
  {
    "objectID": "post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/index.html",
    "href": "post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/index.html",
    "title": "¿Cómo demuestro que mi curva de calibración es lineal?",
    "section": "",
    "text": "En este post intentaremos derribar el mito del coeficiente de correlación con “muchos” 9’s como prueba de linealidad. Además, presentaremos dos test formales para evaluar el modelo de calibración lineal en química analítica."
  },
  {
    "objectID": "post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/index.html#test-de-carencia-de-ajuste-lack-of-fit-iso-11095",
    "href": "post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/index.html#test-de-carencia-de-ajuste-lack-of-fit-iso-11095",
    "title": "¿Cómo demuestro que mi curva de calibración es lineal?",
    "section": "Test de carencia de ajuste (Lack of fit) ISO 11095",
    "text": "Test de carencia de ajuste (Lack of fit) ISO 11095\nEste test está basado en comparar dos estimadores del error aleatorio:\n\nError puro o experimental\nError de carencia de ajuste o lack of fit\n\nEs decir, necesitamos un estimador del error aleatorio totalmente independiente del error del modelo de calibración que queremos ajustar. Para estimar este error, la prueba de carencia de ajuste exige que hagamos replicados de cada uno de los calibrantes.\n\nPero tienen que ser replicados verdaderos. No es válido inyectar varias veces el mismo estándar en el equipo. Prepárelos independientemente.\n\nSi los dos estimadores del error aleatorio son similares, entonces el modelo de calibración que acabamos de ajustar es adecuado para modelar los datos experimentales. ¿Cuán similares tienen que ser? Lo probaremos con un test F. Los detalles algebraicos son latosos-engorrosos y pueden ser consultados en la bibliografía. Sólo indicaremos cómo hacer este test de linealidad en lenguaje R, como no. (¿Y en Excel cuándo?)\nLa tabla @ref(tab:lof) muestra los datos de calibración de cloranfenicol en matriz leche obtenida por GC/MS-NCI (Gas Chromatography/Mass Spectrometry - Negative Chemical Ionization …¡Qué tiempos aquellos!). Note que cada nivel de calibración está preparado en triplicado totalizando n = 15 calibrantes independientes. La figura @ref(fig:lofplot) muestra la curva de calibración.\n\n\n\nCalibración CAF [ug/kg]\n\n\nReplicado\n0\n0.25\n0.5\n0.75\n1\n\n\n\n\n1\n88\n7714\n15292\n22611\n30280\n\n\n2\n154\n7726\n14947\n22945\n30222\n\n\n3\n512\n8043\n15063\n22772\n30089\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nCurva de calibración CAF. Test de carencia de ajuste\n\n\n\n\nLa tabla @ref(tab:lofcal) muestra el análisis estadístico de esta calibración:\n\n\n\n\n\n\nPendiente e intercepto de calibración\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n262\n78\n3\n0.005\n\n\nx.caf\n29936\n127\n236\n0.000\n\n\n\n\n\n\n\nPor ahora no nos detendremos en el análisis de la tabla (eso quedará para otro post). Haremos directamente el Test de Carencia de Ajuste (lack of fit) en R el cual se muestra en la tabla @ref(tab:loftest):\n\nlibrary(olsrr) # Cargamos el package 'olsrr' para aplicar el test lack-of-fit\nols_pure_error_anova(fit.cal)\n\n\n\nLack of Fit F Test \n------------------\nResponse :   y.caf \nPredictor:   x.caf \n\n                           Analysis of Variance Table                             \n---------------------------------------------------------------------------------\n                DF       Sum Sq           Mean Sq        F Value        Pr(&gt;F)    \n---------------------------------------------------------------------------------\nx.caf            1    1680303154.42    1680303154.42     54131.47    6.444664e-25 \nResidual        13        392485.57         30191.20                              \n Lack of fit     3         82074.03         27358.01    0.8813464       0.4832262 \n Pure Error     10        310411.54         31041.15                              \n---------------------------------------------------------------------------------\n\n\nOk, para interpretar el test de carencia de ajuste nos fijaremos en la fila que dice “Lack of fit” y en el p-value del test, el cual aparece bajo la columna Pr(&gt;F) = 0.483. La interpretación tradicional de una prueba estadística diría algo más o menos así:\n\nDado que el p-value \\(&gt; 0.05\\), entonces, no hay evidencias en contra de la hipótesis nula. El modelo lineal es adecuado para modelar los datos de calibración.\n\nAlgunas consideraciones:\n\n¿Dice en alguna parte que el modelo de calibración es lineal? Póngalo de wallpaper en su pantalla: NO.\nLo único que se puede extraer como conclusión es que el modelo lineal es adecuado, es razonable para modelar los datos de calibración. Nada más.\nExisten infinitos modelos de calibración que podrían ser idóneos, este test nos dice si el que hemos elegido para modelar los datos es razonable/adecuado, sin embargo, no nos dice que sea “EL” modelo perfecto.\n¿Qué tiene de especial el famoso 0,05? Absolutamente NADA. ¿Qué concluiría Ud. si el p-value fuese 0,04999 ó 0,05001? Sería un test totalmente inconcluyente.\nLamentablemente, esto es una dicotomía perversa que desde hace mucho tiempo ha sido objeto de varias críticas. Le invito a leer las siguientes referencias sobre la interpretación y controversia de los p-values en ciencia:\n\n\nRonald L. Wasserstein & Nicole A. Lazar (2016) The ASA’s Statement on p-Values: Context, Process, and Purpose The American Statistician Volume 70, 2016 - Issue 2 link\nM.Baker Statisticians issue warning over misuse of P values Nature 531, 151 (10 March 2016) link\nSingh Chawla D. Big names in statistics want to shake up much-maligned P value. Nature. 2017 Jul 26;548(7665):16-17 link\n\n\n“The p-value was never intended to be a substitute for scientific reasoning” Ron Wasserstein, Director Ejecutivo de la Asociación Americana de Estadística ASA."
  },
  {
    "objectID": "post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/index.html#test-de-mandel-iso-8466-1",
    "href": "post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/index.html#test-de-mandel-iso-8466-1",
    "title": "¿Cómo demuestro que mi curva de calibración es lineal?",
    "section": "Test de Mandel ISO 8466-1",
    "text": "Test de Mandel ISO 8466-1\nEsta prueba estadística es bastante sencilla y está basada en la comparación entre el modelo de calibración lineal y un modelo alternativo. Por lo tanto, no es una prueba absoluta, sino relativa a la elección del modelo alternativo. Require al menos n = 6 calibrantes (sin replicado).\nEn general, el test de Mandel utiliza el modelo de calibración cuadrático para compararlo con el modelo lineal:\n\\[ y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^2\\]\nLos detalles estadísticos pueden consultarse en la bibliografía.\n\nPrimero calcule la suma de cuadrados de los residuos \\(SS_{r}\\) para cada uno de los modelos de acuerdo a la siguiente expresión:\n\n\\[\\begin{equation}\n  SS_{r} = \\sum_{i = 1}^{n} e_{i}^2\n    (\\#eq:res)\n\\end{equation}\\]\nDonde el residuo \\(e = y - \\hat{y}\\). \\(y\\) es la respuesta instrumental observada o experimental (áreas, absorbancias, etc.); \\(\\hat{y}\\), es la respuesta instrumental que predice el modelo (lineal o o cuadrático) en cada una de las concentraciones de los calibrantes. Si observa la ecuación @ref(eq:res) el concepto de residuo es el mismo para cualquier modelo de calibración, es decir, ¿cuánto difiere lo que se observa experimentalmente con lo que predice el modelo?\nUn buen modelo tiene residuos pequeños. Un residuo grande para cierto de nivel de concentración implica que existe una gran diferencia entre lo observado y lo que predice el modelo, por lo tanto, nos guiará (en otro post) a detectar posibles valores anómalos o outliers.\n\nCalcule la diferencia entre ambas sumas de cuadrado de los residuos, la del modelo no lineal \\(SS_{r}^{no-lin}\\) y la correspondiente al modelo lineal \\(SS_{r}^{lin}\\):\n\n\\[\\begin{equation}\n  D = SS_{r}^{no-lin} -  SS_{r}^{lin}\n  (\\#eq:D)\n\\end{equation}\\]\n\nEstime el estadístico F calculado:\n\n\\[\\begin{equation}\n  F = \\frac{D}{SS_{r}^{no-lin}/(n - 3)}\n  (\\#eq:D)\n\\end{equation}\\]\n\nObtenga el F de tabla para 1 grado de libertad en el numerador y \\(n - 3\\) para el denominador\nCompare el \\(F_{calculado}\\) con el \\(F_{tabla}\\) y decida en base a la siguiente regla:\n\n\nSi \\(F_{calculado} &lt; F_{tabla}\\) se concluye que no hay evidencias en contra de la hipótesis nula de linealidad del modelo. ¿Quiere decir que el modelo de calibración es exactamente lineal? Ya sabemos que NO. Rigen las mismas consideraciones que que notamos en el test de carencia de ajuste.\nSi \\(F_{calculado} &gt; F_{tabla}\\) se rechaza la hipótesis nula de linealidad del modelo. Los datos no son consistentes con la hipótesis. Y aquí se abre una caja de Pandora, pues esta conclusión también tiene muchas consideraciones estadísticas que se deben tener en cuenta para interpretarla apropiadamente las cuales, por ahora, no profundizaremos.\n\nLos pasos recién descritos son para llevar a cabo el Test de Mandel “a mano”, afortunadamente los softwares estadísticos como R y Excel (sí ¡Excel!) tienen incorporada esta prueba estadística de linealidad. Veamos un ejemplo.\nLa tabla @ref(tab:datamandel) muestra los datos de calibración de Cu por AAS; la figura @ref(fig:plotmandel), la curva de calibración:\n\n\n\nCurva de Calibración Cu\n\n\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n\n\n\n\n-0.007\n0.071\n0.146\n0.212\n0.274\n0.334\n0.385\n0.43\n0.473\n0.511\n0.546\n\n\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nCurva de calibración Cu\n\n\n\n\nA simple vista se observa la no linealidad de la curva de calibración. Veamos que nos dice el Test de Mandel en la siguiente tabla ANOVA:\n\n# d: corresponde al data frame de los datos de calibración\n\nfit.lin &lt;- lm(y ~ x, data = d) # Ajuste lineal.\nfit.nolin &lt;- lm(y ~ x + I(x^2), data = d) # Ajuste no lineal cuadrático\n\nanova(fit.lin, fit.nolin)\n\nAnalysis of Variance Table\n\nModel 1: y ~ x\nModel 2: y ~ x + I(x^2)\n  Res.Df       RSS Df Sum of Sq      F    Pr(&gt;F)    \n1      9 0.0054816                                  \n2      8 0.0000186  1  0.005463 2351.1 3.621e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEn la tabla el valor \\(F = 2351\\) corresponde al \\(F_{calculado}\\) el cual es comparado internamente con el \\(F_{tabla}\\) entregando, finalmente, el p-value \\(Pr(&gt;F) = 3.62e-11\\). La evidencia en contra de la hipótesis nula de linealidad es abrumadora."
  },
  {
    "objectID": "post/cual-es-la-maxima-diferencia-tolerable-entre-duplicados-de-analisis/index.html",
    "href": "post/cual-es-la-maxima-diferencia-tolerable-entre-duplicados-de-analisis/index.html",
    "title": "¿Cuál es la máxima diferencia tolerable entre duplicados de análisis?",
    "section": "",
    "text": "Un día cualquiera en un laboratorio que aún no establece criterios de aceptación de precisión:\n\nDuplicado 1 = 25.56 % Cu\nDuplicado 2 = 25.66 % Cu\nDiferencia = 0.10 % Cu\n\nLa diferencia observada ¿es aceptable para el laboratorio?\nPara responder a esta pregunta debemos considerar varias cosas:\n\n¿Los duplicados fueron realizados en condiciones de repetibilidad o reproducibilidad?\n¿Existe alguna normativa al respecto que se deba cumplir?\n¿Cuál es la metodología analítica? No es lo mismo determinar Cu en concentrado de cobre por electrogravimetría (método primario) que por Fluorescencia de Rayos X.\n¿Cuál es la incertidumbre del método analítico?\n¿Existe algún acuerdo a nivel comercial sobre estas diferencias?\n\nPara abordar este problema tendremos que hace la suposición que los duplicados fueron obtenidos en condiciones de repetibilidad, es decir: mismo analista, mismo día, mismo instrumento, etc. Bajo esta premisa hay varias formas de estimar la máxima diferencia tolerable entre duplicados de análisis.\nNota: En realidad, los conceptos que mostraremos a continuación son completamente análogos para estimar la máxima diferencia tolerable en condiciones de reproducibilidad. Sin embargo, dedicaremos otro post a ese tema específico.\nEl concepto estadístico clave para establecer la tolerancia entre duplicados es el límite de repetibilidad \\(r\\).\n\nLímite de repetibilidad \\(r\\) ISO 5725\nLa guía ISO 5725 define el límite de repetibilidad \\(r\\) de la siguiente manera:\n\\[\nr = 2.8\\cdot s_{r}\n\\] y corresponde a la máxima diferencia, en valor absoluto, que puede tolerarse entre duplicados de análisis, obtenidos bajo condiciones de repetibilidad con un 95% de confianza. Veamos:\n\n\\(s_{r}\\) es la desviación estándar de repetibilidad, la cual da cuenta de la dispersión de las diferencias entre duplicados. Ya explicaremos cómo calcular este parámetro.\nEl factor 2.8: aquí les exijo una prueba de fe mis hermanos, me tienen que creer porque si quieren la demostración, aumentaría mucho la viscosidad de este post . A grosso modo, el factor 2.8 tiene que ver con el 95% de confianza, nos indica que cuando se establece la máxima diferencia tolerable, está permitido que el 5% de los duplicados estén fuera del límite \\(r\\), y aún el sistema analítico se encontraría bajo Control Estadístico.\n\n\n\n¿Cómo obtenemos la precisión de repetibilidad \\(s_{r}\\)?\nExisten varios métodos estadísticos para abordar la estimación de la desviación estándar de repetibililidad \\(s_{r}\\), sin embargo, en este post nos enfocaremos en los dos más utilizados en química analítica:\n\nEstimación basada en el registro histórico de duplicados de análisis.\nLa estimación mediante estudios de precisión siguiendo las directrices de la guía ISO 5725.\n\nNo describiremos todos los detalles de cada uno de los diseños experimentales expuestos en estas guías, más bien, ejemplificaremos el cálculo de la desviación estándar de repetibilidad \\(s_{r}\\):\n\n\nMétodo de estimación en base a datos históricos de duplicados\nObviamente necesitamos crear una base de datos con los registros de análisis de muestras en duplicados en condiciones de repetibilidad. Estas muestras pueden corresponder a muestras de clientes, materiales de referencia primarios o secundarios, muestras control, etc. Lo importante es que ambos duplicados cumplan con las condiciones de repetibilidad. La tabla @ref(tab:bdsr) es un ejemplo de una base de datos a utilizar en este método:\n\n\n\nBase de datos histórica de duplicados (sólo los primeros 6 datos)\n\n\nID\nDuplicado 1\nDuplicado 2\n\n\n\n\nQAQC-01\n30.79\n30.54\n\n\nQAQC-02\n31.89\n32.04\n\n\nQAQC-03\n31.28\n31.32\n\n\nQAQC-04\n31.30\n30.89\n\n\nQAQC-05\n30.70\n30.66\n\n\nQAQC-06\n30.86\n30.69\n\n\n\n\n\n\n\nPuede descargar esta base de datos desde este link. Y ahora la pregunta del millón: ¿Cuántas muestras en duplicado necesito? Si bien es posible obtener un cálculo “exacto” del número de muestras \\(n\\), esto está fuera del alcance de este post. Sin embargo, podemos decir que \\(n &gt; 25\\) es un número inicial adecuado.\nUna vez construida la base de datos, se puede obtener una estimación de \\(s_{r}\\) mediante la ecuación @ref(eq:srdup):\n\\[\\begin{equation}\n  s_{r} = \\sqrt{\\frac{\\sum_{i = 1}^{n} (x_{i1} - x_{i2})^2}{2n}}\n  (\\#eq:srdup)\n\\end{equation}\\]\nEsta ecuación puede ser fácilmente implementada en Excel pero en este post, como no, haremos los cálculos en lenguaje R. Pero antes, observe la figura @ref(fig:dup) la cual muestra un gráfico de dispersión entre Duplicado 1 (\\(X\\)) y Duplicado 2 (\\(Y\\)). En este caso el orden es irrelevante. Si ajustáramos un modelo lineal entre ambas variables ¿Qué valores de pendiente e intercepto deberíamos obtener?\n\n\n\n\n\nGráfico de dispersión entre duplicados\n\n\n\n\n\n¡Correcto! Pendiente \\(\\beta_{1} = 1\\) e intercepto \\(\\beta_{0} = 0\\). La línea roja representa esta recta teórica. Note también que la dispersión de los datos es constante en todo el rango de concentración, propiedad denominada Homocedasticidad.\n\nEsta propiedad es deseable, sin embargo, no todos los sistemas analíticos la poseen. En sí misma no es una problema, sin embargo, si la varibilidad de los duplicados aumenta con la concentración (heterocedasticidad) tendremos que modelar esta variabilidad en función de la concentración en forma explícita o segmentar el rango, lo cual veremos en otro post.\nTambién advierta la presencia de datos alejados de la diagonal, es decir, diferencias entre duplicados grandes. ¿Qué hacemos con ellos?¿Los mantenemos o los eliminamos?\nSi los eliminamos, y realmente reflejaran la variabilidad del método, entonces subestimaríamos la máxima diferencia tolerable entre duplicados, aumentando la frecuencia de alertas de duplicados no conformes (nos ponemos la soga al cuello solitos). Si los mantenemos, y realmente fueron errores puntuales de medición, sobreestimaríamos la tolerancia y la carta control sería de poca utilidad (mágicamente todos los datos caerían siempre dentro del los límites). Este tema lo abordaremos en otro post (llevo una lista).\nComo dato “anecdótico” en las operaciones de trading en el mercado mundial de concentrado de cobre, la máxima diferencia tolerable entre resultados de distintos laboratorios (a.k.a exportador v/s importador) es 0,20 % Cu. Si la diferencia supera este límite, ambos negociadores se van a un arbitraje (multiplique 0,2 % Cu por la millones de toneladas que se transan en el mercado…a \\(X\\) US/libra no es un asunto trivial).\nUtilizando los datos históricos estimamos una desviación estándar de repetibilidad de \\(s_{r} = 0.2\\) % Cu. Por lo tanto, el límite de repetibilidad es obtenido de la ecuación @ref(eq:limr):\n\\[\\begin{eqnarray}\n  r &=& 2.8\\cdot s_{r} \\\\\n  r &=& 2.8\\cdot 0.2 \\\\\n  r &=& 0.57\\, \\text{% Cu}\n  (\\#eq:limr)\n\\end{eqnarray}\\]\n\nInterpretación: La máxima diferencia tolerable, en valor absoluto, entre duplicados de análisis en condiciones de repetibilidad es \\(r = 0.57\\) % Cu.\n\nEntonces, dados los datos iniciales:\n\nDuplicado 1 = 25.56 % Cu\nDuplicado 2 = 25.66 % Cu\nDiferencia = 0.10 % Cu\n\nLa diferencia encontrada entre duplicados \\(\\Delta = 0.1 &lt; 0.57\\) % Cu, por lo tanto, se acepta la diferencia entre duplicados, es un dato de QAQC conforme.\n¿Y qué hacemos si no tenemos datos históricos de duplicados? Por favor, continue leyendo.\n\n\nEstimación mediante estudios de precisión siguiendo las directrices de la guía ISO 5725\nCuando no existen datos históricos, la guía ISO 5725 sugiere llevar a cabo un diseño experimental en el cual se estudien diversos factores que podrían, eventualmente, tener un efecto importante en la precisión del método analítico. Por ejemplo:\n\nAnalistas distintos\nEquipos de medición (cromatógrafos, AAS, etc.)\nDías distintos\nEtc.\n\nEl “problema” de esta aproximación es que a medida que crece el número de factores, el tamaño del diseño experimental (a.k.a número de experientos) crece en forma rápida incluso, en algunos diseños, en forma exponencial.\nLa ventaja de este método es que permite estimar en un único estudio la precisión de repetibilidad, reproducibilidad y la precisión intermedia, es decir, entre-analistas, entre-equipos, etc. La otra ventaja es que permite estimar los denominados componentes de varianza “¿Y?” – se preguntará. Bueno, los componentes de varianza nos indican cuál es el factor que más aporta a la variabilidad del sistema analítico ¿será la variabilidad entre-analistas? ¿o los distintos equipos que dispone el laboratorio? De esta forma Ud. podrá focalizar los esfuerzos y recursos en mejorar la precisión del método sólo en aquellos factores que más aporten a la variabilidad total.\nVeamos en qué consiste este método de estimación de precisión en base al estudio del factor Analista. Existen varios diseños experimentales para evaluar este factor, sin embargo, en este post comenzaremos con algo light:\n\nEstimaremos la precisión de reptibilidad y reproducibilidad del método volumétrico para la determinación de Cu en concentrado de cobre, en un laboratorio donde \\(n = 4\\) analistas son igualmente competentes para llevar a cabo el análisis, siguiendo el mismo instructivo.\n\nPara abordar este objetivo, proponemos el siguiente diseño experimental:\n\n\n\nDiseño Experimental\n\n\n\nUna única muestra será analizada por los \\(n = 4\\) analistas.\nCada analista realizará el análisis en quintuplicado \\(j = 5\\)\nLos \\(k = n\\cdot j = 20\\) análisis deben ser obtenidos en condiciones de repetibilidad\n\nSi bien podríamos publicar una enciclopedia de posts sobre diseño experimental en química, surgen algunas preguntas sobre este diseño en particular:\n\n¿Por qué una única muestra? Porque si cada analista recibiera una muestra distinta, entonces la precisión del factor analista estaría “contaminada” con la variabilidad entre muestras, la cual no nos interesa en este estudio.\n¿Y si una única muestra no es suficiente para llevar a cabo los 20 análisis? Existen otros diseños experimentales denominados anidados que permiten estimar la precisión utilizando muestras distintas.\n¿Por qué los análisis de cada analista deben ser obtenidos en condiciones de repetibilidad? Porque no queremos que otro factor no controlado (por ejemplo, equipos distintos) influya en la estimación de la precisión entre-analistas.\nEn lo posible, aumente el número de analistas en vez de hacer muchos replicados. Es mejor 5 analistas en triplicado, que 3 en quintuplicado.\n“La” muestra podría corresponder a una muestra del cliente. No es necesario que sea un material de referencia, sin embargo, esta muestra debe ser lo suficientemente homogénea… ¡Ah, eso es trampa! ¿Cómo demostramos que la muestra es homogénea? Le doy un dato, anote:\n\n\nSi su muestra es material particulado, le tengo malas noticias: No existen las muestras homogéneas de este tipo de material (gracias a san Pierre Gy por el dato).\n\nComo mencionamos anteriormente podríamos postear ad infinitum sobre diseño de exprimentos en química, sin embargo, la banda ancha es finita así que vamos al grano. La tabla @ref(tab:doe) muestra los datos experimentales del estudio de precisión propuesto:\n\n\n\nResultados de estudio de precisión [% Cu]\n\n\nReplicado\nAnalista 1\nAnalista 2\nAnalista 3\nAnalista 4\n\n\n\n\n1\n24.74\n24.73\n25.06\n25.00\n\n\n2\n25.06\n25.16\n25.17\n24.98\n\n\n3\n25.34\n24.98\n25.24\n24.79\n\n\n4\n25.28\n25.11\n24.80\n24.65\n\n\n5\n25.02\n24.72\n25.11\n24.82\n\n\n\n\n\n\n\nAntes de llevar a cabo el análisis estadístico formal, observemos la figura @ref(fig:doeplot) la cual muestra el valor promedio de cada analista \\(\\pm\\) 1 desviación estándar. Ella nos indica que, aparentemente, los resultados entre los analistas son bastante consistentes.\n\n\n\n\n\nBoxplot estudio de precisión\n\n\n\n\n\nAhora bien ¿Cómo, entonces, estimamos la precisión de repetibilidad y reproducibilidad a partir de la tabla @ref(tab:doe)? Fácil, con el todopoderoso Análisis de Varianza (ANOVA).\n\nNo detallaremos la matemática detrás de esta poderosa técnica, sin embargo, diremos simplemente que el ANOVA es un método cuyo propósito es particionar la variabilidad total de un conjunto de datos en componentes que intentan explicarla. Aplicada a nuestro caso, utilizaremos ANOVA para particionar la variabilidad total de los 20 resultados de % Cu entre dos componentes:\n\nEl factor analista\nLa repetiblidad del método analítico.\n\npara lo cual seguiremos paso a paso las instrucciones de la guía ISO 5725. En primer lugar obtendremos la tabla ANOVA mediante lenguaje R:\n\n\n\nTabla ANOVA precisión\n\n\nOrigen Variación\ng.l\nSQ\nMS\nF calculado\np-value\n\n\n\n\nanalista\n3\n0.2\n0.07\n1.8\n0.19\n\n\nResiduals\n16\n0.6\n0.04\n\n\n\n\n\n\n\n\n\nLas tablas ANOVA muy similares en casi todos los softwares estadísticos profesionales… y en Excel también. Entonces:\n\nRepetibilidad \\(s_{r}\\): Es simplemente la raíz cuadrada del término \\(MS\\) de los Residuos. En la nomenclatura de ANOVA es lo que se conoce como variabilidad dentro (within). Para los datos de la tabla @ref(tab:doe) se obtiene \\(s_{r} = \\sqrt{\\text{MS}_{Residuals}} = \\sqrt{0.04} = 0.19\\) % Cu.\nPrecisión intermedia o variabilidad entre-analistas \\(s_{analista}\\): ¡No tan rápido! No es la raíz cuadrada de \\(MS\\) del factor analista. Debemos hacer el siguiente cálculo adicional:\n\n\\[\\begin{eqnarray}\n  s_{analista} &=& \\sqrt{\\frac{MS_{analista} - MS_{Residuals}}{j}} \\\\\n  s_{analista} &=& \\sqrt{\\frac{0.07 - 0.04}{5}} \\\\\n  s_{analista} &=& 0.08\\, \\text{% Cu}\n\\end{eqnarray}\\]\ndonde \\(j = 5\\) es el número de replicados que hizo cada analista\n\nReproducibilidad \\(s_{R}\\): Es simplemente la combinación en cuadratura de las precisiones arriba calculadas.\n\n\\[\\begin{eqnarray}\n  s_{R} &=& \\sqrt{s_{r}^{2} + s_{analista}^2}\\\\\n  s_{R} &=& 0.21\\, \\text{% Cu}\n\\end{eqnarray}\\]\nPor lo tanto, con estos datos podemos calcular el límite de repetibilidad sin necesidad de tener una base de datos histórica de duplicados. En este caso \\(r = 2.8 s_{r} = 0.58\\) % Cu.\n\n¿Y si quisiera establecer la máxima diferencia tolerable entre analistas?\n\nNos vemos en el siguiente post.\n\n\nBonus track : Breve historia del factor 2.8\nSea \\(x_{1}\\) y \\(x_{2}\\) los duplicados de análisis 1 y 2, respectivamente. Cada uno de ellos “sigue” una distribución Normal con media \\(\\mu\\) y varianza \\(V = \\sigma_{r}^2\\) y, además, entre ellos son independientes, entonces se cumple lo siguiente:\n\nla diferencia entre duplicados \\(\\Delta = x_{1} - x_{2}\\) sigue una distribución Normal con media 0 y varianza \\(V_{\\Delta} = V(x_{1} - x_{2}) = V(x_{1}) + V(x_{2}) = 2\\sigma_{r}^2\\).\nSi la varianza de las diferencias es \\(V_{\\Delta} = 2\\sigma_{r}^2\\), entonces la desviación estándar es \\(\\sqrt{2} \\sigma_{r}\\).\nPor lo tanto, si quisiéramos construir un intervalo de confianza al 95% para la diferencia entre duplicados obtendríamos \\(\\Delta \\pm 2\\sqrt{2} \\sigma_{r}\\). El 2 es por que para una distribución Normal se sabe que entre la media \\(\\pm\\) 2 la desviación estándar se encuentran aproximadamente el 95% de las observaciones.\n\\(s_{r}\\) es la estimación de \\(\\sigma_{r}\\), la cual es fija pero desconocida.\nComo \\(\\sqrt{2}\\approx 1,41\\) entonces, con un 95% de confianza, la diferencia se encuentra entre \\(\\Delta \\pm 2\\cdot 1,41 \\cdot s_{r} = 2.8\\cdot s_{r}\\). Ahora imágineme como el mago Tamariz al final de sus actos tocando el violín ¡chiararaaá! (Si eres old school sabrás quien es el mago Tamariz. Si eres millenial mira este video).\n\n\n\nBibliografía\n\nISO 5725 – 3:1994 Accuracy (trueness and precision) of measurement methods and results – Part 3: Intermediate measures of the precision of a standard measurement method\nMichael Thompson, Bertil Magnusson Methodology in internal quality control of chemical analysis Accreditation and Quality Assurance August 2013, Volume 18, Issue 4, pp 271–278\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "post/mis-datos-no-son-normales/index.html",
    "href": "post/mis-datos-no-son-normales/index.html",
    "title": "¡Mis datos no son normales! ¿Qué hago?…Cálmese, nunca lo fueron… ni lo serán",
    "section": "",
    "text": "Bueno, aquí va la primera piedra:\n\nNo existen datos experimentales normales\n\nSus datos obtenidos en el laboratorio no “siguen” ninguna distribución de probabilidad. La naturaleza no “sigue” ninguna distribución de probabilidad.\n\nLa Normalidad es sólo una abstracción, es un modelo matemático de un fenómeno aleatorio.\n\nY como todo modelo, podría ser razonable para un conjunto de datos y totalmente equivocado para otro. Somos nosotros, los químicos/científicos, quienes proponemos modelos del sistema que estamos estudiando y a través de la experimentación corroboramos o no estos modelos.\nTodos los tests estadísticos formales para evaluar la normalidad tampoco responden en forma 100% certera si esta hipótesis es válida, pues están afectos a los errores de tipo falso positivo (I) y falso negativo (II). Por lo tanto, las pruebas estadísticas en la práctica no confirman que los datos experimentales sean Normales, sino que nos indican si el modelo Normal es razonable o no. Si lo es, actuamos como si “fuesen” normales y hacemos inferencia estadística a partir de las propiedades de la Normal.\nEl modelo Normal se describe en la ecuación @ref(eq:normal) y la figura @ref(fig:plotnormal) muestra la archiconocida forma de campana:\n\\[\\begin{equation}\n  f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}}\\exp{-\\frac{1}{2}\\left(\\frac{x - \\mu}{\\sigma}\\right)^2}\n  (\\#eq:normal)\n\\end{equation}\\]\ndonde \\(\\sigma\\) y \\(\\mu\\) son la desviación estándar y media, respectivamente. Notar que la distribución Normal es aplicable sólo a variables continuas, tales como concentración, temperatura, masa, etc. No se puede aplicar la distribución normal a variables discretas como cuentas de células bajo un campo de microscopio, por ejemplo. Quizás algún microbiólogo está familiarizado con el uso de logaritmos en sus cálculos de incertidumbre, bueno, es porque se utilizan otros modelos de probabilidad para datos discretos (ufc), como el modelo Poisson.\nAdvierta también, que los posibles valores que puede tomar la variable \\(X\\) están en el no despreciable rango entre \\(-\\infty\\) y \\(+\\infty\\). ¿Ha comprado algún estándar de calibración cuyo certificado indique una pureza de \\(99.7 \\pm 0.5\\) %? Raro ¿no? Bueno, pues el proveedor ha aplicado equivocadamente la distribución Normal a una variable que no es Normal: pureza química. En efecto, desde el punto de vista químico la pureza está confinada al intervalo \\([0, 100]\\) %, por lo tanto, no tiene sentido químico un certificado que indique \\(99.7 \\pm 0.5\\) %. Para modelar pureza química es necesario utilizar una distribución de probabilidad que esté restringida al intervalo \\([0, 100]\\) % (o \\([0, 1]\\)) como, por ejemplo, la distribución Beta.\n\n\n\n\n\nDistribución Normal con media = 0 y sd = 1\n\n\n\n\nExisten varios test para evaluar la palusibilidad de la normalidad de los datos, pero en este post discutiremos sólo dos de ellos: El test de Shapiro-Wilk y el Test de Anderson-Darling.\nLa matemática detrás de estos tests no es muy digerible, por lo que simplemente los ejemplificaremos con algunos datos reales y simulados. La ventaja de usar simulaciones es que “creamos” artificialmente datos de la distribución que se nos plazca y así verificar el desempeño de estos tests. Si recuerda, ya habíamos utilizado la simulación cuando revisamos las pruebas de linealidad en este post.\n\nAntes de hacer cualquier prueba estadística de normalidad grafique los datos, a través de un histograma y un gráfico de probabilidad Normal\n\nEstos gráficos le darán una primera aproximación para evaluar el supuesto de normalidad. Todos los softwares estadísticos incorporan estos gráficos. A continuación los veremos en acción en datos normales simulados en lenguaje R, qué otro. El siguiente es el código para llevar a cabo esta simulación de \\(n = 100\\) datos normales:\n\nset.seed(123) # Con este comando nos aseguramos de generar siempre\n              # los mismos datos aleatorios. Sino, obviamente, todos\n              # generaríamos números distintos pues son aleatorios ¿no?\n\nn &lt;- 100 # Número de datos a simular\nmu &lt;- 10 # Media de los n = 100 datos\nsigma &lt;- 1 # Desviación estándar de los n = 100 datos\n\n# Genera 100 dato normales con media mu y desviación estándar sigma\n# y guárdalos en el vector llamado x\nx &lt;- rnorm(n, mu, sigma)\n\nAl calcular la media y desviación estándar (muestral) de estos datos obtenemos \\(\\overline{x} = 10.1\\) y \\(s = 0.9\\) “¿Pero cómo? ¿No habíamos simulado una media de 10 y desviación estándar 1? Esto es una estafa” Keep calm recuerde que son aleatorios. La figura @ref(fig:normplot) muestra a la izquierda el histograma y a la derecha el gráfico de normalidad (QQ-Plot) de los datos simulados:\n\n\n\n\n\nIzquierda histograma, derecha gráfico de normalidad\n\n\n\n\nEl histograma muestra esa forma de campana característica de la distribución normal. Quizás no conozca el gráfico de probabilidad normal o QQ-Plot, pero es la primera evidencia que un estadístico revisa para evaluar la hipótesis de normalidad. Note que la “mayoría” de los datos está sobre una línea diagonal roja, cuando Ud. observe este patrón podría concluir que el modelo normal es razonable o adecuado para modelar sus datos.\n\n¿Son concluyentes estos gráficos? No, en absoluto. Simplemente muestran que la normalidad es una hipótesis plausible.\n\nRecuerde que estos datos son simulados, por lo tanto, era esperable este comportamiento. Pero sus datos experimentales son “reales”, a priori no sabe qué comportamiento podrían evidenciar, sólo puede plantear una hipótesis.\nApliquemos ahora los test “formales” de linealidad: test de Shapiro y test de Anderson. Ambos tests intentan evaluar la hipótesis nula \\(H_{0}\\) que los datos provienen de una distribución Normal:\n\nlibrary(nortest) # Cargamos esta librería que contiene varios test de\n                 # Normalidad, entre ellos Anderson-Darling\n\n# Test de Shapiro-Wilk (no requiere librería nortest)\nshapiro.test(x)\n\n\n    Shapiro-Wilk normality test\n\ndata:  x\nW = 0.99388, p-value = 0.9349\n\n# test de Anderson-Darling\nad.test(x)\n\n\n    Anderson-Darling normality test\n\ndata:  x\nA = 0.182, p-value = 0.9104\n\n\nLa interpretación tradicional de las pruebas de hipótesis sería más o menos la siguiente:\n\nYa que el p-value &gt; 0,05, entonces, no hay evidencia para rechazar la hipótesis de normalidad de los datos. ¿Se conluye, entonces, que los datos son normales? No. Simplemente, no tenemos la evidencia para rechzar la hipótesis.\n\nPor lo tanto, no es que los datos sean normales, sino que la hipótesis de normalidad es razonable, por lo que actuaremos como si fuese cierto. Obviamente, estos resultados eran esperables pues hemos “creado” datos normales, pero recuerde que sus datos son “reales”, no simulados. Hay otras consideraciones de las pruebas de hipótesis que no mencionaremos por espacio, pero que un post futuro discutiremos en profundidad. Especialmente, esta perversa dicotomía del p-value &lt; ó &gt; 0,05 de la cual ya hicimos mención en este post.\n\n“The p-value was never intended to be a substitute for scientific reasoning” Ron Wasserstein, Director Ejecutivo de la Asociación Americana de Estadística ASA.\n\nNota: Para tamaños de muestra grandes (\\(n &gt; 1000\\)), una pequeña desviación de la normalidad hará que los tests estadísticos acusen No Normalidad\nCuando nos referimos a “actuar como si fuese cierto”, estamos diciendo que todos aquellos procedimientos estadísticos que suponen normalidad de los datos, funcionarán de acuerdo a la teoría. ¿Cuáles son estos métodos estadísticos que requieren normalidad de los datos?:\n\nTest de Student en todas sus variantes (es un test de sesgo)\nTest de Fisher para comparar varianzas (precisión analítica de 2 métodos)\nCurva de calibración lineal\nMáxima diferencia tolerable entre duplicados de análisis, discutido aquí\nAnálisis de varianza para evaluar varios métodos analíticos o analistas\nIntervalos de confianza para la media de concentraciones.\nIncertidumbre de métodos analíticos. El \\(k = 2\\) asume normalidad de las concentraciones.\n… y un largo etc.\n\nOk, es cierto, a medida que aumenta el \\(n\\) la suposición de normalidad es cada vez menos relevante. De hecho algunos de los tests mencionados arriba son más o menos “robustos” a la suposición de normalidad.\n\n¿Qué observaríamos si la hipótesis de normalidad fuese totalmente inverosímil para modelar nuestros datos?\nSimulemos ahora datos no normales y veamos cuáles son los resultados tanto de los gráficos exploratorios como de las pruebas estadísticas formales:\n\n# Simularemos m = 100 datos discretos de una distribución Poisson\n\nset.seed (123) # Para que pueda reproducir los datos\nm &lt;- 100 # m = 100 datos\nlambda &lt;- 5 # Parámetro de la distribución Poisson\n\n# Generar m = 100 datos de una distribución Poisson con parámtro lambda = 5\ny &lt;- rpois(m, lambda)\n\n\n\n\n\n\n{{% callout warning %}} ¿No les parece familiar el QQ-Plot a aquellos que validan homogeneidad de peso en validación de procesos farmacéuticos? 1313{{% /callout %}}\nLa evidencia de los gráficos es abrumadora, los datos no son normales. Esto concuerda con lo que muestran los tests estadísticos de normalidad:\n\n# Test de Shapiro-Wilk (no requiere librería nortets)\nshapiro.test(y)\n\n\n    Shapiro-Wilk normality test\n\ndata:  y\nW = 0.97077, p-value = 0.02531\n\n# test de Anderson-Darling\nad.test(y)\n\n\n    Anderson-Darling normality test\n\ndata:  y\nA = 1.2355, p-value = 0.003072\n\n\nComo era esperable, ambos tests confirman que la hipótesis de normalidad no es razonable para modelar los datos(p-value &lt; 0,05)\n\n\nSi mis datos no son normales, entonces ¿Cómo los analizo?\nTranquilo(a), el mundo sigue girando. Existen varios métodos estadísticos que Ud. puede utilizar para analizar datos donde la hipótesis de normalidad no es razonable o se ha demostrado empíricamente que no es :\n\nBootstrap: Utilizado, entre otros propósitos, para obtener intervalos de confianza para datos no normales.\nTests no paramétricos: Análogos a las pruebas paramétricas tradicionales (Test T, ANOVA, etc.)\nTests de permutaciones: También son una excelente alternativa a las pruebas paramétricas tradicionales y funcionan, incluso, para conjuntos pequeños de datos. Son tests “exactos”, pero necesitan que Ud. disponga de un buen “tarro” (computador) pues son computationally-intensive methods.\nModelos lineales generalizados: Idóneos para modelar datos discretos como cuentas de células (leucocitos, ufc, etc.) o variables dicotómicas (Conforme/No Conforme), etc.\nTransformación de datos: Especialmente útiles son la transformación de Johnson y la de Box-Cox.\nEstadística Robusta: No tan sólo son útiles para minimizar el efecto de valores anómalos (outliers), sino también para obener estimadores de datos que no son normales.\n\nPara finalizar veamos en acción uno de estos métodos: Bootstrap. Sin embargo, el detalle estadístico y su implementación los veremos en otro post, por ahora, simplemente lo ejemplificaremos. La figura @ref(fig:As) muestra el histograma y el QQ-Plot de normalidad correspondientes a datos de concentración de arsénico [ppm] muestreados en \\(n = 271\\) pozos de agua en Bangladesh:\n\n\n\n\n\nHistograma y QQ-Plot datos de Arsénico [ppm] en n = 271 pozos en Bangladesh\n\n\n\n\nClaramente, ni si quiera es necesario hacer un test de normalidad, la evidencia que muestra la figura @ref(fig:As) en contra de la hipótesis de normalidad es abrumadora. El promedio de la concentración de As es \\(\\overline{x} = 125\\) ppm y la desviación estándar \\(s = 298\\) ppm. Utilizando la fórmula usual para estimar un intervalo de confianza al 95% para la media \\(\\overline{x} \\pm t_{\\alpha/2, n - 1} s/\\sqrt{n}\\) obtenemos [90, 161] ppm As. Sin embargo, la gran asimetría de los datos hace inverosímil el intervalo obtenido.\nAl aplicar el método bootstrap obtenemos un intervalo para la media al 95% (BCa) entre [95, 164] ppm As, el cual es más “correcto” por si Ud. necesita informar este parámetro. La figura @ref(fig:Asboot) muestra el histograma y QQ-Plot de normalidad de el método de bootstrap. Advierta el Teorema Central del Límite en su máxima expresión.\n\n\n\n\n\nHistograma y QQ-Plot de las estimaciones de la media de los datos de As con N = 1000 remuestreos\n\n\n\n\nBueno estimado lector, nos vemos pronto. Saludos.\n\n\nBibliografía\n\nGhasemi A, Zahediasl S. Normality Tests for Statistical Analysis: A Guide for Non-Statisticians. International Journal of Endocrinology and Metabolism. 2012;10(2):486-489. doi:10.5812/ijem.3505.\nHenry C. Thode Testing For Normality CRC Press 2002\nIs normality testing ‘essentially useless’?\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "post/post_2/post2.html",
    "href": "post/post_2/post2.html",
    "title": "post 2",
    "section": "",
    "text": "Las posibilidades\n\\[y = \\beta_{0} + \\beta_{1}x\\]\n\nplot(rnorm(1000))\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo/index.html",
    "href": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo/index.html",
    "title": "Validación de los cálculos de incertidumbre en química analítica con el método Monte Carlo. Parte I",
    "section": "",
    "text": "De acuerdo al numeral 8.1 del Suplemento 1 de la guía GUM, el método de Monte Carlo es un método general para estimar la incertidumbre de medición y puede, bajo ciertas directrices, validar los cálculos realizados con el método GUM. En este post asumiremos que Ud., esimado lector, está familiarizado con el método GUM y ya lo tiene implementado , por ejemplo, en una hoja Excel y le gustaría validar sus cálculos mediante un método totalmente independiente y más general. De esta forma podrá cumplir cabalmente con el siguiente numeral de la norma 17025:\n¿Cómo sabe Ud. que su implementación en Excel está correcta?"
  },
  {
    "objectID": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo/index.html#método-gum",
    "href": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo/index.html#método-gum",
    "title": "Validación de los cálculos de incertidumbre en química analítica con el método Monte Carlo. Parte I",
    "section": "Método GUM",
    "text": "Método GUM\nEste es un ejercicio bastante simple para el método GUM, pues el factor de dilución es una operación de división, por lo que aplicando las reglas de propagación de la incertidumbre de una división, obtenemos lo siguiente:\n\\[\\begin{equation}\n  u_{f} = f\\sqrt{\\left(\\frac{u_{V_{final}}}{V_{final}}\\right)^2 +\n  \\left(\\frac{u_{V_{inicial}}}{V_{incial}}\\right)^2}\n  (\\#eq:f)\n\\end{equation}\\]\nAsumiremos por simplicidad que las incertidumbres asociadas al material volumétrico son las indicadas por el fabricante en el mismo material, es decir, de acuerdo a la figura @ref(fig:matraz) y, por ahora, serán las únicas fuentes de incertidumbre del material volumétrico (olvidaremos la T° y la repetibilidad).\n\n\n\n\n\nIncertidumbre del fabricante\n\n\n\n\nAhora bien, las incertidumbres del material volumétrico corresponden a incertidumbres expandidas \\(U\\), por lo tanto, debemos convertirlas a incertidumbres estándares antes de aplicar la ecuación @ref(eq:f). También por simplicidad, modelaremos los volúmenes mediante una distribución rectangular, por lo tanto, al estandarizar \\(u = U/k\\), con \\(k = \\sqrt{3}\\) obtenemos lo siguiente:\n\\[\\begin{eqnarray}\n  u_{V_{final}} &=& \\frac{0,6}{\\sqrt{3}} = 0.35\\, \\text{mL}\\\\\n  u_{V_{incial}} &=& \\frac{0,1}{\\sqrt{3}} = 0.06\\, \\text{mL}\\\\\n  u_{f} &=& \\frac{100}{20}\\sqrt{\\left(\\frac{0.35}{100}\\right)^2 +\n  \\left(\\frac{0.06}{20}\\right)^2} \\\\\n    u_{f} &=&  0.02255\n\\end{eqnarray}\\]\nEn este ejemplo, podemos asumir que los grados de libertad de ambas incertidumbres tienden a infinito, por lo tanto, si queremos obtener la incertidumbre expandida del factor de dilución con un 95% de confianza, se asume un factor de cobertura \\(k = 2\\), de esta forma obtenemos \\(U_{f} = ku_{f} = 0.04509\\) mL."
  },
  {
    "objectID": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo/index.html#método-de-monte-carlo",
    "href": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo/index.html#método-de-monte-carlo",
    "title": "Validación de los cálculos de incertidumbre en química analítica con el método Monte Carlo. Parte I",
    "section": "Método de Monte Carlo",
    "text": "Método de Monte Carlo\nImplementaremos en R, los pasos descritos del método de Monte Carlo:\n\nk &lt;- sqrt(3) # Factor de estandarización para una distribución rectangular\nvi &lt;- 20     # Volumen inicial [mL]\nUvi &lt;- 0.1   # Incertidumbre expandida del volumen inicial [mL]\nuvi &lt;- Uvi/k # Incertidumbre estándar del volumen inicial [mL]\nvf &lt;- 100    # Volumen incial [mL]\nUvf &lt;- 0.6   # Incertidumbre expandida del volumen final [mL]\nuvf &lt;- Uvf/k # Incertidumbre estándar del volumen final [mL]\n\n# Aquí haremos la simulación de Monte Carlo\nset.seed(123) # Para que Ud. obtenga los mismos resultados en su simulación\n\n# Generaremos valores aleatorios de volumen inicial y volumen final\n# desde una distribución rectangular con el comando runif(n, minimo, maximo)\n# minimo = volumen - U\n# maximos = volumen + U\n# Los guardaremos en los vectores vi.sim y vf.sim\n\nn &lt;- 1000\nvi.sim &lt;- runif(n, vi - Uvi, vi + Uvi)\nvf.sim &lt;- runif(n, vf - Uvf, vf + Uvf)\n\n# Ahora calcularemos el factor de dilución para cada uno de los pares de \n# valores de volumen inicial y final que simulamos y lo guardaremos en el\n# el vector f.sim\n\nf.sim &lt;- vf.sim/vi.sim # Es la misma fórmula\n\n“Bueno ¿Y?” se preguntará Ud.\nVeamos que hemos generado con la simulación:\n\n\\(n = 1000\\) valores aleatorios del volumen inicial a partir de una distribución rectangular con media vi = 20 mL e incertidumbre expandida Uvi = 0.1 mL. El promedio de los 1000 volumenes iniciales simulados es 19.999 mL y una desviación estándar de uvi = \\(U_{vf}/\\sqrt{3} = 0.058\\) mL. La figura @ref(fig:visim) muestra el histograma de los valores simulados. Note que la simulación concuerda perfectamente con los valores de incertidumbre informados por el fabricante (\\(20 \\pm 0.1\\) mL).\n\n\n\n\n\n\nHistograma de los valores simulados de volumen inicial [mL]\n\n\n\n\n\n\\(n = 1000\\) valores aleatorios del volumen final a partir de una distribución rectangular con media vf = 100 mL e incertidumbre expandida Uvf = 0.6 mL.\nPara cada uno de los pares datos simulados de volumen inicial y final, se calculó el factor de dilución, por lo tanto, se obtuvieron en total \\(n = 1000\\) factores los cuales se “guardaron” en el vector f.sim, tal como se muestra en la tabla @ref(tab:fsim):\n\n\n\n\nVariables simuladas. Se muestran los primeros 6 datos\n\n\nvf.sim\nvi.sim\nf.sim\n\n\n\n\n99.73\n19.96\n5.00\n\n\n100.11\n20.06\n4.99\n\n\n99.59\n19.98\n4.98\n\n\n100.42\n20.08\n5.00\n\n\n100.42\n20.09\n5.00\n\n\n99.97\n19.91\n5.02\n\n\n\n\n\n\nLa figura @ref(fig:fsimhis) muestra el histograma de los 1000 factores de dilución simulados:\n\n\n\n\n\n\nHistograma de factores de dilución simulados\n\n\n\n\n“¡Qué interesante!”, dirá Ud., la división de dos variables rectangulares genera una distribución de datos que, al menos, es simétrica. ¿Es razonable asumir una distribución normal del factor de dilución simulado? Si recuerda la discusión en este post, podemos evaluar la admisibilidad de esta hipótesis mediante el análisis gráfico QQ-Plot de normalidad de los datos simulados y el test de Shapiro, el cual se muestra en la figura @ref(fig:fsimnorm).\n\n\n\n\n\nQQ-Plot de normalidad de los n factores de dilución simulados\n\n\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  f.sim\nW = 0.99005, p-value = 2.719e-06\n\n\nAparentemente, el modelo normal sería razonable para modelar el factor de dilución sino fuera por los siguientes hechos:\n\nEl histograma del factor de dilución tiene “colas livianas”, lo cual se puede advertir en el QQ-plot de normalidad en los valores extremos.\n\n\nLa evidencia del test de Shapiro en contra de la hipótesis de normalidad.\nY lo más importante, la razón de dos variables independientes rectangulares (uniformes) teóricamente no es Normal (está demostrado).\n\nOk, probablemente esta discusión no sea de mucho interés por ahora, pero nos dará pistas para dirigir la discusión posterior.\n\nEntonces ¿Cómo obtenemos la incertidumbre del factor de dilución por el método de Monte Carlo?\n\nMuy sencillo, a partir de la desviación estándar de los factores de dilución simulados, es decir, \\(u_{f}^{MC} = 0.02302\\). Como podrá advertir, es muy similar a la obtenida por el método GUM \\(u_{f} = 0.02255\\), la diferencia relativa es de un 2.1 %. Es más, ajustando a las cifras significativas correctas se obtiene la misma magnitud 0.02\n\n¿Queda validado el método GUM con los cálculos del método de Monte Carlo? Desde el punto de vista metrológico químico: Sí. Desde el punto de vista numérico: Depende.\n\nLo que sucede es que el numeral 8.1 del suplemento 1 dela guía GUM es explícito en establecer un criterio de aceptación entre el método GUM y el método de Monte Carlo (MC):\n\\[\\begin{eqnarray}\n  |y - U(y) - y_{low}| &&lt;& \\xi \\\\\n  |y + U(y) - y_{high}| &&lt;& \\xi\n\\end{eqnarray}\\]\ndonde \\(y \\pm U(y)\\) es el valor calculado de la variable y su incertidumbre expandida estimada por el método GUM; \\(y_{low}\\) e \\(y_{high}\\) corresponden a los percentiles 2.5 y 97.5 de los datos simulados, es decir, el intervalo de incertidumbre al 95% de confianza calculado por el método de Monte Carlo. \\(\\xi\\) es la tolerancia numérica entre ambas metodologías de cálculo. Es decir, es un test de precisión numérica, no metrológica.\nEl valor de \\(\\xi\\) está relacionado las cifras significativas que tienen sentido físico-químico y metrológico. Por ejemplo, si para una gravimetría usamos una balanza granataria cuya incertidumbre es del orden de \\(\\pm 0.1\\) g, no podríamos elegir una tolerancia numérica de \\(0.00001\\) g. Para establecer \\(\\xi\\) la guía indica lo siguiente:\n\nExprese \\(u(y)\\) en notación científica manteniendo las cifras significativas. En nuestro caso obtuvimos \\(u_{f} = 0.0225\\), la cual puede ser redondeada a una cifra significativa \\(u_{f} = 0.02\\). Esta incertidumbre, entonces, se expresa como \\(2 \\cdot 10^{-2}\\).\nPara obtener \\(\\xi\\), utilice el exponente de la potencia de 10 (t = -2) del paso anterior, en la siguiente expresión:\n\n\\[\\begin{eqnarray}\n  \\xi &=& \\frac{1}{2}\\times 10^{t} \\\\\n  \\xi &=& \\frac{1}{2}\\times 10^{-2}\\\\\n  \\xi &=& 0.005\n\\end{eqnarray}\\]\n\n¿Cómo obtenemos los percentiles 2.5 y 97.5 de la simulación de Monte Carlo?\n\nMuy sencillo, con el comando quantile:\nEsto quiere decir, que de los \\(n = 1000\\) datos simulados del factor de dilución, un 95% se encuentra dentro del intervalo [4.96, 5.04]. La figura @ref(fig:quantilofig) muestra este intervalo en el histograma de los datos simulados:\n\nhist(f.sim, \n     xlab = 'Factor de dilución',\n     main = '',\n     freq = T,\n     breaks = 20,\n     xlim = c(4.93, 5.07))\n\nabline(v = quantilos[1], col = 'red')\nabline(v = quantilos[2], col = 'red')\n\n\n\n\nIntervalo de confianza al 95% de los datos simulados del factor de dilución\n\n\n\n\nPor lo tanto, sólo nos queda calcular \\(U(y)\\) que es la incertidumbre expandida del factor de dilución calculada por el método GUM. De acuerdo a la guía \\(U = k\\cdot u\\), donde \\(k\\) es el factor de cobertura para obtener un intervalo de incertidumbre con cierto grado de confianza. Aquí es donde la guía GUM asume, bajo ciertas condiciones (ver numeral G.2.3), que la variable de respuesta, en este caso factor de dilución, puede aproximarse a una distribución Normal donde \\(k \\approx 2\\). Advierta que para nuestro ejemplo esta suposición no tiene mucho asidero. Por lo tanto, siguiendo las directrices de la guía GUM \\(U_{f} = 2\\cdot 0.023 = 0.05\\).\nCon todos los datos estimados, llevemos a cabo el test de validación entre el método GUM y el método de Monte Carlo:\n\\[\\begin{eqnarray}\n  |5 - 0.045 - 4.957| &&lt;& 0.005 \\\\\n  |5 + 0.045 - 5.043| &&lt;& 0.005\n\\end{eqnarray}\\]\n\nEn ambos casos \\(0.002 &lt; 0.005\\), por lo tanto, el método GUM queda validado\n\nInsisto con lo del mago Tamariz: ¡chiararáaa!\nObservaciones:\n\nSi bien en este ejemplo sólo utilizamos \\(n = 1000\\) simulaciones, en la práctica se requieren muchas más (\\(10^{5} - 10^{6}\\)). El suplemento 1 de la GUM entrega más directrices en este tema.\nMientras mayor sea el grado de no linealidad de la ecuación de medición, más divergencias habrá entre GUM y MC. Siendo este último el de mayor generalidad.\nSi bien se puede implementar Monte Carlo en Excel, es una tarea bastante engorrosa pues debe programarlo en Visual Basic. Le sugiero utilizar lenguajes de programación más modernos como R o Python, los cuales tienen librerías especializadas en métodos de simulación.\nA mayor asimetría de la distribución empírica, mayores diferencias habrá entre ambos métodos.\nDé un sentido químico a la simulación ¿Recuerda que la pureza química no es Normal? Intente con la distribución Beta la cual es más apropiada para modelar pureza.\n\nEn este post hemos validado el método GUM frente a Monte Carlo “a mano”, es decir, hemos hecho el test en forma manual. En el próximo post utilizaremos la librería metRology la cual incorpora la validación de GUM con MC en un único comando GUM.validate… ¡y listo!.\nHasta la próxima."
  },
  {
    "objectID": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo/index.html#bibliografía",
    "href": "post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo/index.html#bibliografía",
    "title": "Validación de los cálculos de incertidumbre en química analítica con el método Monte Carlo. Parte I",
    "section": "Bibliografía",
    "text": "Bibliografía\n\nEvaluation of measurement data – Guide to the expression of uncertainty in measurement JCGM 100:2008\nEvaluation of measurement data – Supplement 1 to the “Guide to the expression of uncertainty in measurement” – Propagation of distributions using a Monte Carlo method JCGM 101:2008\nStephen L R Ellison metRology: Support for Metrological Applications R package version 0.9-23-2, 2016."
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "talks",
    "section": "",
    "text": "hist(rnorm(1000))\n\n\n\n\n\nhist(rnorm(1000))\n\n\n\n\n\nhist(rnorm(1000))\n\n\n\n\n\nplot(rnorm(1000), rnorm(1000))\n\n\n\n\n\n\n\n Back to top"
  }
]