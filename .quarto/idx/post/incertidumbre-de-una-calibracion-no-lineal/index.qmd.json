{"title":"Incertidumbre de una calibración no lineal","markdown":{"yaml":{"title":"Incertidumbre de una calibración no lineal","subtitle":"Método GUM y Monte Carlo -- Norma ISO 8466:2","date":"2020-06-06"},"headingText":"Métodos de estimación de incertidumbre de calibración","containsRefs":false,"markdown":"\n\nEn un [post anterior](https://www.analytical.cl/post/como-calcular-la-incertidumbre-de-una-curva-de-calibracion/) \nrevisamos cómo estimar la incertidumbre de la concentración \nde una muestra problema, cuando ésta ha sido obtenida interpolando la señal \ninstrumental en una curva de calibración lineal.\n\nLa expresión es relativamente simple y vimos también cómo podemos implementarla\nen el lenguaje de programación `R` a través del package `chemCal`.\n\nSin embargo, la vida no es tan sencilla. Recoradará estimad@ lector@ que está \nbastante documentada la presencia de desviaciones de la linealidad \na altas concentraciones, fenómeno muy conocido en los métodos \nespectrofotométricos (Ley de Lambert-Beer). La severidad de estas desviaciones \nvaría en función del detector, el analito y otros factores físico-químicos\ndel sistema de medición.\n\nCuando existen estas desviaciones y deseamos llevar a cabo un \n[test de linealidad](https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/),\nes muy probable que el test rechace el modelo lineal, por lo tanto, no podemos\nestimar la incertidumbre de calibración asumiendo este modelo. Si bien es cierto\npodemos reducir el rango lineal y diluir la muestra problema que está fuera\ndel rango, la operación de dilución introduce nuevos errores (incluso errores \nhumanos de transcripción bastante frecuentes).\n\nUna alternativa válida sería utilizar un modelo de calibración que capture esta\nno linealidad evitando así la dilución de la muestra, \npor lo tanto el problema se reduce a:\n\n> ¿Cómo estimar la incertidumbre de una muestra problema que ha sido\n> obtenida a través de una curva de calibración no lineal?\n\nSin embargo, de esta pregunta se desprende al mismo tiempo otra interrogante:\n\n> ¿Cuál modelo de calibración no lineal utilizaré?\n\nExisten varios modelos de calibración no lineal:\n\n1. Polinomios\n2. New Rational (en realidad se llaman *aproximaciones de Padé*)\n3. Splines\n4. Loess\n5. etc.\n\n\nPor lo tanto, no existe una respuesta completamente correcta desde \nla prespectiva estadística, pues un modelo cuadrático sería tan válido como \nun polinomio cúbico. Desde el punto de vista químico podríamos preguntarnos\n¿qué sentido químico tiene una curva de calibración polinómica de grado 5?\n¿Son interpretables los parámetros del modelo? En un modelo lineal como el \nde Lambert-Beer: $y = \\beta_{0} + \\beta_{1}x$ la pendiente de la curva de \ncalibración tiene una interpretación química: es el producto entre coeficiente \nde extinción molar y la longitud de la celda:\n\n$$\n\\underbrace{A}_\\text{y} = \\underbrace{\\epsilon \\cdot b}_\\text{$\\beta_{1}$} \\cdot\n\\underbrace{C}_\\text{x}\n(\\#eq:lambert)\n$$\nPero recuerde este sabio consejo de un monstruo de la estadística aplicada:\n\n> *\"All models are wrong, but some are useful\"*\n> -- <cite>George Box</cite>\n\nPor lo tanto, tenemos que tomar una decisión. Y obviamente, como soy el autor de\neste humilde post, ya la tomé por Ud. En este artículo estimaremos la \nincertidumbre de calibración de un modelo polinómico de grado 2, también \nconocido como modelo cuadrático.\n\nNota: Desde el punto de vista **estrictamente estadístico** los modelos \npolinómicos, como la calibración cuadrática, son también modelos lineales ya que \nlos coeficientes del modelo son lineales\n\n$$y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^2 + \\epsilon$$\n\nEn cambio, en un modelo del tipo exponencial:\n\n$$y = \\beta_{0}\\cdot e^{\\beta_{1}x}$$\n\nEl coeficiente $\\beta_{1}$ no es una función lineal.\n\n\nEn este post ejemplificaremos y compararemos tres métodos de estimación\nde incertidumbre de calibración:\n\n1. Norma ISO 8466-2:2001 *Water quality -- Calibration and evaluation of \nanalytical methods and estimation of performance characteristics -- Part 2: \nCalibration strategy for non-linear second-order calibration functions.*\n\n2. Método GUM\n\n3. Método de Monte Carlo (Suplemento 1 ISO-GUM)\n\nImplementaremos todos los métodos en el lenguaje de programación `R`, explicando\npaso a paso el código fuente con el fin de que Ud. obtenga los mismos \nresultados, es decir, un **análisis reproducible**.\n\n# Datos de calibración\n\nPara ejemplificar los cálculos, utilizaremos los datos de calibración indicados\nen el ejemplo de la sección 7 de la norma ISO 8466-2. El siguiente código `R` \nnos permite ingresar los datos manualmente:\n\n```{r data}\n# Ingresamos los datos de calibración de la sección 7 de la norma ISO 8466-2\n# x: concentración en mg/L\n# y: Absorbancia [UA]\n\nx <- c(12, 18, 24, 30, 36, 42, 48, 54, 60, 66)\ny <- c(0.083, 0.123, 0.164, 0.203, 0.240, 0.273, 0.303, 0.334, 0.364, 0.393)\n\nd <- data.frame(x, y) # creamos un data frame con las variables x e y (esto es\n                      # análogo a una matriz de datos en Excel con dos columnas)\n```\n\nA continuación graficamos la curva de calibración con la librería `ggplot2`:\n\n```{r}\nlibrary(ggplot2) # cargamos la librería ggplot2\n\ntheme_set(theme_minimal()) # esto es sólo por una cuestión estética del gráfico\n\nggplot(d, aes(x = x, y = y)) +\n  geom_point(color = 'red') +\n  xlab('Concentración [mg/L]') +\n  ylab('Absorbancia [UA]')\n\n```\n\nMmm... no sé Ud. pero yo veo una leve curvatura.\nComo lo vimos en un [post anterior](https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/)\nllevaremos a cabo un análisis estadístico básico para evaluar si el modelo de\ncalibración lineal es adecuado, o si nos inclinamos por la hipótesis de no \nlinealidad.\n\nComo no tenemos replicados de cada punto de calibración, haremos un Test de \nLinealidad de Mandel. Lo primero, es ajustar un modelo lineal a los datos \n$y = a + bx$:\n\n```{r fit.lineal}\nfit.lineal <- lm(y ~ x, data = d) # ajustamos un modelo lineal y lo guardamos \n                                  # con el nombre fit.lineal\n\nsummary(fit.lineal) # para ver el análisis estadístico del ajuste\n```\n\nEsta tabla nos dice que el intercepto del modelo es \n$a = `r fit.lineal$coeff[1]`$ y la pendiente $b = `r fit.lineal$coeff[2]`$.\nNote el alto coeficiente de determinación \n$r^{2} = `r round(summary(fit.lineal)$r.square, 4)`$ lo cual indica que es un \nbuen modelo. El coeficiente de correlación es \n$r = `r round(sqrt(summary(fit.lineal)$r.square), 3)`$ que si bien es un dato a\nconsiderar, no es una prueba formal de linealidad.\n\nLa siguiente figura muestra el ajuste lineal sobre los datos de calibración:\n\n```{r plot.lineal}\nlibrary(ggpmisc) # para escribir ecuaciones dentro del gráfico\n\nggplot(d, aes(x = x, y = y)) +\n  geom_point(color = 'red') +\n  geom_smooth(method = 'lm', se = F, \n              size = 0.5) + # dibuja la curva de calibración lineal\n  xlab('Concentración [mg/L]') +\n  ylab('Absorbancia [UA]') +\n  stat_poly_eq(aes(label =  paste(stat(eq.label), stat(rr.label), \n                                  sep = \"*\\\", \\\"*\")), \n               formula = y ~ x, \n               parse = TRUE, \n               rr.digits = 4)\n```\n\nSe observa que el ajuste lineal no es un buen modelo, pues no captura la \ncurvatura de los datos a pesar del alto coeficiente de correlación. \nEsto se oberva más claramente si obervamos el gráfico\nde residuos:\n\n```{r fit.lin.res}\nplot(fit.lineal, which = 1, add.smooth = F, pch = 19, col = 'red', \n     main = 'Gráfico de residuos modelo lineal')\n```\n\nLa evidencia en contra del modelo lineal es abrumadora, el gráfico muestra \nclaramente un patrón en los residuos que indica que el modelo lineal \nno es adecuado. Sin embargo, a pesar de la evidencia, haremos el Test de Mandel\npara \"comprobar\" esta hipótesis. Para aplicar el Test de Mandel debemos ahora \najustar el modelo cuadrático y compararlo con el modelo lineal.\nPara ser consistentes en la notación de la\nnorma ISO 8466-2, definiremos el modelo de calibración cuadrático como:\n\n$$ \ny = a + bx + cx^2\n$$\n\n```{r fit.cuad}\nfit.nolineal <- lm(y ~ x + I(x^2), data = d) # ajuste cuadrático y los guardamos \n                                          # con el nombre fit.nolineal\nsummary(fit.nolineal)\n```\n\nSe obtiene una tabla similar que la del modelo lineal, con la adición del \ncoeficiente que acompaña al \n$x^2$: `I(x^2)` $= `r round(fit.nolineal$coeff[3], 8)`$. Note\nque el coeficiente de determinación del modelo cuadrático es mayor que el \ndel modelo lineal. Esto siempre se cumplirá, lo que hace el Test de Mandel es\ndiscernir si esta \"mejora\" en el modelo es \"significativa\". \n\nLa siguiente figura muestra el ajuste no lineal, el cual captura mucho mejor\nla curvatura de los datos:\n\n```{r plot.nolineal}\nggplot(d, aes(x = x, y = y)) +\n  geom_point(color = 'red') +\n  geom_smooth(method = 'lm',         # dibuja la curva de calibración no lineal\n              se = F, \n              formula = y ~ x + I(x^2), size = 0.5) + \n  xlab('Concentración [mg/L]') +\n  ylab('Absorbancia [UA]') +\n  stat_poly_eq(aes(label =  paste(stat(eq.label), stat(rr.label), \n                                  sep = \"*\\\", \\\"*\")),\n               formula = y ~ x + I(x^2), \n               parse = TRUE, \n               rr.digits = 4)\n```\n\n\nOk, aplicamos\nel Test de Mandel con el comando `anova`:\n\n```{r mandel}\nanova(fit.lineal, fit.nolineal)\n```\n\n```{r p.mandel, echo = F}\np.mandel <- anova(fit.lineal, fit.nolineal)$`Pr(>F)`[2]\n```\n\nEl p-value del test de Mandel es $`r round(p.mandel, 8)`$, el cual de acuerdo a \nla interpretación tradicional, indica que el modelo lineal no es adecuado para \nlos datos de calibración.\n\nProcedamos, entonces, a estimar la incertidumbre de la concentración $\\hat{x}$\nde una muestra problema, cuyo valor fue obtenido interpolando la señal \ninstrumental en el modelo de calibración no lineal.\n\n## Estimación de incertidumbre de acuerdo a ISO 8466-2\n\nDesde el punto de vista metrológico, la aproximación que indica esta norma es \nsimilar a lo que dicta la guía ISO GUM clásica, es decir, \nestima la incertidumbre a partir de un modelo de medición $y = f(x)$. \nLa \"gracia\" de esta norma es que nos \nahorra tinta, pues la ecuación de incertidumbre ya está \"algebraicamente \nmanipulada\". No entraremos en los detalles de las primeras secciones de la\nnorma los cuales estudian el comportamiento de la curvatura, es decir, si será\nposible encontrar un máximo o un mínimo, lo cual es clave en la utilidad del \nmodelo cuadrático como función de calibración. Esto es\nimportante porque recuerde que una función parabólica tiene dos soluciones, si \nexistiera un máximo o un mínimo en el rango de trabajo, el modelo cuadrático no \npuede ser utilizado como función de calibración.\n\nLa siguiente ecuación calcula la **incertidumbre expandida** \n$I(\\hat{x}) = U_{\\hat{x}}$ de la concentración de la muestra problema $\\hat{x}$, \ninterpolada en la curva de calibración no lineal $y = a + bx + cx^2$. \nCorresponde a la ecuación (27) de la norma:\n\n\n$$\nI(\\hat{x}) = \\frac{s_{y} \\cdot t_{n - 3,\\, 95\\%}}{b + 2c\\hat{x}} \\cdot\n            \\sqrt{\\frac{1}{N} + \\frac{1}{\\hat{N}} + \n            \\frac{(\\hat{x} - \\overline{x})^2 \\, Q_{x^4} + \n            \\left(\\hat{x}^2 - \\frac{\\sum x_{i}^{2}}{N} \\right)^2 Q_{xx} -\n            2(\\hat{x} - \\overline{x}) \n            \\left(\\hat{x}^2 - \\frac{\\sum x_{i}^{2}}{N} \\right) Q_{x^3}}\n            {Q_{x^4} Q_{xx} - \\left( Q_{x^3} \\right)^2}}\n$$\n\ndonde:\n\n$$\ns_{y} = \\sqrt{\\frac{\\sum (y_{i} -\\hat{y})^2}{N - 3}}\n$$\n\n- $y_{i}$ es la respuesta experimental observada del estándar $i$, $\\hat{y}$ es la\nrespuesta instrumental que predice el modelo para el mismo estándar $i$, por lo\ntanto $e_{i} = y_{i} - \\hat{y}$ es el residuo. $N$ es el número de calibrantes. \n¿Por qué el denominador es $N - 3$ y no $N -2$ como en la calibración lineal? \nPorque el modelo cuadrático posee tres parámetros $a$, $b$ y $c$.\n\n- $t_{N - 3,\\, 95\\%}$ es el valor del T de Student con $N - 3$ grados de \nlibertad y un 95% de confianza.\n\n- $\\hat{N}$ es el número de replicados \nindependientes de la muestra problema. Como discutimos en \n[otro post](https://www.analytical.cl/post/como-calcular-la-incertidumbre-de-una-curva-de-calibracion/), \nesto no corresponde a inyectar $\\hat{N}$ veces la misma muestra en el \ninstrumento.\n\n- $\\hat{x}$ es la concentración de la muestra problema interpolada en la curva\nde calibración no lineal, la cual se obtiene resolviendo la ecuación\ncuadrática. Como Ud. recordará de sus años mozos esto siginifica que \nla concentración interpolada se obtiene a partir de:\n\n$$\\hat{x} = \\frac{-b \\pm \\sqrt{b^2 - 4(a - y_{0})c}}{2c}$$\ndonde $y_{0}$ es la señal instrumental de la muestra problema.\n\n- $x_{i}$ es la concentración del estándar $i$\n\n- $\\overline{x} = \\sum_{i = 1}^{N} x_{i}$ es el promedio de las concentraciones \nde los calibrantes.\n\nFinalmente:\n\n$$\n\\begin{aligned}\nQ_{xx}  &= \\sum x_{i}^2 - \\frac{\\left(\\sum x_{i}\\right)^2}{N} \\\\\nQ_{x^3} &= \\sum x_{i}^3 - \\left(\\sum x_{i} \\times \\frac{\\sum x_{i}^2}{N}\\right) \\\\\nQ_{x^4} &= \\sum x_{i}^4 - \\frac{\\left(\\sum x_{i}^2\\right)^2}{N}\n\\end{aligned}\n$$\n\nOk, nada del otro mundo. Es bien fea, pero sólo son operaciones de aritmética\nbásica. Algunas observaciones:\n\nComo Ud. recordará en el caso de la calibración lineal, a partir de esta\necuación podemos inferir que si deseamos minimizar la incertidumbre de \ncalibración no lineal podemos :\n\n1. Aumentar el número de calibrantes $N$\n2. Aumentar el número de replicados independientes de la muestra problema $\\hat{N}$\n3. Aumentar la sensibilidad del método, que en el caso de la calibración\ncuadrática está dada por $b + 2c\\hat{x}$, es decir, depende de la concentración \nde la muestra problema $\\hat{x}$. En cambio, en la calibración lineal la \nsensibilidad era constante en todo el rango de concentración estudiado y \ncorrespondía a la pediente de la curva.\n\nEn el caso de la calibración lineal, la incertidumbre de calibración se minimiza\nen el centroide de la curva, en el caso del modelo cuadrático esto no siempre\nes así. Observe en la siguiente figura las bandas de confianza de ambos tipos de \ncalibración:\n\n```{r patch, echo = F}\nset.seed(123)\nx.sim <- seq(12, 66, by = 6)\ny.sim <- -5.621212e-03 + 10.670455e-03*x.sim + -0.304209e-05*x.sim^2 + \n  rnorm(length(x.sim), 0, 0.1)\nd.sim <- data.frame(x = x.sim, y = y.sim)\nfit.sim <- lm(y.sim ~ x.sim + I(x.sim^2))\nnolin.u.plot <- ggplot(d.sim, aes(x = x, y = y)) +\n  #geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = T, \n              formula = y ~ x + I(x^2), \n              fill = 'blue', \n              alpha = 0.2) +\n  xlab('Concentración [mg/L]') +\n  ylab('UA') +\n  ggtitle('Curva de calibración cuadrática') +\n  theme_bw()\n\n\nset.seed(123)\nx.sim <- seq(12, 66, by = 6)\ny.sim <- -5.621212e-03 + (10.670455e-03 + 2*0.304209e-05)*x.sim + \n  rnorm(length(x.sim), 0, 0.1)\nd.sim <- data.frame(x = x.sim, y = y.sim)\nfit.sim <- lm(y.sim ~ x.sim + I(x.sim^2))\nlin.u.plot <- ggplot(d.sim, aes(x = x, y = y)) +\n  #geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', \n              se = T, \n              fill = 'blue', \n              alpha = 0.2) +\n  xlab('Concentración [mg/L]') +\n  ylab('UA') +\n  ggtitle('Curva de calibración lineal') +\n  theme_bw()\n\nlibrary(patchwork)\n\nlin.u.plot + nolin.u.plot + plot_annotation(\n  title = 'Incertidumbre de calibración', \n  theme = theme(plot.title = element_text(hjust = 0.5)))\n```\n\nAdvierta que ambos modelos comparten la propiedad que la mayor incertidumbre se\nencuentra en los extremos. Sin embargo, en la calibración cuadrática, para este \nconjunto de datos, la menor incertidumbre no está en el centro de la curva.\n\nOk, a continuación implementaremos la ecuación de incertidumbre en `R` con los\ndatos del ejemplo de la sección 7 de la norma. La señal instrumental de la \nmuestra problema es $y_{0} = 0.084$ UA:\n\n```{r}\nN <- length(x) # Número de calibrantes\nN.hat <- 1     # Número de replicados de la muestra problema\nQxx <- sum(x^2) - sum(x)^2/N\nQx3 <- sum(x^3) -(sum(x) * sum(x^2)/N)\nQx4 <- sum(x^4) - sum(x^2)^2/N\n\na <- fit.nolineal$coefficients[1]\nb <- fit.nolineal$coefficients[2]\nc <- fit.nolineal$coefficients[3]\n\ns.y <- summary(fit.nolineal)$sigma # Es lo que R denomina Residual standard error\nt <- qt(0.975, N - 3) # El T de Student (¡Ya no se usan tablas!)\n\ny0 <- 0.084 # Es la señal instrumental de la muestra problema\nx.hat <- (-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c) # Concentración de la muestra\n\nIx <- (s.y * t)/(b + 2*c*x.hat) * sqrt(\n  1/N + 1/N.hat + ((x.hat - mean(x))^2*Qx4 + (x.hat^2 - sum(x^2)/N)^2 * Qxx -  \n  2*(x.hat - mean(x))*(x.hat^2 - sum(x^2)/N)*Qx3)/\n  (Qx4 * Qxx - Qx3^2)\n)\n\nIx <- unname(Ix) # Simplemente es para dejar sólo el número\n\n```\n\nLa concentración de la muestra es $\\hat{x} = `r round(x.hat, 2)`$ mg/L.\nAl aplicar esta metodología obtenemos una incertidumbre expandida de \n$I(\\hat{x}) = `r round(Ix, 2)`$ mg/L, es decir, exactamente la misma que la que \nindica la norma ISO. Note que si Ud. quisiera combinar esta incertidumbre de \ncalibración con algún otro factor (p.ej: masa de la muestra, volumen de aforo, \netc.) debe primero tansformarla en incertidumbre estándar, dividiéndola por el \nfactor de cobertura $k$, que en este caso corresponde al t Student con $N - 3$ \ngrados de libertad al 95% de confianza (k = `r round(qt(0.975, N - 3), 2)`):\n\n$$\nu_{\\hat{x}} = \\frac{U_{\\hat{x}}}{k} = `r round(Ix/t, 2)`\\, \\, \\text{mg/L}\n$$\nPor lo tanto, si tuviéramos que informar el resultado de la concentración\nde la muestra interpolada en la curva de calibración no lineal informaríamos\n$`r round(x.hat, 2)` \\pm `r round(Ix, 2)`$ mg/L [*nota mental: mmmm... esto de\nlas cifras significativas da para otro post, pero dejémoslo así por ahora. \nNo olvidar borrar este comentario.*]\n\n¿Cómo varía esta incertidumbre de calibración no lineal con la concentración de\nla muestra? La siguiente figura muestra esta variación:\n\n```{r u.vs.con}\nx <- seq(12, 66, by = 6) # Rango de concentración\nN <- length(x)\nN.hat <- 1\nmu.x <- mean(x) # promedio de las concentraciones de los calibrantes\nsq.x <- sum(x^2) # suma de las concentraciones de los calibrantes al cuadrado\nQxx <- sum(x^2) - sum(x)^2/N\nQx3 <- sum(x^3) -(sum(x) * sum(x^2)/N)\nQx4 <- sum(x^4) - sum(x^2)^2/N\nt <- qt(0.975, N - 3)\n\n# Para graficar la incertidumbre vs concentración, primero debemos crear una\n# función que tome un X (una concentración) y calcule el Y (incertidumbre)\nUx <- function(x) {\n    U <- s.y*t/(b + 2*c*x) * sqrt(\n    1/N + 1/N.hat + ((x - mu.x)^2*Qx4 + (x^2 - sq.x/N)^2 * Qxx -  \n    2*(x - mu.x)*(x^2 - sq.x/N)*Qx3)/\n    (Qx4 * Qxx - Qx3^2))\n    return(unname(U))\n}\n\n# Graficamos concentración (X) vs Incertidumbre (Y)\n\nplot(x, Ux(x), type = 'n',\n     main = 'Concentración vs Incertidumbre de calibración',\n     xlab = 'Concentración [mg/L]',\n     ylab = 'Incertidumbre expandida [mg/L]')\nlines(spline(x, Ux(x)), col = 'red')\n```\nSe aprecia que la incertidumbre aumenta con la concentración en una forma no \nconstante para concentraciones mayores a 20 mg/L. \nTal como mencionamos anteriormente, el mínimo no se encuentra en el \ncentro del rango de concentración como ocurre con la calibración lineal. Para \nencontrar el valor exacto de concentración que minimiza la incertidumbre en este \nrango, usamos el comando `optimize`:\n\n```{r}\n# Busca el mínimo de la función Ux en el intervalo de 12 a 66 mg/L\noptimize(Ux, interval = c(12, 66))\n```\n\nLa concentración que minimiza la incertidumbre es \n`r round(optimize(Ux, interval = c(12, 66))$minimum, 2)` mg/L.\n\n\nMuy entretenido, pero la vida es corta y debemos ser eficientes por lo tanto, \npara evitarnos el \"tedio\" de implementar la fórmula a mano, utilizaremos\nel package `investr` el cual calcula exactamente la incertidumbre de \ncalibración de un gran número de modelos de calibración, entre ellos, los \nmodelos cuadráticos:\n\n```{r investr.u}\n# y0 es la señal de la muestra problema y0 = 0.084 UA\nlibrary(investr) # Cargamos la librería investr\nx.hat <- invest(fit.nolineal, data = d, y0 = y0, interval = 'Wald')\nx.hat\n```\n\ndonde:\n\n- `estimate` es la concentración de la muestra problema\n- `upper` es el extremo superior de la incertidumbre expandida $I(\\hat{x})$\n- `lower` es el extremo inferior de la incertidumbre expandida $I(\\hat{x})$\n- `se` es la incertidumbre estándar de calibración $u_{\\hat{x}}$, la cual es \nexactamente igual a la obtenida por la fórmula anterior\n$u_{\\hat{x}} = \\frac{U_{\\hat{x}}}{k} = `r round(Ix/t, 2)`\\, \\, \\text{mg/L}$\n\nNote que si quisiéramos obener $I(\\hat{x})$ a partir de esta tabla, tendríamos \nque hacer la siguiente operación $I(\\hat{x}) =$ `upper` - `estimate`:\n\n```{r}\nx.hat$upper - x.hat$estimate\n```\n\n\nNo podemos usar el package `chemCal` que utilizamos\nen un [post anterior](https://www.analytical.cl/post/como-calcular-la-incertidumbre-de-una-curva-de-calibracion/) \npara estimar la incertidumbre de calibración, porque este package sólo soporta \ncalibraciones lineales.\n\n\n## Estimación de incertidumbre mediante Guía ISO GUM\n\nYa que la señal instrumental es una función de la concentración, entonces, \npodemos utilizar la aproximación ISO GUM clásica para estimar la incertidumbre\nde calibración. Por \"clásica\" me refiero a utilizar la aproximación de Taylor\ncon las derivadas parciales. Esta guía dice lo siguiente:\n\n1. Expresar el mensurando como una ecuación de medición a través de una relación\nfuncional con las magnitudes de entrada. En este caso el mensurando es la \nconcentración $\\hat{x}$ cuya ecuación de medición es la solución de la ecuación\ncuadrática $y_{0} = a + b\\hat{x} + c\\hat{x^2}$ donde $y_{0}$ es la señal de la \nmuestra problema:\n\n$$\n\\hat{x} = \\frac{-b \\pm \\sqrt{b^2 - 4(a - y_{0})c}}{2c}\n$$\n2. Identificación de las fuentes de incertidumbre. Al observar la ecuación de \nmedición identificamos las siguientes fuentes de incertidumbre:\n\n- Parámetros del modelo cuadrático: $a$, $b$ y $c$\n- Señal instrumental de la muestra problema $y_{0}$\n\n3. Evaluación de las fuentes de incertidumbre: \n\n- Las incertidumbres estándar de los parámetros del modelo pueden ser obtenidas\ndirectamente del ajuste cuadrático `fit.nolineal`:\n\n```{r u.param}\n# parámetros del modelo\na <- fit.nolineal$coeff[1]\nb <- fit.nolineal$coeff[2]\nc <- fit.nolineal$coeff[3]\n\n# las incertidumbres estándar de a, b y c las obtenemos con la función summary\nua <- summary(fit.nolineal)$coefficients[1, 2]\nub <- summary(fit.nolineal)$coefficients[2, 2]\nuc <- summary(fit.nolineal)$coefficients[3, 2]\n```\n\n\n- La incertidumbre estándar de la señal instrumental de la muestra problema\ntambién puede obtenerse del ajuste cuadrático y corresponde a la \ndesviación estándar residual:\n\n```{r u.y0}\nuy0 <- summary(fit.nolineal)$sigma\ny0 <- 0.084 # dato del problema, es decir, la absorbancia de la muestra\n```\n\n4. Determinación de la incertidumbre estándar combinada $u_{\\hat{x}}$ a través \nde la expresión:\n\n$$\nu_{\\hat{x}}^2 = \\left( \\frac{\\partial{\\hat{x}}}{\\partial{y_{0}}}\\right) ^{2} (u_{y_{0}})^{2} + \n\\left( \\frac{\\partial{\\hat{x}}}{\\partial{a}}\\right) ^{2} (u_{a})^{2} + \n\\left( \\frac{\\partial{\\hat{x}}}{\\partial{b}}\\right) ^{2} (u_{b})^{2} +\n\\left( \\frac{\\partial{\\hat{x}}}{\\partial{c}}\\right )^{2} (u_{c})^{2}\n$$\n\n\"sólo\" nos falta obtener las derivadas parciales (aguante ese código $\\LaTeX$):\n\n$$\n\\begin{aligned}\n\\frac{\\partial{\\hat{x}}}{\\partial{y_{0}}} &= \n\\frac{1}{\\sqrt{b^{2} - 4c(a-y_{0})}} \\\\\n\\frac{\\partial{\\hat{x}}}{\\partial{a}} &=\n  \\frac{-1}{\\sqrt{b^{2} - 4c(a-y_{0})}} \\\\\n\\frac{\\partial{\\hat{x}}}{\\partial{b}} &=\n\\frac{-1 + \\frac{b}{\\sqrt{b^{2} - 4c(a-y_{0})}}}{2c} \\\\\n\\frac{\\partial{\\hat{x}}}{\\partial{c}} &=\n  \\frac{-a + y_{0}}{c\\sqrt{b^{2} - 4c(a-y_{0})}} - \n  \\frac{-b + \\sqrt{b^{2} - 4c(a-y_{0})}}{2c^{2}}\n\\end{aligned}\n$$\n\n¡Listo! ahora debemos evaluar las expresiones. Pero como soy flojo, \nprefiero usar el excelente package `metRology` que hará todo el trabajo por\nmí:\n\n```{r u.GUM}\nlibrary(metRology) # cargamos la librería\n\nexpr <- expression((-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c)) # ecuación de medición\nx <- list(a = a, b = b, c = c, y0 = y0) # valores de cada X input\nu <- c(ua, ub, uc, uy0) # incertidumbres estándar de cada X input\nu.GUM <- uncert(expr, x, u, method = 'GUM') # Usamos el método GUM\nu.GUM\n\n```\n\n¿What? ¿Por qué obtuvimos una incertidumbre estándar de `r round(u.GUM$u.y, 3)` \ny no la que calculamos con la ecuación de la norma ISO `r round(Ix/t, 3)`?\nPor la sencilla razón de que los parámetros de un modelo cuadrático no son\nindependientes, sus covarianzas no son 0. Es más, algunas de las covarianzas\nson negativas. Observe la siguiente figura que fue obtenida simulando \ncurvas de calibración cuadráticas. En la figura se muestra las correlaciones\nentre los tres parámetros del modelo no lineal:\n\n```{r}\n# Simularemos p = 200 curvas de calibración cuadráticas a partir de los datos \n# empíricos \n\np <- 200 # Número de simulaciones\na.sim <- numeric(p) # vector que guardará el parámetro a\nb.sim <- numeric(p) # vector que guardará el parámetro b\nc.sim <- numeric(p) # vector que guardará el parámetro c\n\n# Hacemos un loop\nfor(i in 1:p){\n  x.sim <- seq(12, 66, by = 6)\n  y.sim <- a + b*x.sim + c*x.sim^2 + rnorm(length(x.sim), 0, uy0)\n  fit.nolineal.sim <- lm(y.sim ~ x.sim + I(x.sim^2))\n  a.sim[i] <- fit.nolineal.sim$coeff[1]\n  b.sim[i] <- fit.nolineal.sim$coeff[2]\n  c.sim[i] <- fit.nolineal.sim$coeff[3]\n}\n\n# guardamos los parámetros simulados en un data frame que llamamos param.sim\nparam.sim <- data.frame(a.sim, b.sim, c.sim) \n                                                \n# graficamos los parámetros simulados\nplot(param.sim)\n```\n\n\nSe advierte claramente que existe una correlación negativa entre los parámetros\n$a$ y $b$, además entre $b$ y $c$. La correlación entre $a$ y $c$ es positiva.\nEn rigor, habría que incorporar las derivadas parciales cruzadas y las \ncovarianzas entre los parámetros. De sólo pensarlo, me dan ganas de \nprocastinar aún más la escritura de este post, así que recurriremos al \npackage `metRology`.\n\nLa parte \"fácil\" es obtener la matriz de covarianzas de los parámetros del\nmodelo con el comando `vcov`:\n\n```{r vcov}\nv <- vcov(fit.nolineal)\ncolnames(v) <- c('a', 'b', 'c') # solo cosmética para que aparezcan los nombres\nrownames(v) <- c('a', 'b', 'c') # de los parámetros (es opcional)\nv\n```\n\nLa diagonal de esta matriz es precisamente la incertidumbre estándar al \ncuadrado de los parámetros (a.k.a sus varianzas). Si queremos, también podemos\nexpresarla como matriz de correlaciones con el comando `cov2cor`:\n\n```{r corr}\nparam.cor <- cov2cor(v)\nparam.cor\n```\n\nEn la diagonal de esta matriz obviamente esperamos correlación 1. Se observa\nclaramente la alta correlación entre los parámetros, como dijimos anteriormente, \nalgunas de ellas son negativas.\n\nLa parte \"difícil\" es que debemos incorporar la variable señal\ninstrumental de la muestra problema $y_{0}$, la cual obviamente es independiente \nde los parámetros del modelo:\n\n\n```{r u.gum.cov}\n# Incorporamos la variable y0 que es independiente de los parámetros\nv <- rbind(v, y0 = rep(0, 3)) \nv <- cbind(v, y0 = rep(0, 4))\nv[4, 4] <- uy0^2 # Asignamos al elemento de la 4a fila y 4a columna  \n                 # la varianza de y0\nv\n```\n\nAhora, incorporamos las covarianzas en el cálculo por método GUM:\n\n```{r, eval = T}\nu.GUM.cov <- uncert(expr, x, cov = v, method = \"GUM\")\nu.GUM.cov\n```\n\n¡Perfecto!, ahora sí, al incluir las covarianzas obtenemos resultados consistentes \ncon el método descrito en la norma ISO 8466-2.\n\n## Estimación con el Método de Monte Carlo\n\nNo detallaremos aquí cómo funciona el método de Monte Carlo, puede consultarlo \nen [este post](https://www.analytical.cl/post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo/) y en \n[este otro](https://www.analytical.cl/post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/).\n\nSería super simple si usamos el package `metRology`, el problema es que el \npackage lanza un error numérico cuando existen covarianzas negativas. Probé \nel ejemplo que incluye el manual de `metRology` y el error se repite. Es un \nproblema al evaluar la suma de las correlaciones. Le \nconsulté al autor Steve Ellison, sin embargo, a la fecha (09 de junio 2020) \naún no tengo respuesta, a pesar de que Steve siempre responde las consultas en\nforma muy expedita. Otros usuarios han tenido un problema similar y se ha \nabierto un hilo en [stackoverflow](https://stackoverflow.com/questions/60971950/error-in-eigensigma-symmetric-true-0-x-0-matrix-in-metrology-uncertmc-wit/62119518#62119518).\n\nPor lo tanto, implementamos el método de Monte Carlo \"a mano\" utilizando el \npackage `MASS` el cual permite generar muestras aleatorias multivariadas \nincluyendo las correlaciones:\n\n```{r u.MC.sim}\n# No funciona metRology MC así que lo hicimos a mano\nlibrary(MASS) # cargamos la librería\n\n# Generamos n muestras aleatorias multivariadas, cuyas medias \n# corresponden a los valores de a, b, c e y0\n# La matriz de covarianza Sigma = v la calculamos anteriormente\n\nset.seed(123) # Para que Ud. obtenga los mismos resultados\nmuestra.MC <- mvrnorm(n = 10000, mu = c(a, b, c, y0), Sigma = v, empirical = T)\ncolnames(muestra.MC) <- c('a', 'b', 'c', 'y0') # solo cosmética\nmuestra.MC <- data.frame(muestra.MC) # lo guardamos como data.frame\nhead(muestra.MC) # muestra las primeras n = 6 simulaciones\n\n```\n\nCada fila es una simulación. Si, por ejemplo, calculamos el promedio de cada\nvariable simulada, obtenemos un valor similar a los valores empíricos. A mayor \nnúmero de simulaciones, más nos acercamos a valores que asumimos como\nverdaderos.\n\n```{r}\napply(muestra.MC, 2, mean) # promedio de cada columna\n```\n\nBien, lo que tenemos que hacer es que en cada simulación debemos \ncalcular la concentración de la muestra:\n\n\n```{r u.MC}\n# cargaré estas librerías sólo para facilitar la manipulación de los datos\nlibrary(magrittr)\nlibrary(tidyverse)\n\n# Creamos una nueva variable llamada x.hat que corresponde a la concentración de\n# la muestra\nmuestra.MC <- muestra.MC %>% \n  mutate(x.hat = (-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c))\nhead(muestra.MC) # muestra las primeras n = 6 simulaciones\n```\n\nLa última columna corresponde a la concentración calculada para cada \nsimulación. Por lo tanto, si queremos obtener la incertidumbre estándar de \nla concentración, basta calcular la desviación estándar de esa columna:\n\n```{r}\nmu.x.hat.MC <- mean(muestra.MC$x.hat) # valor promedio de concentración\nu.x.hat.MC <- sd(muestra.MC$x.hat) # incertidumbre estándar de la concentración\nu.x.hat.MC\n```\n\nSe obtiene una incertidumbre estándar de calibración de \n`r round(u.x.hat.MC, 3)` mg/L, la\ncual es consistente con los otros métodos estudiados. La siguiente\nfigura muestra el histograma de las concentraciones simuladas:\n\n\n```{r plot.u.MC}\nhist(muestra.MC$x.hat, \n     breaks = 20,\n     main = 'Concentraciones simuladas por Monte Carlo',\n     xlab = 'Concentración [mg/L]')\n```\n\n\nFinalmente, la siguiente tabla resume los resultados de los tres métodos \nconsiderando la incertidumbre estándar de calibración:\n\n```{r tabla}\ntabla <- data.frame(Ix/t, u.GUM$u.y, u.GUM.cov$u.y, u.x.hat.MC)\nknitr::kable(tabla, \n             rownames = NA,\n             col.names = c('ISO', 'GUM', 'GUM/Covarianzas', 'Monte Carlo'),\n             align = 'l')\n```\n\nSe aprecia claramente una excelente concordancia entre los tres métodos.\nSin embargo, para que el método GUM entregue resultados correctos, es necesario\nincorporar las covarianzas entre las variables input.\n\nEn un próximo post exploraremos el método _Bootstrap_, un método estadístico \npor excelencia para estimar incertidumbre sin utilizar un modelo de medición...\n\n> ¡Dejad que los datos hablen!\n\n# Bibliografía\n\n1. Norma ISO 8466-2:2001 *Water quality -- Calibration and evaluation of \nanalytical methods and estimation of performance characteristics -- Part 2: \nCalibration strategy for non-linear second-order calibration functions.*\n\n2.  Brandon M. Greenwell and Christine M. Schubert Kabban (2014). investr: An R\nPackage for Inverse Estimation. The R Journal, 6(1), 90-100. URL http://journal.r-project.org/archive/2014-1/greenwell-kabban.pdf.\n\n3. NIST/SEMATECH e-Handbook of Statistical Methods, \n_Uncertainty for quadratic calibration using propagation of error_,\nhttps://www.itl.nist.gov/div898/handbook/mpc/section3/mpc3671.htm, \n09 de junio 2020.\n\n4. Nonlinear multivariate calibration methods in analytical chemistry\nSonja Sekulic, Mary Beth Seasholtz, Ziyi Wang, Bruce R. Kowalski, Samuel E. \nLee, and Bradley R. Holt _Analytical Chemistry 1993 65 (19), 835A-845A_","srcMarkdownNoYaml":"\n\nEn un [post anterior](https://www.analytical.cl/post/como-calcular-la-incertidumbre-de-una-curva-de-calibracion/) \nrevisamos cómo estimar la incertidumbre de la concentración \nde una muestra problema, cuando ésta ha sido obtenida interpolando la señal \ninstrumental en una curva de calibración lineal.\n\nLa expresión es relativamente simple y vimos también cómo podemos implementarla\nen el lenguaje de programación `R` a través del package `chemCal`.\n\nSin embargo, la vida no es tan sencilla. Recoradará estimad@ lector@ que está \nbastante documentada la presencia de desviaciones de la linealidad \na altas concentraciones, fenómeno muy conocido en los métodos \nespectrofotométricos (Ley de Lambert-Beer). La severidad de estas desviaciones \nvaría en función del detector, el analito y otros factores físico-químicos\ndel sistema de medición.\n\nCuando existen estas desviaciones y deseamos llevar a cabo un \n[test de linealidad](https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/),\nes muy probable que el test rechace el modelo lineal, por lo tanto, no podemos\nestimar la incertidumbre de calibración asumiendo este modelo. Si bien es cierto\npodemos reducir el rango lineal y diluir la muestra problema que está fuera\ndel rango, la operación de dilución introduce nuevos errores (incluso errores \nhumanos de transcripción bastante frecuentes).\n\nUna alternativa válida sería utilizar un modelo de calibración que capture esta\nno linealidad evitando así la dilución de la muestra, \npor lo tanto el problema se reduce a:\n\n> ¿Cómo estimar la incertidumbre de una muestra problema que ha sido\n> obtenida a través de una curva de calibración no lineal?\n\nSin embargo, de esta pregunta se desprende al mismo tiempo otra interrogante:\n\n> ¿Cuál modelo de calibración no lineal utilizaré?\n\nExisten varios modelos de calibración no lineal:\n\n1. Polinomios\n2. New Rational (en realidad se llaman *aproximaciones de Padé*)\n3. Splines\n4. Loess\n5. etc.\n\n\nPor lo tanto, no existe una respuesta completamente correcta desde \nla prespectiva estadística, pues un modelo cuadrático sería tan válido como \nun polinomio cúbico. Desde el punto de vista químico podríamos preguntarnos\n¿qué sentido químico tiene una curva de calibración polinómica de grado 5?\n¿Son interpretables los parámetros del modelo? En un modelo lineal como el \nde Lambert-Beer: $y = \\beta_{0} + \\beta_{1}x$ la pendiente de la curva de \ncalibración tiene una interpretación química: es el producto entre coeficiente \nde extinción molar y la longitud de la celda:\n\n$$\n\\underbrace{A}_\\text{y} = \\underbrace{\\epsilon \\cdot b}_\\text{$\\beta_{1}$} \\cdot\n\\underbrace{C}_\\text{x}\n(\\#eq:lambert)\n$$\nPero recuerde este sabio consejo de un monstruo de la estadística aplicada:\n\n> *\"All models are wrong, but some are useful\"*\n> -- <cite>George Box</cite>\n\nPor lo tanto, tenemos que tomar una decisión. Y obviamente, como soy el autor de\neste humilde post, ya la tomé por Ud. En este artículo estimaremos la \nincertidumbre de calibración de un modelo polinómico de grado 2, también \nconocido como modelo cuadrático.\n\nNota: Desde el punto de vista **estrictamente estadístico** los modelos \npolinómicos, como la calibración cuadrática, son también modelos lineales ya que \nlos coeficientes del modelo son lineales\n\n$$y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^2 + \\epsilon$$\n\nEn cambio, en un modelo del tipo exponencial:\n\n$$y = \\beta_{0}\\cdot e^{\\beta_{1}x}$$\n\nEl coeficiente $\\beta_{1}$ no es una función lineal.\n\n# Métodos de estimación de incertidumbre de calibración\n\nEn este post ejemplificaremos y compararemos tres métodos de estimación\nde incertidumbre de calibración:\n\n1. Norma ISO 8466-2:2001 *Water quality -- Calibration and evaluation of \nanalytical methods and estimation of performance characteristics -- Part 2: \nCalibration strategy for non-linear second-order calibration functions.*\n\n2. Método GUM\n\n3. Método de Monte Carlo (Suplemento 1 ISO-GUM)\n\nImplementaremos todos los métodos en el lenguaje de programación `R`, explicando\npaso a paso el código fuente con el fin de que Ud. obtenga los mismos \nresultados, es decir, un **análisis reproducible**.\n\n# Datos de calibración\n\nPara ejemplificar los cálculos, utilizaremos los datos de calibración indicados\nen el ejemplo de la sección 7 de la norma ISO 8466-2. El siguiente código `R` \nnos permite ingresar los datos manualmente:\n\n```{r data}\n# Ingresamos los datos de calibración de la sección 7 de la norma ISO 8466-2\n# x: concentración en mg/L\n# y: Absorbancia [UA]\n\nx <- c(12, 18, 24, 30, 36, 42, 48, 54, 60, 66)\ny <- c(0.083, 0.123, 0.164, 0.203, 0.240, 0.273, 0.303, 0.334, 0.364, 0.393)\n\nd <- data.frame(x, y) # creamos un data frame con las variables x e y (esto es\n                      # análogo a una matriz de datos en Excel con dos columnas)\n```\n\nA continuación graficamos la curva de calibración con la librería `ggplot2`:\n\n```{r}\nlibrary(ggplot2) # cargamos la librería ggplot2\n\ntheme_set(theme_minimal()) # esto es sólo por una cuestión estética del gráfico\n\nggplot(d, aes(x = x, y = y)) +\n  geom_point(color = 'red') +\n  xlab('Concentración [mg/L]') +\n  ylab('Absorbancia [UA]')\n\n```\n\nMmm... no sé Ud. pero yo veo una leve curvatura.\nComo lo vimos en un [post anterior](https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/)\nllevaremos a cabo un análisis estadístico básico para evaluar si el modelo de\ncalibración lineal es adecuado, o si nos inclinamos por la hipótesis de no \nlinealidad.\n\nComo no tenemos replicados de cada punto de calibración, haremos un Test de \nLinealidad de Mandel. Lo primero, es ajustar un modelo lineal a los datos \n$y = a + bx$:\n\n```{r fit.lineal}\nfit.lineal <- lm(y ~ x, data = d) # ajustamos un modelo lineal y lo guardamos \n                                  # con el nombre fit.lineal\n\nsummary(fit.lineal) # para ver el análisis estadístico del ajuste\n```\n\nEsta tabla nos dice que el intercepto del modelo es \n$a = `r fit.lineal$coeff[1]`$ y la pendiente $b = `r fit.lineal$coeff[2]`$.\nNote el alto coeficiente de determinación \n$r^{2} = `r round(summary(fit.lineal)$r.square, 4)`$ lo cual indica que es un \nbuen modelo. El coeficiente de correlación es \n$r = `r round(sqrt(summary(fit.lineal)$r.square), 3)`$ que si bien es un dato a\nconsiderar, no es una prueba formal de linealidad.\n\nLa siguiente figura muestra el ajuste lineal sobre los datos de calibración:\n\n```{r plot.lineal}\nlibrary(ggpmisc) # para escribir ecuaciones dentro del gráfico\n\nggplot(d, aes(x = x, y = y)) +\n  geom_point(color = 'red') +\n  geom_smooth(method = 'lm', se = F, \n              size = 0.5) + # dibuja la curva de calibración lineal\n  xlab('Concentración [mg/L]') +\n  ylab('Absorbancia [UA]') +\n  stat_poly_eq(aes(label =  paste(stat(eq.label), stat(rr.label), \n                                  sep = \"*\\\", \\\"*\")), \n               formula = y ~ x, \n               parse = TRUE, \n               rr.digits = 4)\n```\n\nSe observa que el ajuste lineal no es un buen modelo, pues no captura la \ncurvatura de los datos a pesar del alto coeficiente de correlación. \nEsto se oberva más claramente si obervamos el gráfico\nde residuos:\n\n```{r fit.lin.res}\nplot(fit.lineal, which = 1, add.smooth = F, pch = 19, col = 'red', \n     main = 'Gráfico de residuos modelo lineal')\n```\n\nLa evidencia en contra del modelo lineal es abrumadora, el gráfico muestra \nclaramente un patrón en los residuos que indica que el modelo lineal \nno es adecuado. Sin embargo, a pesar de la evidencia, haremos el Test de Mandel\npara \"comprobar\" esta hipótesis. Para aplicar el Test de Mandel debemos ahora \najustar el modelo cuadrático y compararlo con el modelo lineal.\nPara ser consistentes en la notación de la\nnorma ISO 8466-2, definiremos el modelo de calibración cuadrático como:\n\n$$ \ny = a + bx + cx^2\n$$\n\n```{r fit.cuad}\nfit.nolineal <- lm(y ~ x + I(x^2), data = d) # ajuste cuadrático y los guardamos \n                                          # con el nombre fit.nolineal\nsummary(fit.nolineal)\n```\n\nSe obtiene una tabla similar que la del modelo lineal, con la adición del \ncoeficiente que acompaña al \n$x^2$: `I(x^2)` $= `r round(fit.nolineal$coeff[3], 8)`$. Note\nque el coeficiente de determinación del modelo cuadrático es mayor que el \ndel modelo lineal. Esto siempre se cumplirá, lo que hace el Test de Mandel es\ndiscernir si esta \"mejora\" en el modelo es \"significativa\". \n\nLa siguiente figura muestra el ajuste no lineal, el cual captura mucho mejor\nla curvatura de los datos:\n\n```{r plot.nolineal}\nggplot(d, aes(x = x, y = y)) +\n  geom_point(color = 'red') +\n  geom_smooth(method = 'lm',         # dibuja la curva de calibración no lineal\n              se = F, \n              formula = y ~ x + I(x^2), size = 0.5) + \n  xlab('Concentración [mg/L]') +\n  ylab('Absorbancia [UA]') +\n  stat_poly_eq(aes(label =  paste(stat(eq.label), stat(rr.label), \n                                  sep = \"*\\\", \\\"*\")),\n               formula = y ~ x + I(x^2), \n               parse = TRUE, \n               rr.digits = 4)\n```\n\n\nOk, aplicamos\nel Test de Mandel con el comando `anova`:\n\n```{r mandel}\nanova(fit.lineal, fit.nolineal)\n```\n\n```{r p.mandel, echo = F}\np.mandel <- anova(fit.lineal, fit.nolineal)$`Pr(>F)`[2]\n```\n\nEl p-value del test de Mandel es $`r round(p.mandel, 8)`$, el cual de acuerdo a \nla interpretación tradicional, indica que el modelo lineal no es adecuado para \nlos datos de calibración.\n\nProcedamos, entonces, a estimar la incertidumbre de la concentración $\\hat{x}$\nde una muestra problema, cuyo valor fue obtenido interpolando la señal \ninstrumental en el modelo de calibración no lineal.\n\n## Estimación de incertidumbre de acuerdo a ISO 8466-2\n\nDesde el punto de vista metrológico, la aproximación que indica esta norma es \nsimilar a lo que dicta la guía ISO GUM clásica, es decir, \nestima la incertidumbre a partir de un modelo de medición $y = f(x)$. \nLa \"gracia\" de esta norma es que nos \nahorra tinta, pues la ecuación de incertidumbre ya está \"algebraicamente \nmanipulada\". No entraremos en los detalles de las primeras secciones de la\nnorma los cuales estudian el comportamiento de la curvatura, es decir, si será\nposible encontrar un máximo o un mínimo, lo cual es clave en la utilidad del \nmodelo cuadrático como función de calibración. Esto es\nimportante porque recuerde que una función parabólica tiene dos soluciones, si \nexistiera un máximo o un mínimo en el rango de trabajo, el modelo cuadrático no \npuede ser utilizado como función de calibración.\n\nLa siguiente ecuación calcula la **incertidumbre expandida** \n$I(\\hat{x}) = U_{\\hat{x}}$ de la concentración de la muestra problema $\\hat{x}$, \ninterpolada en la curva de calibración no lineal $y = a + bx + cx^2$. \nCorresponde a la ecuación (27) de la norma:\n\n\n$$\nI(\\hat{x}) = \\frac{s_{y} \\cdot t_{n - 3,\\, 95\\%}}{b + 2c\\hat{x}} \\cdot\n            \\sqrt{\\frac{1}{N} + \\frac{1}{\\hat{N}} + \n            \\frac{(\\hat{x} - \\overline{x})^2 \\, Q_{x^4} + \n            \\left(\\hat{x}^2 - \\frac{\\sum x_{i}^{2}}{N} \\right)^2 Q_{xx} -\n            2(\\hat{x} - \\overline{x}) \n            \\left(\\hat{x}^2 - \\frac{\\sum x_{i}^{2}}{N} \\right) Q_{x^3}}\n            {Q_{x^4} Q_{xx} - \\left( Q_{x^3} \\right)^2}}\n$$\n\ndonde:\n\n$$\ns_{y} = \\sqrt{\\frac{\\sum (y_{i} -\\hat{y})^2}{N - 3}}\n$$\n\n- $y_{i}$ es la respuesta experimental observada del estándar $i$, $\\hat{y}$ es la\nrespuesta instrumental que predice el modelo para el mismo estándar $i$, por lo\ntanto $e_{i} = y_{i} - \\hat{y}$ es el residuo. $N$ es el número de calibrantes. \n¿Por qué el denominador es $N - 3$ y no $N -2$ como en la calibración lineal? \nPorque el modelo cuadrático posee tres parámetros $a$, $b$ y $c$.\n\n- $t_{N - 3,\\, 95\\%}$ es el valor del T de Student con $N - 3$ grados de \nlibertad y un 95% de confianza.\n\n- $\\hat{N}$ es el número de replicados \nindependientes de la muestra problema. Como discutimos en \n[otro post](https://www.analytical.cl/post/como-calcular-la-incertidumbre-de-una-curva-de-calibracion/), \nesto no corresponde a inyectar $\\hat{N}$ veces la misma muestra en el \ninstrumento.\n\n- $\\hat{x}$ es la concentración de la muestra problema interpolada en la curva\nde calibración no lineal, la cual se obtiene resolviendo la ecuación\ncuadrática. Como Ud. recordará de sus años mozos esto siginifica que \nla concentración interpolada se obtiene a partir de:\n\n$$\\hat{x} = \\frac{-b \\pm \\sqrt{b^2 - 4(a - y_{0})c}}{2c}$$\ndonde $y_{0}$ es la señal instrumental de la muestra problema.\n\n- $x_{i}$ es la concentración del estándar $i$\n\n- $\\overline{x} = \\sum_{i = 1}^{N} x_{i}$ es el promedio de las concentraciones \nde los calibrantes.\n\nFinalmente:\n\n$$\n\\begin{aligned}\nQ_{xx}  &= \\sum x_{i}^2 - \\frac{\\left(\\sum x_{i}\\right)^2}{N} \\\\\nQ_{x^3} &= \\sum x_{i}^3 - \\left(\\sum x_{i} \\times \\frac{\\sum x_{i}^2}{N}\\right) \\\\\nQ_{x^4} &= \\sum x_{i}^4 - \\frac{\\left(\\sum x_{i}^2\\right)^2}{N}\n\\end{aligned}\n$$\n\nOk, nada del otro mundo. Es bien fea, pero sólo son operaciones de aritmética\nbásica. Algunas observaciones:\n\nComo Ud. recordará en el caso de la calibración lineal, a partir de esta\necuación podemos inferir que si deseamos minimizar la incertidumbre de \ncalibración no lineal podemos :\n\n1. Aumentar el número de calibrantes $N$\n2. Aumentar el número de replicados independientes de la muestra problema $\\hat{N}$\n3. Aumentar la sensibilidad del método, que en el caso de la calibración\ncuadrática está dada por $b + 2c\\hat{x}$, es decir, depende de la concentración \nde la muestra problema $\\hat{x}$. En cambio, en la calibración lineal la \nsensibilidad era constante en todo el rango de concentración estudiado y \ncorrespondía a la pediente de la curva.\n\nEn el caso de la calibración lineal, la incertidumbre de calibración se minimiza\nen el centroide de la curva, en el caso del modelo cuadrático esto no siempre\nes así. Observe en la siguiente figura las bandas de confianza de ambos tipos de \ncalibración:\n\n```{r patch, echo = F}\nset.seed(123)\nx.sim <- seq(12, 66, by = 6)\ny.sim <- -5.621212e-03 + 10.670455e-03*x.sim + -0.304209e-05*x.sim^2 + \n  rnorm(length(x.sim), 0, 0.1)\nd.sim <- data.frame(x = x.sim, y = y.sim)\nfit.sim <- lm(y.sim ~ x.sim + I(x.sim^2))\nnolin.u.plot <- ggplot(d.sim, aes(x = x, y = y)) +\n  #geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = T, \n              formula = y ~ x + I(x^2), \n              fill = 'blue', \n              alpha = 0.2) +\n  xlab('Concentración [mg/L]') +\n  ylab('UA') +\n  ggtitle('Curva de calibración cuadrática') +\n  theme_bw()\n\n\nset.seed(123)\nx.sim <- seq(12, 66, by = 6)\ny.sim <- -5.621212e-03 + (10.670455e-03 + 2*0.304209e-05)*x.sim + \n  rnorm(length(x.sim), 0, 0.1)\nd.sim <- data.frame(x = x.sim, y = y.sim)\nfit.sim <- lm(y.sim ~ x.sim + I(x.sim^2))\nlin.u.plot <- ggplot(d.sim, aes(x = x, y = y)) +\n  #geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', \n              se = T, \n              fill = 'blue', \n              alpha = 0.2) +\n  xlab('Concentración [mg/L]') +\n  ylab('UA') +\n  ggtitle('Curva de calibración lineal') +\n  theme_bw()\n\nlibrary(patchwork)\n\nlin.u.plot + nolin.u.plot + plot_annotation(\n  title = 'Incertidumbre de calibración', \n  theme = theme(plot.title = element_text(hjust = 0.5)))\n```\n\nAdvierta que ambos modelos comparten la propiedad que la mayor incertidumbre se\nencuentra en los extremos. Sin embargo, en la calibración cuadrática, para este \nconjunto de datos, la menor incertidumbre no está en el centro de la curva.\n\nOk, a continuación implementaremos la ecuación de incertidumbre en `R` con los\ndatos del ejemplo de la sección 7 de la norma. La señal instrumental de la \nmuestra problema es $y_{0} = 0.084$ UA:\n\n```{r}\nN <- length(x) # Número de calibrantes\nN.hat <- 1     # Número de replicados de la muestra problema\nQxx <- sum(x^2) - sum(x)^2/N\nQx3 <- sum(x^3) -(sum(x) * sum(x^2)/N)\nQx4 <- sum(x^4) - sum(x^2)^2/N\n\na <- fit.nolineal$coefficients[1]\nb <- fit.nolineal$coefficients[2]\nc <- fit.nolineal$coefficients[3]\n\ns.y <- summary(fit.nolineal)$sigma # Es lo que R denomina Residual standard error\nt <- qt(0.975, N - 3) # El T de Student (¡Ya no se usan tablas!)\n\ny0 <- 0.084 # Es la señal instrumental de la muestra problema\nx.hat <- (-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c) # Concentración de la muestra\n\nIx <- (s.y * t)/(b + 2*c*x.hat) * sqrt(\n  1/N + 1/N.hat + ((x.hat - mean(x))^2*Qx4 + (x.hat^2 - sum(x^2)/N)^2 * Qxx -  \n  2*(x.hat - mean(x))*(x.hat^2 - sum(x^2)/N)*Qx3)/\n  (Qx4 * Qxx - Qx3^2)\n)\n\nIx <- unname(Ix) # Simplemente es para dejar sólo el número\n\n```\n\nLa concentración de la muestra es $\\hat{x} = `r round(x.hat, 2)`$ mg/L.\nAl aplicar esta metodología obtenemos una incertidumbre expandida de \n$I(\\hat{x}) = `r round(Ix, 2)`$ mg/L, es decir, exactamente la misma que la que \nindica la norma ISO. Note que si Ud. quisiera combinar esta incertidumbre de \ncalibración con algún otro factor (p.ej: masa de la muestra, volumen de aforo, \netc.) debe primero tansformarla en incertidumbre estándar, dividiéndola por el \nfactor de cobertura $k$, que en este caso corresponde al t Student con $N - 3$ \ngrados de libertad al 95% de confianza (k = `r round(qt(0.975, N - 3), 2)`):\n\n$$\nu_{\\hat{x}} = \\frac{U_{\\hat{x}}}{k} = `r round(Ix/t, 2)`\\, \\, \\text{mg/L}\n$$\nPor lo tanto, si tuviéramos que informar el resultado de la concentración\nde la muestra interpolada en la curva de calibración no lineal informaríamos\n$`r round(x.hat, 2)` \\pm `r round(Ix, 2)`$ mg/L [*nota mental: mmmm... esto de\nlas cifras significativas da para otro post, pero dejémoslo así por ahora. \nNo olvidar borrar este comentario.*]\n\n¿Cómo varía esta incertidumbre de calibración no lineal con la concentración de\nla muestra? La siguiente figura muestra esta variación:\n\n```{r u.vs.con}\nx <- seq(12, 66, by = 6) # Rango de concentración\nN <- length(x)\nN.hat <- 1\nmu.x <- mean(x) # promedio de las concentraciones de los calibrantes\nsq.x <- sum(x^2) # suma de las concentraciones de los calibrantes al cuadrado\nQxx <- sum(x^2) - sum(x)^2/N\nQx3 <- sum(x^3) -(sum(x) * sum(x^2)/N)\nQx4 <- sum(x^4) - sum(x^2)^2/N\nt <- qt(0.975, N - 3)\n\n# Para graficar la incertidumbre vs concentración, primero debemos crear una\n# función que tome un X (una concentración) y calcule el Y (incertidumbre)\nUx <- function(x) {\n    U <- s.y*t/(b + 2*c*x) * sqrt(\n    1/N + 1/N.hat + ((x - mu.x)^2*Qx4 + (x^2 - sq.x/N)^2 * Qxx -  \n    2*(x - mu.x)*(x^2 - sq.x/N)*Qx3)/\n    (Qx4 * Qxx - Qx3^2))\n    return(unname(U))\n}\n\n# Graficamos concentración (X) vs Incertidumbre (Y)\n\nplot(x, Ux(x), type = 'n',\n     main = 'Concentración vs Incertidumbre de calibración',\n     xlab = 'Concentración [mg/L]',\n     ylab = 'Incertidumbre expandida [mg/L]')\nlines(spline(x, Ux(x)), col = 'red')\n```\nSe aprecia que la incertidumbre aumenta con la concentración en una forma no \nconstante para concentraciones mayores a 20 mg/L. \nTal como mencionamos anteriormente, el mínimo no se encuentra en el \ncentro del rango de concentración como ocurre con la calibración lineal. Para \nencontrar el valor exacto de concentración que minimiza la incertidumbre en este \nrango, usamos el comando `optimize`:\n\n```{r}\n# Busca el mínimo de la función Ux en el intervalo de 12 a 66 mg/L\noptimize(Ux, interval = c(12, 66))\n```\n\nLa concentración que minimiza la incertidumbre es \n`r round(optimize(Ux, interval = c(12, 66))$minimum, 2)` mg/L.\n\n\nMuy entretenido, pero la vida es corta y debemos ser eficientes por lo tanto, \npara evitarnos el \"tedio\" de implementar la fórmula a mano, utilizaremos\nel package `investr` el cual calcula exactamente la incertidumbre de \ncalibración de un gran número de modelos de calibración, entre ellos, los \nmodelos cuadráticos:\n\n```{r investr.u}\n# y0 es la señal de la muestra problema y0 = 0.084 UA\nlibrary(investr) # Cargamos la librería investr\nx.hat <- invest(fit.nolineal, data = d, y0 = y0, interval = 'Wald')\nx.hat\n```\n\ndonde:\n\n- `estimate` es la concentración de la muestra problema\n- `upper` es el extremo superior de la incertidumbre expandida $I(\\hat{x})$\n- `lower` es el extremo inferior de la incertidumbre expandida $I(\\hat{x})$\n- `se` es la incertidumbre estándar de calibración $u_{\\hat{x}}$, la cual es \nexactamente igual a la obtenida por la fórmula anterior\n$u_{\\hat{x}} = \\frac{U_{\\hat{x}}}{k} = `r round(Ix/t, 2)`\\, \\, \\text{mg/L}$\n\nNote que si quisiéramos obener $I(\\hat{x})$ a partir de esta tabla, tendríamos \nque hacer la siguiente operación $I(\\hat{x}) =$ `upper` - `estimate`:\n\n```{r}\nx.hat$upper - x.hat$estimate\n```\n\n\nNo podemos usar el package `chemCal` que utilizamos\nen un [post anterior](https://www.analytical.cl/post/como-calcular-la-incertidumbre-de-una-curva-de-calibracion/) \npara estimar la incertidumbre de calibración, porque este package sólo soporta \ncalibraciones lineales.\n\n\n## Estimación de incertidumbre mediante Guía ISO GUM\n\nYa que la señal instrumental es una función de la concentración, entonces, \npodemos utilizar la aproximación ISO GUM clásica para estimar la incertidumbre\nde calibración. Por \"clásica\" me refiero a utilizar la aproximación de Taylor\ncon las derivadas parciales. Esta guía dice lo siguiente:\n\n1. Expresar el mensurando como una ecuación de medición a través de una relación\nfuncional con las magnitudes de entrada. En este caso el mensurando es la \nconcentración $\\hat{x}$ cuya ecuación de medición es la solución de la ecuación\ncuadrática $y_{0} = a + b\\hat{x} + c\\hat{x^2}$ donde $y_{0}$ es la señal de la \nmuestra problema:\n\n$$\n\\hat{x} = \\frac{-b \\pm \\sqrt{b^2 - 4(a - y_{0})c}}{2c}\n$$\n2. Identificación de las fuentes de incertidumbre. Al observar la ecuación de \nmedición identificamos las siguientes fuentes de incertidumbre:\n\n- Parámetros del modelo cuadrático: $a$, $b$ y $c$\n- Señal instrumental de la muestra problema $y_{0}$\n\n3. Evaluación de las fuentes de incertidumbre: \n\n- Las incertidumbres estándar de los parámetros del modelo pueden ser obtenidas\ndirectamente del ajuste cuadrático `fit.nolineal`:\n\n```{r u.param}\n# parámetros del modelo\na <- fit.nolineal$coeff[1]\nb <- fit.nolineal$coeff[2]\nc <- fit.nolineal$coeff[3]\n\n# las incertidumbres estándar de a, b y c las obtenemos con la función summary\nua <- summary(fit.nolineal)$coefficients[1, 2]\nub <- summary(fit.nolineal)$coefficients[2, 2]\nuc <- summary(fit.nolineal)$coefficients[3, 2]\n```\n\n\n- La incertidumbre estándar de la señal instrumental de la muestra problema\ntambién puede obtenerse del ajuste cuadrático y corresponde a la \ndesviación estándar residual:\n\n```{r u.y0}\nuy0 <- summary(fit.nolineal)$sigma\ny0 <- 0.084 # dato del problema, es decir, la absorbancia de la muestra\n```\n\n4. Determinación de la incertidumbre estándar combinada $u_{\\hat{x}}$ a través \nde la expresión:\n\n$$\nu_{\\hat{x}}^2 = \\left( \\frac{\\partial{\\hat{x}}}{\\partial{y_{0}}}\\right) ^{2} (u_{y_{0}})^{2} + \n\\left( \\frac{\\partial{\\hat{x}}}{\\partial{a}}\\right) ^{2} (u_{a})^{2} + \n\\left( \\frac{\\partial{\\hat{x}}}{\\partial{b}}\\right) ^{2} (u_{b})^{2} +\n\\left( \\frac{\\partial{\\hat{x}}}{\\partial{c}}\\right )^{2} (u_{c})^{2}\n$$\n\n\"sólo\" nos falta obtener las derivadas parciales (aguante ese código $\\LaTeX$):\n\n$$\n\\begin{aligned}\n\\frac{\\partial{\\hat{x}}}{\\partial{y_{0}}} &= \n\\frac{1}{\\sqrt{b^{2} - 4c(a-y_{0})}} \\\\\n\\frac{\\partial{\\hat{x}}}{\\partial{a}} &=\n  \\frac{-1}{\\sqrt{b^{2} - 4c(a-y_{0})}} \\\\\n\\frac{\\partial{\\hat{x}}}{\\partial{b}} &=\n\\frac{-1 + \\frac{b}{\\sqrt{b^{2} - 4c(a-y_{0})}}}{2c} \\\\\n\\frac{\\partial{\\hat{x}}}{\\partial{c}} &=\n  \\frac{-a + y_{0}}{c\\sqrt{b^{2} - 4c(a-y_{0})}} - \n  \\frac{-b + \\sqrt{b^{2} - 4c(a-y_{0})}}{2c^{2}}\n\\end{aligned}\n$$\n\n¡Listo! ahora debemos evaluar las expresiones. Pero como soy flojo, \nprefiero usar el excelente package `metRology` que hará todo el trabajo por\nmí:\n\n```{r u.GUM}\nlibrary(metRology) # cargamos la librería\n\nexpr <- expression((-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c)) # ecuación de medición\nx <- list(a = a, b = b, c = c, y0 = y0) # valores de cada X input\nu <- c(ua, ub, uc, uy0) # incertidumbres estándar de cada X input\nu.GUM <- uncert(expr, x, u, method = 'GUM') # Usamos el método GUM\nu.GUM\n\n```\n\n¿What? ¿Por qué obtuvimos una incertidumbre estándar de `r round(u.GUM$u.y, 3)` \ny no la que calculamos con la ecuación de la norma ISO `r round(Ix/t, 3)`?\nPor la sencilla razón de que los parámetros de un modelo cuadrático no son\nindependientes, sus covarianzas no son 0. Es más, algunas de las covarianzas\nson negativas. Observe la siguiente figura que fue obtenida simulando \ncurvas de calibración cuadráticas. En la figura se muestra las correlaciones\nentre los tres parámetros del modelo no lineal:\n\n```{r}\n# Simularemos p = 200 curvas de calibración cuadráticas a partir de los datos \n# empíricos \n\np <- 200 # Número de simulaciones\na.sim <- numeric(p) # vector que guardará el parámetro a\nb.sim <- numeric(p) # vector que guardará el parámetro b\nc.sim <- numeric(p) # vector que guardará el parámetro c\n\n# Hacemos un loop\nfor(i in 1:p){\n  x.sim <- seq(12, 66, by = 6)\n  y.sim <- a + b*x.sim + c*x.sim^2 + rnorm(length(x.sim), 0, uy0)\n  fit.nolineal.sim <- lm(y.sim ~ x.sim + I(x.sim^2))\n  a.sim[i] <- fit.nolineal.sim$coeff[1]\n  b.sim[i] <- fit.nolineal.sim$coeff[2]\n  c.sim[i] <- fit.nolineal.sim$coeff[3]\n}\n\n# guardamos los parámetros simulados en un data frame que llamamos param.sim\nparam.sim <- data.frame(a.sim, b.sim, c.sim) \n                                                \n# graficamos los parámetros simulados\nplot(param.sim)\n```\n\n\nSe advierte claramente que existe una correlación negativa entre los parámetros\n$a$ y $b$, además entre $b$ y $c$. La correlación entre $a$ y $c$ es positiva.\nEn rigor, habría que incorporar las derivadas parciales cruzadas y las \ncovarianzas entre los parámetros. De sólo pensarlo, me dan ganas de \nprocastinar aún más la escritura de este post, así que recurriremos al \npackage `metRology`.\n\nLa parte \"fácil\" es obtener la matriz de covarianzas de los parámetros del\nmodelo con el comando `vcov`:\n\n```{r vcov}\nv <- vcov(fit.nolineal)\ncolnames(v) <- c('a', 'b', 'c') # solo cosmética para que aparezcan los nombres\nrownames(v) <- c('a', 'b', 'c') # de los parámetros (es opcional)\nv\n```\n\nLa diagonal de esta matriz es precisamente la incertidumbre estándar al \ncuadrado de los parámetros (a.k.a sus varianzas). Si queremos, también podemos\nexpresarla como matriz de correlaciones con el comando `cov2cor`:\n\n```{r corr}\nparam.cor <- cov2cor(v)\nparam.cor\n```\n\nEn la diagonal de esta matriz obviamente esperamos correlación 1. Se observa\nclaramente la alta correlación entre los parámetros, como dijimos anteriormente, \nalgunas de ellas son negativas.\n\nLa parte \"difícil\" es que debemos incorporar la variable señal\ninstrumental de la muestra problema $y_{0}$, la cual obviamente es independiente \nde los parámetros del modelo:\n\n\n```{r u.gum.cov}\n# Incorporamos la variable y0 que es independiente de los parámetros\nv <- rbind(v, y0 = rep(0, 3)) \nv <- cbind(v, y0 = rep(0, 4))\nv[4, 4] <- uy0^2 # Asignamos al elemento de la 4a fila y 4a columna  \n                 # la varianza de y0\nv\n```\n\nAhora, incorporamos las covarianzas en el cálculo por método GUM:\n\n```{r, eval = T}\nu.GUM.cov <- uncert(expr, x, cov = v, method = \"GUM\")\nu.GUM.cov\n```\n\n¡Perfecto!, ahora sí, al incluir las covarianzas obtenemos resultados consistentes \ncon el método descrito en la norma ISO 8466-2.\n\n## Estimación con el Método de Monte Carlo\n\nNo detallaremos aquí cómo funciona el método de Monte Carlo, puede consultarlo \nen [este post](https://www.analytical.cl/post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo/) y en \n[este otro](https://www.analytical.cl/post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/).\n\nSería super simple si usamos el package `metRology`, el problema es que el \npackage lanza un error numérico cuando existen covarianzas negativas. Probé \nel ejemplo que incluye el manual de `metRology` y el error se repite. Es un \nproblema al evaluar la suma de las correlaciones. Le \nconsulté al autor Steve Ellison, sin embargo, a la fecha (09 de junio 2020) \naún no tengo respuesta, a pesar de que Steve siempre responde las consultas en\nforma muy expedita. Otros usuarios han tenido un problema similar y se ha \nabierto un hilo en [stackoverflow](https://stackoverflow.com/questions/60971950/error-in-eigensigma-symmetric-true-0-x-0-matrix-in-metrology-uncertmc-wit/62119518#62119518).\n\nPor lo tanto, implementamos el método de Monte Carlo \"a mano\" utilizando el \npackage `MASS` el cual permite generar muestras aleatorias multivariadas \nincluyendo las correlaciones:\n\n```{r u.MC.sim}\n# No funciona metRology MC así que lo hicimos a mano\nlibrary(MASS) # cargamos la librería\n\n# Generamos n muestras aleatorias multivariadas, cuyas medias \n# corresponden a los valores de a, b, c e y0\n# La matriz de covarianza Sigma = v la calculamos anteriormente\n\nset.seed(123) # Para que Ud. obtenga los mismos resultados\nmuestra.MC <- mvrnorm(n = 10000, mu = c(a, b, c, y0), Sigma = v, empirical = T)\ncolnames(muestra.MC) <- c('a', 'b', 'c', 'y0') # solo cosmética\nmuestra.MC <- data.frame(muestra.MC) # lo guardamos como data.frame\nhead(muestra.MC) # muestra las primeras n = 6 simulaciones\n\n```\n\nCada fila es una simulación. Si, por ejemplo, calculamos el promedio de cada\nvariable simulada, obtenemos un valor similar a los valores empíricos. A mayor \nnúmero de simulaciones, más nos acercamos a valores que asumimos como\nverdaderos.\n\n```{r}\napply(muestra.MC, 2, mean) # promedio de cada columna\n```\n\nBien, lo que tenemos que hacer es que en cada simulación debemos \ncalcular la concentración de la muestra:\n\n\n```{r u.MC}\n# cargaré estas librerías sólo para facilitar la manipulación de los datos\nlibrary(magrittr)\nlibrary(tidyverse)\n\n# Creamos una nueva variable llamada x.hat que corresponde a la concentración de\n# la muestra\nmuestra.MC <- muestra.MC %>% \n  mutate(x.hat = (-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c))\nhead(muestra.MC) # muestra las primeras n = 6 simulaciones\n```\n\nLa última columna corresponde a la concentración calculada para cada \nsimulación. Por lo tanto, si queremos obtener la incertidumbre estándar de \nla concentración, basta calcular la desviación estándar de esa columna:\n\n```{r}\nmu.x.hat.MC <- mean(muestra.MC$x.hat) # valor promedio de concentración\nu.x.hat.MC <- sd(muestra.MC$x.hat) # incertidumbre estándar de la concentración\nu.x.hat.MC\n```\n\nSe obtiene una incertidumbre estándar de calibración de \n`r round(u.x.hat.MC, 3)` mg/L, la\ncual es consistente con los otros métodos estudiados. La siguiente\nfigura muestra el histograma de las concentraciones simuladas:\n\n\n```{r plot.u.MC}\nhist(muestra.MC$x.hat, \n     breaks = 20,\n     main = 'Concentraciones simuladas por Monte Carlo',\n     xlab = 'Concentración [mg/L]')\n```\n\n\nFinalmente, la siguiente tabla resume los resultados de los tres métodos \nconsiderando la incertidumbre estándar de calibración:\n\n```{r tabla}\ntabla <- data.frame(Ix/t, u.GUM$u.y, u.GUM.cov$u.y, u.x.hat.MC)\nknitr::kable(tabla, \n             rownames = NA,\n             col.names = c('ISO', 'GUM', 'GUM/Covarianzas', 'Monte Carlo'),\n             align = 'l')\n```\n\nSe aprecia claramente una excelente concordancia entre los tres métodos.\nSin embargo, para que el método GUM entregue resultados correctos, es necesario\nincorporar las covarianzas entre las variables input.\n\nEn un próximo post exploraremos el método _Bootstrap_, un método estadístico \npor excelencia para estimar incertidumbre sin utilizar un modelo de medición...\n\n> ¡Dejad que los datos hablen!\n\n# Bibliografía\n\n1. Norma ISO 8466-2:2001 *Water quality -- Calibration and evaluation of \nanalytical methods and estimation of performance characteristics -- Part 2: \nCalibration strategy for non-linear second-order calibration functions.*\n\n2.  Brandon M. Greenwell and Christine M. Schubert Kabban (2014). investr: An R\nPackage for Inverse Estimation. The R Journal, 6(1), 90-100. URL http://journal.r-project.org/archive/2014-1/greenwell-kabban.pdf.\n\n3. NIST/SEMATECH e-Handbook of Statistical Methods, \n_Uncertainty for quadratic calibration using propagation of error_,\nhttps://www.itl.nist.gov/div898/handbook/mpc/section3/mpc3671.htm, \n09 de junio 2020.\n\n4. Nonlinear multivariate calibration methods in analytical chemistry\nSonja Sekulic, Mary Beth Seasholtz, Ziyi Wang, Bruce R. Kowalski, Samuel E. \nLee, and Bradley R. Holt _Analytical Chemistry 1993 65 (19), 835A-845A_"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css","../../custom.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","theme":"uniited","knitr":{"opts_chunk":{"warning":false,"message":false}},"title":"Incertidumbre de una calibración no lineal","subtitle":"Método GUM y Monte Carlo -- Norma ISO 8466:2","date":"2020-06-06"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}