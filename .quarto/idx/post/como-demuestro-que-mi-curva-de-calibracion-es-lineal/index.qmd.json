{"title":"¿Cómo demuestro que mi curva de calibración es lineal?","markdown":{"yaml":{"title":"¿Cómo demuestro que mi curva de calibración es lineal?","date":"2017-08-23","lastmod":"2022-03-26T10:53:06-03:00"},"headingText":"Coeficiente de correlación","containsRefs":false,"markdown":"\n\n\nEn este post intentaremos derribar el mito del coeficiente de correlación con\n\"muchos\" 9's como prueba de linealidad. Además, presentaremos dos test\nformales para evaluar el modelo de calibración lineal en química\nanalítica.\n\n\nEste parámetro estadístico indica la fuerza y dirección de la relación de\ndos variables cuantitativas, por ejemplo;\n\n- Concentración ($x$) y Absorbancia ($y$)\n- $log \\text{ Concentración}$ y $E$ Potencial (Ecuación de Nernst)\n- La edad de las ganadoras de Miss América con los asesinatos utilizando objetos \ncalientes y vapor. ¡Cuidado con las correlaciones [espurias](http://tylervigen.com/spurious-correlations)!\n\nTodos los químicos estamos familiarizados con la ecuación de Lambert-Beer,\nla cual establece la archiconocida relación entre absorbancia y concentración\nen métodos espectrofotométricos:\n\n\\begin{equation}\n  \\underbrace{A}_\\text{y} = \\underbrace{\\epsilon \\cdot b}_\\text{$\\beta_{1}$} \\cdot\n  \\underbrace{C}_\\text{x}\n    (\\#eq:lambert)\n\\end{equation}\n\n\nDe la ecuación \\@ref(eq:lambert) se observa claramente la relación con el modelo\nestándar de calibración lineal $y = \\beta_{0} + \\beta_{1}x$ asumiendo un\nintercepto $\\beta_{0} = 0$. Por lo tanto ¿por qué nos sorprende tanto \nencontrar un coeficiente de \ncorrelación alto en curvas de calibración espectrofotométricas? Era totalmente\nesperable, pues hay un modelo físico-químico que sustenta el modelo lineal.\n\nOK, de acuerdo. Este modelo físico-químico sólo es válido bajo ciertas \ncondiciones (como todos los modelos), de hecho son conocidas las desviaciones \nde la ley de Lambert-Beer a altas concentraciones.\n\n\n\n# Derribando el mito del r = 0,999...\n\nPara comenzar, por favor, ponga atención a la figura \\@ref(fig:anscombe)\ndenominada \"El Cuarteto de Anscombe\". La \"gracia\" de estos\ndatos de calibración es que todos tienen la misma pendiente, intercepto, \nerror de calibración y... ¡coeficiente de correlación!\n\n¿No me cree? Le dejo este [link](https://1drv.ms/x/s!AuF6FPVWruwDyKxMLQ2ngb99Eo3q7w?e=5jIW6e) \npara que descargue los datos en archivo Excel\ny se convenza con sus propios ojos.\n\n\n\n```{r anscombe, echo = F, warning=F, fig.cap = 'El Cuarteto de Ascombe'}\n\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n#correlation\ncor1 <- format(cor(anscombe$x1, anscombe$y1), digits=3)\ncor2 <- format(cor(anscombe$x2, anscombe$y2), digits=3)\ncor3 <- format(cor(anscombe$x3, anscombe$y3), digits=3)\ncor4 <- format(cor(anscombe$x4, anscombe$y4), digits=3)\n \n#define the OLS regression\nline1 <- lm(y1 ~ x1, data=anscombe)\nline2 <- lm(y2 ~ x2, data=anscombe)\nline3 <- lm(y3 ~ x3, data=anscombe)\nline4 <- lm(y4 ~ x4, data=anscombe)\n \ncircle.size = 5\ncolors = list('red', '#0066CC', '#4BB14B', '#FCE638')\n \n#plot1\nplot1 <- ggplot(anscombe, aes(x=x1, y=y1)) + geom_point(size=circle.size, pch=21, fill=colors[[1]]) +\n  geom_abline(intercept=line1$coefficients[1], slope=line1$coefficients[2]) +\n  annotate(\"text\", x = 10.5, y = 5, label = paste(\"correlación = \", cor1))\n \n#plot2\nplot2 <- ggplot(anscombe, aes(x=x2, y=y2)) + geom_point(size=circle.size, pch=21, fill=colors[[2]]) +\n  geom_abline(intercept=line2$coefficients[1], slope=line2$coefficients[2]) +\n  annotate(\"text\", x = 10, y = 3, label = paste(\"correlación = \", cor2))\n \n#plot3\nplot3 <- ggplot(anscombe, aes(x=x3, y=y3)) + geom_point(size=circle.size, pch=21, fill=colors[[3]]) +\n  geom_abline(intercept=line3$coefficients[1], slope=line3$coefficients[2]) +\n  annotate(\"text\", x = 10.5, y = 5, label = paste(\"correlación = \", cor3))\n \n#plot4\nplot4 <- ggplot(anscombe, aes(x=x4, y=y4)) + geom_point(size=circle.size, pch=21, fill=colors[[4]]) +\n  geom_abline(intercept=line4$coefficients[1], slope=line4$coefficients[2]) +\n  annotate(\"text\", x = 12.5, y = 6, label = paste(\"correlación = \", cor4))\n \ngrid.arrange(plot1, plot2, plot3, plot4, top='El Cuarteto de Anscombe')\n\n```\n\n\n\n\nEl punto que revela la figura \\@ref(fig:anscombe) es que es posible obtener \ncoeficientes de \ncorrelación \"altos\" inclusive con datos que, a simpe vista, no revelan\nuna relación lineal entre $X$ e $Y$. Es más, es posible obtener un alto\ncoeficiente de correlación donde no existe absolutamente ninguna \ncorrelación entre $X$ e $Y$ mediante un mal de diseño de la curva de \ncalibración. Por ejemplo, en la figura \\@ref(fig:influyente) se muestra a la izquierda\nque la correlación entre $x$ e $y$ es prácticamente 0. Sin embargo, \ncuando incluimos un punto _influyente_, muy alejado de la nube de puntos a \nbaja concentración, mágicamente el r = 1 (derecha).\n\n> *Moraleja:* Trate, en lo posible, de diseñar la curva con los puntos \n> equiespaciados y evite los saltos de varios órdenes de magnitud de la \n> concentración. \n\n```{r influyente, echo = F, fig.cap = 'Punto inlfuyente en la calibración'}\n\nset.seed(123)\nx1 <- seq(0, 1, 0.1)\ny1 <- rnorm(length(x1))\nx2 <- c(x1, 100)\ny2 <- c(y1, 100)\n\nr1 <- cor(x1, y1)\nr2 <- cor(x2, y2)\n\ng1 <- ggplot(data.frame(x1, y1), aes(x1, y1)) +\n  geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = F) +\n  theme_bw() +\n  xlab('x') +\n  ylab('y') +\n  annotate(\"text\", x = 0.25, y = 0.5, \n           label = paste(\"correlación = \", round(r1, 2)))\n  \n\ng2 <- ggplot(data.frame(x2, y2), aes(x2, y2)) +\n  geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = F) +\n  theme_bw() +\n  xlab('x') +\n  ylab('y') +\n  annotate(\"text\", x = 50, y = 25, \n           label = paste(\"correlación = \", round(r2, 2)))\n\ngrid.arrange(g1, g2, top = 'Mal diseño de calibración', ncol = 2)\n\n```\n\n\nLa linealidad tampoco es un parámetro cuantitativo, una curva con r = 0,999 no \nes más lineal que otra con r = 0,99. Observe la figura \\@ref(fig:simplot), ambas curvas fueron simuladas en lenguaje `R` con el mismo intercepto y \npendiente siguiendo estrictamente el modelo lineal \n$y = \\beta_{0} + \\beta_{1}x$, sin embargo, tienen coeficientes de \ncorrelación distintos. La curva de la izquierda no es más lineal que la de la\nderecha ya que ambas fueron simuladas a partir del mismo modelo, la única\ndiferencia es que la de la derecha tiene una mayor dispersión de los puntos, pero\nno por ello es \"menos lineal\", de hecho ambas lo son, pues fueron simuladas.\n\n```{r sim}\n\nset.seed(123) # Es para que Ud. obtenga los mismos \n              # resultados en su simulación en R\n              \n\nb0 <- 1  # Intercepto = 1\nb1 <- 10 # Pendiente = 10\ns <- 1   # Desviación estándar de calibración\n\n# Simulamos el mismo modelo lineal \nx <- 1:10 # Calibrantes\ny1 <- b0 + b1*x + rnorm(10, 0, s) # Absorbancias con \n                                  # error = s = 1\ny2 <- b0 + b1*x + rnorm(10, 0, 10*s) # Absorbancias con \n                                     # error = 10*s = 10\n\n```\n\n```{r simplot, fig.cap = 'Simulación de curvas perfectamente lineales', echo = F}\n\ncor1 <- cor(x, y1)\ncor2 <- cor(x, y2)\n\nlin1 <- ggplot(data.frame(x, y1), aes(x, y1)) + \n  geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = F) +\n  theme_bw() +\n  xlab('x') +\n  ylab('y') +\n  annotate(\"text\", x = 5, y = 30, \n           label = paste(\"correlación = \", round(cor1, 3)))\n\nlin2 <- ggplot(data.frame(x, y2), aes(x, y2)) + \n  geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = F) +\n  theme_bw() +\n  xlab('x') +\n  ylab('y') +\n  annotate(\"text\", x = 5, y = 30, \n           label = paste(\"correlación = \", round(cor2, 3)))\n\ngrid.arrange(lin1, lin2, ncol = 2)\n\n```\n\n\n\n# Test formales de linealidad\n\nExisten varios tests estadísticos formales para evaluar el supuesto de \nlinealidad de la curva de calibración. Sin embargo, en este post veremos dos\nque son los más utilizados en Química Analítica y son sugeridos por \nnormativas internacionales (para presentárselos a los amables auditores).\n\nSi bien no es estrictamente riguroso, para simplificar el concepto, diremos que\nambos tests estadísticos intentan dirimir entre dos hipótesis:\n\n- $H_{0}$ (a.k.a Hipótesis Nula) : El modelo lineal es adecuado para describir \nlos datos de calibración\n- $H_{1}$ (a.k.a Hipótesis alternativa): El modelo lineal **NO** es adecuado para \ndescribir los datos de calibración\n\nTambién debemos hacer la siguiente acotación: En **estadística** \nun modelo lineal es\naquel en que sus parámetros son lineales. Por ejemplo, la curva de calibración lineal\nclásica $y = \\beta_{0} + \\beta_{1}x$ tanto $\\beta_{0}$  y $\\beta_{1}$ son \nlineales. Sin embargo, en un modelo exponencial $y = \\gamma_{0} e^{\\gamma_{1}x}$\nel coeficiente $\\gamma_{1}$ no lo es.\n\nDicho esto, el modelo cuadrático de calibración\n$y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^2$ **es lineal** desde el punto de vista\nestrictamente estadístico. Sin embargo, debido al arraigo del concepto de\nlinealidad en química analítica no modificaremos su interpretación.\n\n\n## Test de carencia de ajuste (_Lack of fit_) ISO 11095\n\n\nEste test está basado en comparar dos estimadores del error aleatorio:\n\n1. Error puro o experimental\n2. Error de carencia de ajuste o _lack of fit_\n\nEs decir, necesitamos un estimador del error aleatorio totalmente independiente\ndel error del modelo de calibración que queremos ajustar. Para estimar este\nerror, la prueba de carencia de ajuste exige que hagamos replicados de cada uno\nde los calibrantes.\n\n> Pero tienen que ser replicados verdaderos. No es válido inyectar varias veces\nel mismo estándar en el equipo. Prepárelos independientemente.\n\nSi los dos estimadores del error aleatorio son similares, entonces el modelo\nde calibración que acabamos de ajustar es adecuado para modelar los \ndatos experimentales. ¿Cuán similares tienen que ser? Lo probaremos con un test\nF. Los detalles algebraicos son latosos-engorrosos y pueden ser consultados \nen la bibliografía. Sólo indicaremos cómo hacer este test de linealidad en \nlenguaje `R`, como no. (¿Y en Excel cuándo?)\n\n\nLa tabla \\@ref(tab:lof) muestra los datos de calibración de cloranfenicol en matriz leche\nobtenida por GC/MS-NCI \n(_Gas Chromatography/Mass Spectrometry - Negative Chemical Ionization_ ...¡Qué \ntiempos aquellos!). Note que cada nivel de calibración está preparado en \ntriplicado totalizando n = 15 calibrantes independientes. \nLa figura \\@ref(fig:lofplot) muestra la curva de calibración.\n\n```{r lof, echo = F, warning=F, message=F}\noptions(knitr.table.format = 'html') \n\n\nlibrary(knitr)\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(broom)\n\nset.seed(123)\nx.caf <- rep(seq(0:0.5, by = 0.25), each = 3)\ny.caf <- 200 + 30000*x.caf + rnorm(length(x.caf), 0, 200)\nReplicado <- factor(rep(1:3, 5))\n\ndata.caf <- data.frame(Replicado, x.caf, y.caf)\n\nkable(data.caf %>% spread(., x.caf, y.caf),\n      digits = 0,\n      align = 'c',\n      caption = 'Calibración CAF [ug/kg]') %>%\n  kable_styling(full_width = T)      \n\n```\n\n```{r lofplot, echo = F, fig.cap = 'Curva de calibración CAF. Test de carencia de ajuste'}\n\nggplot(data.caf, aes(x = x.caf, y = y.caf)) +\n  geom_point(pch = 21, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = F) +\n  theme_bw() +\n  xlab('Concentración CAF [ug/kg]') +\n  ylab('Area')\n\n```\n\nLa tabla \\@ref(tab:lofcal) muestra el análisis estadístico de \nesta calibración:\n\n<!-- Ancho de las tabla -->\n<style type=\"text/css\">\n.table {\n\n    width: 100%;\n    \n}\n</style>\n\n```{r lofcal, echo = F}\n\nfit.cal <- lm(y.caf ~ x.caf, data = data.caf)\nkable(tidy(fit.cal),\n      digits = c(0, 0, 0, 0, 3),\n      caption = 'Pendiente e intercepto de calibración',\n      booktabs = T)\n\n```\n\nPor ahora no nos detendremos en el análisis de la tabla (eso quedará para otro post). Haremos directamente el Test de Carencia de Ajuste (_lack of fit_) en\n`R` el cual se muestra en la tabla \\@ref(tab:loftest):\n\n```{r lofalr3, echo = T, message=F, warning=F, eval = F}\n\nlibrary(olsrr) # Cargamos el package 'olsrr' para aplicar el test lack-of-fit\nols_pure_error_anova(fit.cal)\n\n```\n\n\n```{r loftest, echo = F, message=F, warning=F}\n\noptions(knitr.kable.NA = '')\n\nlibrary(olsrr)\nlof.test <- ols_pure_error_anova(fit.cal)\nlof.test\n# kable(lof.test,\n#       digits = c(0, 0, 0, 0, 2),\n#       caption = 'Tabla de test Carencia de Ajuste')\n\n```\n\nOk, para interpretar el test de carencia de ajuste nos fijaremos en la\nfila que dice \"_Lack of fit_\" y en el _p-value_ del test, el cual aparece\nbajo la columna _Pr(>F)_ = `r round(lof.test$pl, 3)`. La interpretación\ntradicional de una prueba estadística diría algo más o menos así:\n\n> Dado que el _p-value_ $> 0.05$, entonces, no hay evidencias en contra de la \n> hipótesis nula. El modelo lineal es adecuado para modelar los datos de\n> calibración.\n\nAlgunas consideraciones:\n\n1. ¿Dice en alguna parte que el modelo de calibración es lineal? Póngalo de\n_wallpaper_ en su pantalla: **NO**.\n2. Lo único que se puede extraer como conclusión es que el modelo lineal \nes adecuado, es razonable para modelar los datos de calibración. Nada más.\n3. Existen infinitos modelos de calibración que podrían ser idóneos, este test\nnos dice si el que hemos elegido para modelar los datos es razonable/adecuado, \nsin embargo, no nos dice que sea \"EL\" modelo perfecto.\n4. ¿Qué tiene de especial el famoso 0,05? Absolutamente *NADA*. ¿Qué concluiría\nUd. si el _p-value_ fuese 0,04999 ó 0,05001? Sería un test totalmente \ninconcluyente. \n5. Lamentablemente, esto es una dicotomía perversa que desde hace mucho \ntiempo ha sido objeto de varias críticas. Le invito a leer las siguientes\nreferencias sobre la interpretación y controversia de los _p-values_ en ciencia:\n\n- Ronald L. Wasserstein & Nicole A. Lazar (2016)\nThe ASA's Statement on p-Values: Context, Process, and Purpose \n_The American Statistician Volume 70, 2016 - Issue 2_ [link](http://amstat.tandfonline.com/doi/abs/10.1080/00031305.2016.1154108)\n\n- M.Baker Statisticians issue warning over misuse of P values\n_Nature **531**, 151 (10 March 2016)_ [link](http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503)\n\n- Singh Chawla D. Big names in statistics want to shake up much-maligned P value. _Nature. 2017 Jul 26;548(7665):16-17_ [link](https://www.nature.com/news/big-names-in-statistics-want-to-shake-up-much-maligned-p-value-1.22375?beta=false)\n\n\n\n\n\n\n\n\n> \"The p-value was never intended to be a substitute for scientific reasoning\" \n> Ron Wasserstein, Director Ejecutivo de la Asociación Americana de Estadística \n> ASA.\n\n\n\n\n## Test de Mandel ISO 8466-1\n\nEsta prueba estadística es bastante sencilla y está basada en la comparación\nentre el modelo de calibración lineal y un modelo alternativo. Por lo tanto, \nno es una prueba absoluta, sino relativa a la elección del modelo alternativo. Require al menos n = 6 calibrantes (sin replicado).\n\nEn general, el test de Mandel utiliza el modelo de calibración cuadrático para\ncompararlo con el modelo lineal:\n\n$$ y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^2$$\n\nLos detalles estadísticos pueden consultarse en la bibliografía.\n\n1. Primero calcule la suma de cuadrados de los residuos $SS_{r}$ para cada uno de \nlos modelos de acuerdo a la siguiente expresión:\n\n\\begin{equation}\n  SS_{r} = \\sum_{i = 1}^{n} e_{i}^2\n    (\\#eq:res)\n\\end{equation}\n\n\nDonde el residuo $e = y - \\hat{y}$.\n$y$ es la respuesta instrumental observada o experimental \n(áreas, absorbancias, etc.); $\\hat{y}$, es la respuesta instrumental que predice\nel modelo (lineal o o cuadrático) en cada una de las concentraciones de los\ncalibrantes. Si observa la ecuación \\@ref(eq:res) el concepto de residuo es el mismo para\ncualquier modelo de calibración, es decir, ¿cuánto difiere lo que se observa\nexperimentalmente con lo que predice el modelo?\n\nUn buen modelo tiene residuos pequeños.\nUn residuo grande para cierto de nivel de concentración implica que existe una\ngran diferencia entre lo observado y lo que predice el modelo, por lo tanto, nos\nguiará (en otro post) a detectar posibles valores anómalos o _outliers_.\n\n\n2. Calcule la diferencia entre ambas sumas de cuadrado de los residuos, la del\nmodelo no lineal $SS_{r}^{no-lin}$ y la correspondiente al modelo lineal\n$SS_{r}^{lin}$:\n\n\\begin{equation}\n  D = SS_{r}^{no-lin} -  SS_{r}^{lin}\n  (\\#eq:D)\n\\end{equation}\n\n3. Estime el estadístico F calculado:\n\n\\begin{equation}\n  F = \\frac{D}{SS_{r}^{no-lin}/(n - 3)}\n  (\\#eq:D)\n\\end{equation}\n\n3. Obtenga el F de tabla para 1 grado de libertad en el numerador y\n$n - 3$ para el denominador\n\n4. Compare el $F_{calculado}$ con el $F_{tabla}$ y decida en base a la siguiente\nregla:\n\n- Si $F_{calculado} < F_{tabla}$ se concluye que no hay evidencias en contra\nde la hipótesis nula de linealidad del modelo. ¿Quiere decir que el modelo de\ncalibración es exactamente lineal? Ya sabemos que **NO**. Rigen las mismas\nconsideraciones que que notamos en el test de carencia de ajuste.\n\n- Si $F_{calculado} > F_{tabla}$ se rechaza la hipótesis nula de linealidad\ndel modelo. Los datos no son consistentes con la hipótesis. Y aquí se abre\nuna caja de Pandora, pues esta conclusión también tiene muchas consideraciones\nestadísticas que se deben tener en cuenta para interpretarla apropiadamente las\ncuales, por ahora, no profundizaremos.\n\nLos pasos recién descritos son para llevar a cabo el Test de Mandel \"a mano\",\nafortunadamente los softwares estadísticos como `R` y Excel (sí ¡Excel!) tienen\nincorporada esta prueba estadística de linealidad. Veamos un ejemplo.\n\nLa tabla \\@ref(tab:datamandel) muestra los datos de calibración de Cu por AAS;\nla figura \\@ref(fig:plotmandel), la curva de calibración:\n\n```{r datamandel, echo = F}\nlibrary(kableExtra)\n\nset.seed(123)\nb0 <- -0.006\nb1 <- 0.008\nb2 <- -0.000025\nx <- seq(0, 100, 10)\ny <- b0 + b1*x + b2*x^2 + rnorm(length(x), 0, 0.00148)\ny <- round(y, 3)\nd <- data.frame(x, y)\n\n\nknitr::kable(spread(d, x, y),\n             caption = 'Curva de Calibración Cu',\n             booktabs = T,\n             align = 'c') %>% \n  kable_styling(full_width = F, position = 'left')\n\n\n```\n\n```{r plotmandel, echo = F, fig.cap = 'Curva de calibración Cu'}\nggplot(d, aes(x = x, y = y)) +\n  geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = F) +\n  xlab('Cu [ppm]') +\n  ylab('UA') +\n  theme_bw()\n```\n\nA simple vista se observa la no linealidad de la curva de calibración. Veamos\nque nos dice el Test de Mandel en la siguiente tabla ANOVA:\n\n```{r mandeltest, comment = ''}\n\n# d: corresponde al data frame de los datos de calibración\n\nfit.lin <- lm(y ~ x, data = d) # Ajuste lineal.\nfit.nolin <- lm(y ~ x + I(x^2), data = d) # Ajuste no lineal cuadrático\n\nanova(fit.lin, fit.nolin)\n\n```\n\nEn la tabla el valor \n$F = `r round(anova(fit.lin, fit.nolin )$F[2], 0)`$ corresponde al \n$F_{calculado}$ el cual es comparado internamente con el $F_{tabla}$ \nentregando, finalmente, el _p-value_ \n$Pr(>F) = `r prettyNum(anova(fit.lin, fit.nolin )$'Pr(>F)'[2], digits = 3)`$. \nLa evidencia \nen contra de la hipótesis nula de linealidad es abrumadora.\n\n\n\n# Entonces, resumiendo ¿Por qué no puedo probar linealidad de la curva de calibración?\n\nPorque la decisión está basada en pruebas estadísticas, las cuáles tienen \nalgunas consideraciones para su correcta interpretación:\n\n1. Con estas pruebas estadísticas no se puede probar linealidad, lo que \npodemos concluir es que el modelo lineal es adecuado o razonable\npara modelar nuestros datos de calibración ¡nada más!.\n\n2. Es imposible que en un sistema físico-químico complejo como una llama o plasma/detector\n(ICP-MS) exista una relación \"perfectamente\" lineal entre absorbancia (cuentas) \ny concentración. Lo que hicieron Lambert & Beer (o cualquier científico que \nproponga un modelo de la naturaleza) fue proponer una simplificación \ndel sistema\ny representarlo mediante un modelo cuantitativo. \n\n3. Existen muchos modelos que se podrían ajustar muy bien \na nuestros datos de calibración,\npero en estadística existe el principio de parsimonia:\n\n> En igualdad de condiciones, la explicación más sencilla suele ser la más \nprobable\n\n¿Por qué complicarnos la existencia con un modelo hiper-super-parabólico-\ntangencial si el modelo lineal es razonable y adecuado para nuestros\npropósitos de cuantificación? Pero ojo:\n\n> \"Everything should be made as simple as possible, but no simpler\"\n> -- Albert Einstein\n\nEs aquí donde las pruebas estadísticas nos ayudan a decidir entre varios modelos\nplausibles.\n\n# En defensa del coeficiente de correlación\n\nEs cierto, el $r$ con \"muchos\" 9's no es una prueba formal de linealidad... \n¿quiere decir que el $r$ no es importante en Química\nAnalítica? Por supuesto que sí lo es. Anote:\n\n> El coeficiente de correlación está íntimamente ligado con la\n> incertidumbre de calibración. A mayor $r$ menor es la \n> incertidumbre de calibración.\n\nPuede profundizar en este aspecto consultando en:\n\nEllison, S.L.R. In defense of the correlation\ncoefficient. _Accred Qual Assur (2006) 11: 146._ \nhttps://doi.org/10.1007/s00769-006-0087-y \n\n\n# Por último... ¿y el $r^2$?\n\nAhhh, pero eso es otra cosa... hasta la próxima. \n\n\n# Bibliografía\n\n1. Lutz Brüggemann, Wolfgang Quapp, Rainer Wennrich **Test for non-linearity concerning linear calibrated chemical measurements** (2006) _Accreditation and Quality Assurance Volume 11, Issue 12, pp 625–631_\n\n2. J. M. Andrade and M. P. Gómez-Carracedo **Notes on the use of Mandel's test to check for nonlinearity in laboratory calibrations**\n_Anal. Methods, 2013,5, 1145-1149_\n---\n","srcMarkdownNoYaml":"\n\n\nEn este post intentaremos derribar el mito del coeficiente de correlación con\n\"muchos\" 9's como prueba de linealidad. Además, presentaremos dos test\nformales para evaluar el modelo de calibración lineal en química\nanalítica.\n\n# Coeficiente de correlación\n\nEste parámetro estadístico indica la fuerza y dirección de la relación de\ndos variables cuantitativas, por ejemplo;\n\n- Concentración ($x$) y Absorbancia ($y$)\n- $log \\text{ Concentración}$ y $E$ Potencial (Ecuación de Nernst)\n- La edad de las ganadoras de Miss América con los asesinatos utilizando objetos \ncalientes y vapor. ¡Cuidado con las correlaciones [espurias](http://tylervigen.com/spurious-correlations)!\n\nTodos los químicos estamos familiarizados con la ecuación de Lambert-Beer,\nla cual establece la archiconocida relación entre absorbancia y concentración\nen métodos espectrofotométricos:\n\n\\begin{equation}\n  \\underbrace{A}_\\text{y} = \\underbrace{\\epsilon \\cdot b}_\\text{$\\beta_{1}$} \\cdot\n  \\underbrace{C}_\\text{x}\n    (\\#eq:lambert)\n\\end{equation}\n\n\nDe la ecuación \\@ref(eq:lambert) se observa claramente la relación con el modelo\nestándar de calibración lineal $y = \\beta_{0} + \\beta_{1}x$ asumiendo un\nintercepto $\\beta_{0} = 0$. Por lo tanto ¿por qué nos sorprende tanto \nencontrar un coeficiente de \ncorrelación alto en curvas de calibración espectrofotométricas? Era totalmente\nesperable, pues hay un modelo físico-químico que sustenta el modelo lineal.\n\nOK, de acuerdo. Este modelo físico-químico sólo es válido bajo ciertas \ncondiciones (como todos los modelos), de hecho son conocidas las desviaciones \nde la ley de Lambert-Beer a altas concentraciones.\n\n\n\n# Derribando el mito del r = 0,999...\n\nPara comenzar, por favor, ponga atención a la figura \\@ref(fig:anscombe)\ndenominada \"El Cuarteto de Anscombe\". La \"gracia\" de estos\ndatos de calibración es que todos tienen la misma pendiente, intercepto, \nerror de calibración y... ¡coeficiente de correlación!\n\n¿No me cree? Le dejo este [link](https://1drv.ms/x/s!AuF6FPVWruwDyKxMLQ2ngb99Eo3q7w?e=5jIW6e) \npara que descargue los datos en archivo Excel\ny se convenza con sus propios ojos.\n\n\n\n```{r anscombe, echo = F, warning=F, fig.cap = 'El Cuarteto de Ascombe'}\n\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n#correlation\ncor1 <- format(cor(anscombe$x1, anscombe$y1), digits=3)\ncor2 <- format(cor(anscombe$x2, anscombe$y2), digits=3)\ncor3 <- format(cor(anscombe$x3, anscombe$y3), digits=3)\ncor4 <- format(cor(anscombe$x4, anscombe$y4), digits=3)\n \n#define the OLS regression\nline1 <- lm(y1 ~ x1, data=anscombe)\nline2 <- lm(y2 ~ x2, data=anscombe)\nline3 <- lm(y3 ~ x3, data=anscombe)\nline4 <- lm(y4 ~ x4, data=anscombe)\n \ncircle.size = 5\ncolors = list('red', '#0066CC', '#4BB14B', '#FCE638')\n \n#plot1\nplot1 <- ggplot(anscombe, aes(x=x1, y=y1)) + geom_point(size=circle.size, pch=21, fill=colors[[1]]) +\n  geom_abline(intercept=line1$coefficients[1], slope=line1$coefficients[2]) +\n  annotate(\"text\", x = 10.5, y = 5, label = paste(\"correlación = \", cor1))\n \n#plot2\nplot2 <- ggplot(anscombe, aes(x=x2, y=y2)) + geom_point(size=circle.size, pch=21, fill=colors[[2]]) +\n  geom_abline(intercept=line2$coefficients[1], slope=line2$coefficients[2]) +\n  annotate(\"text\", x = 10, y = 3, label = paste(\"correlación = \", cor2))\n \n#plot3\nplot3 <- ggplot(anscombe, aes(x=x3, y=y3)) + geom_point(size=circle.size, pch=21, fill=colors[[3]]) +\n  geom_abline(intercept=line3$coefficients[1], slope=line3$coefficients[2]) +\n  annotate(\"text\", x = 10.5, y = 5, label = paste(\"correlación = \", cor3))\n \n#plot4\nplot4 <- ggplot(anscombe, aes(x=x4, y=y4)) + geom_point(size=circle.size, pch=21, fill=colors[[4]]) +\n  geom_abline(intercept=line4$coefficients[1], slope=line4$coefficients[2]) +\n  annotate(\"text\", x = 12.5, y = 6, label = paste(\"correlación = \", cor4))\n \ngrid.arrange(plot1, plot2, plot3, plot4, top='El Cuarteto de Anscombe')\n\n```\n\n\n\n\nEl punto que revela la figura \\@ref(fig:anscombe) es que es posible obtener \ncoeficientes de \ncorrelación \"altos\" inclusive con datos que, a simpe vista, no revelan\nuna relación lineal entre $X$ e $Y$. Es más, es posible obtener un alto\ncoeficiente de correlación donde no existe absolutamente ninguna \ncorrelación entre $X$ e $Y$ mediante un mal de diseño de la curva de \ncalibración. Por ejemplo, en la figura \\@ref(fig:influyente) se muestra a la izquierda\nque la correlación entre $x$ e $y$ es prácticamente 0. Sin embargo, \ncuando incluimos un punto _influyente_, muy alejado de la nube de puntos a \nbaja concentración, mágicamente el r = 1 (derecha).\n\n> *Moraleja:* Trate, en lo posible, de diseñar la curva con los puntos \n> equiespaciados y evite los saltos de varios órdenes de magnitud de la \n> concentración. \n\n```{r influyente, echo = F, fig.cap = 'Punto inlfuyente en la calibración'}\n\nset.seed(123)\nx1 <- seq(0, 1, 0.1)\ny1 <- rnorm(length(x1))\nx2 <- c(x1, 100)\ny2 <- c(y1, 100)\n\nr1 <- cor(x1, y1)\nr2 <- cor(x2, y2)\n\ng1 <- ggplot(data.frame(x1, y1), aes(x1, y1)) +\n  geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = F) +\n  theme_bw() +\n  xlab('x') +\n  ylab('y') +\n  annotate(\"text\", x = 0.25, y = 0.5, \n           label = paste(\"correlación = \", round(r1, 2)))\n  \n\ng2 <- ggplot(data.frame(x2, y2), aes(x2, y2)) +\n  geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = F) +\n  theme_bw() +\n  xlab('x') +\n  ylab('y') +\n  annotate(\"text\", x = 50, y = 25, \n           label = paste(\"correlación = \", round(r2, 2)))\n\ngrid.arrange(g1, g2, top = 'Mal diseño de calibración', ncol = 2)\n\n```\n\n\nLa linealidad tampoco es un parámetro cuantitativo, una curva con r = 0,999 no \nes más lineal que otra con r = 0,99. Observe la figura \\@ref(fig:simplot), ambas curvas fueron simuladas en lenguaje `R` con el mismo intercepto y \npendiente siguiendo estrictamente el modelo lineal \n$y = \\beta_{0} + \\beta_{1}x$, sin embargo, tienen coeficientes de \ncorrelación distintos. La curva de la izquierda no es más lineal que la de la\nderecha ya que ambas fueron simuladas a partir del mismo modelo, la única\ndiferencia es que la de la derecha tiene una mayor dispersión de los puntos, pero\nno por ello es \"menos lineal\", de hecho ambas lo son, pues fueron simuladas.\n\n```{r sim}\n\nset.seed(123) # Es para que Ud. obtenga los mismos \n              # resultados en su simulación en R\n              \n\nb0 <- 1  # Intercepto = 1\nb1 <- 10 # Pendiente = 10\ns <- 1   # Desviación estándar de calibración\n\n# Simulamos el mismo modelo lineal \nx <- 1:10 # Calibrantes\ny1 <- b0 + b1*x + rnorm(10, 0, s) # Absorbancias con \n                                  # error = s = 1\ny2 <- b0 + b1*x + rnorm(10, 0, 10*s) # Absorbancias con \n                                     # error = 10*s = 10\n\n```\n\n```{r simplot, fig.cap = 'Simulación de curvas perfectamente lineales', echo = F}\n\ncor1 <- cor(x, y1)\ncor2 <- cor(x, y2)\n\nlin1 <- ggplot(data.frame(x, y1), aes(x, y1)) + \n  geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = F) +\n  theme_bw() +\n  xlab('x') +\n  ylab('y') +\n  annotate(\"text\", x = 5, y = 30, \n           label = paste(\"correlación = \", round(cor1, 3)))\n\nlin2 <- ggplot(data.frame(x, y2), aes(x, y2)) + \n  geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = F) +\n  theme_bw() +\n  xlab('x') +\n  ylab('y') +\n  annotate(\"text\", x = 5, y = 30, \n           label = paste(\"correlación = \", round(cor2, 3)))\n\ngrid.arrange(lin1, lin2, ncol = 2)\n\n```\n\n\n\n# Test formales de linealidad\n\nExisten varios tests estadísticos formales para evaluar el supuesto de \nlinealidad de la curva de calibración. Sin embargo, en este post veremos dos\nque son los más utilizados en Química Analítica y son sugeridos por \nnormativas internacionales (para presentárselos a los amables auditores).\n\nSi bien no es estrictamente riguroso, para simplificar el concepto, diremos que\nambos tests estadísticos intentan dirimir entre dos hipótesis:\n\n- $H_{0}$ (a.k.a Hipótesis Nula) : El modelo lineal es adecuado para describir \nlos datos de calibración\n- $H_{1}$ (a.k.a Hipótesis alternativa): El modelo lineal **NO** es adecuado para \ndescribir los datos de calibración\n\nTambién debemos hacer la siguiente acotación: En **estadística** \nun modelo lineal es\naquel en que sus parámetros son lineales. Por ejemplo, la curva de calibración lineal\nclásica $y = \\beta_{0} + \\beta_{1}x$ tanto $\\beta_{0}$  y $\\beta_{1}$ son \nlineales. Sin embargo, en un modelo exponencial $y = \\gamma_{0} e^{\\gamma_{1}x}$\nel coeficiente $\\gamma_{1}$ no lo es.\n\nDicho esto, el modelo cuadrático de calibración\n$y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^2$ **es lineal** desde el punto de vista\nestrictamente estadístico. Sin embargo, debido al arraigo del concepto de\nlinealidad en química analítica no modificaremos su interpretación.\n\n\n## Test de carencia de ajuste (_Lack of fit_) ISO 11095\n\n\nEste test está basado en comparar dos estimadores del error aleatorio:\n\n1. Error puro o experimental\n2. Error de carencia de ajuste o _lack of fit_\n\nEs decir, necesitamos un estimador del error aleatorio totalmente independiente\ndel error del modelo de calibración que queremos ajustar. Para estimar este\nerror, la prueba de carencia de ajuste exige que hagamos replicados de cada uno\nde los calibrantes.\n\n> Pero tienen que ser replicados verdaderos. No es válido inyectar varias veces\nel mismo estándar en el equipo. Prepárelos independientemente.\n\nSi los dos estimadores del error aleatorio son similares, entonces el modelo\nde calibración que acabamos de ajustar es adecuado para modelar los \ndatos experimentales. ¿Cuán similares tienen que ser? Lo probaremos con un test\nF. Los detalles algebraicos son latosos-engorrosos y pueden ser consultados \nen la bibliografía. Sólo indicaremos cómo hacer este test de linealidad en \nlenguaje `R`, como no. (¿Y en Excel cuándo?)\n\n\nLa tabla \\@ref(tab:lof) muestra los datos de calibración de cloranfenicol en matriz leche\nobtenida por GC/MS-NCI \n(_Gas Chromatography/Mass Spectrometry - Negative Chemical Ionization_ ...¡Qué \ntiempos aquellos!). Note que cada nivel de calibración está preparado en \ntriplicado totalizando n = 15 calibrantes independientes. \nLa figura \\@ref(fig:lofplot) muestra la curva de calibración.\n\n```{r lof, echo = F, warning=F, message=F}\noptions(knitr.table.format = 'html') \n\n\nlibrary(knitr)\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(broom)\n\nset.seed(123)\nx.caf <- rep(seq(0:0.5, by = 0.25), each = 3)\ny.caf <- 200 + 30000*x.caf + rnorm(length(x.caf), 0, 200)\nReplicado <- factor(rep(1:3, 5))\n\ndata.caf <- data.frame(Replicado, x.caf, y.caf)\n\nkable(data.caf %>% spread(., x.caf, y.caf),\n      digits = 0,\n      align = 'c',\n      caption = 'Calibración CAF [ug/kg]') %>%\n  kable_styling(full_width = T)      \n\n```\n\n```{r lofplot, echo = F, fig.cap = 'Curva de calibración CAF. Test de carencia de ajuste'}\n\nggplot(data.caf, aes(x = x.caf, y = y.caf)) +\n  geom_point(pch = 21, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = F) +\n  theme_bw() +\n  xlab('Concentración CAF [ug/kg]') +\n  ylab('Area')\n\n```\n\nLa tabla \\@ref(tab:lofcal) muestra el análisis estadístico de \nesta calibración:\n\n<!-- Ancho de las tabla -->\n<style type=\"text/css\">\n.table {\n\n    width: 100%;\n    \n}\n</style>\n\n```{r lofcal, echo = F}\n\nfit.cal <- lm(y.caf ~ x.caf, data = data.caf)\nkable(tidy(fit.cal),\n      digits = c(0, 0, 0, 0, 3),\n      caption = 'Pendiente e intercepto de calibración',\n      booktabs = T)\n\n```\n\nPor ahora no nos detendremos en el análisis de la tabla (eso quedará para otro post). Haremos directamente el Test de Carencia de Ajuste (_lack of fit_) en\n`R` el cual se muestra en la tabla \\@ref(tab:loftest):\n\n```{r lofalr3, echo = T, message=F, warning=F, eval = F}\n\nlibrary(olsrr) # Cargamos el package 'olsrr' para aplicar el test lack-of-fit\nols_pure_error_anova(fit.cal)\n\n```\n\n\n```{r loftest, echo = F, message=F, warning=F}\n\noptions(knitr.kable.NA = '')\n\nlibrary(olsrr)\nlof.test <- ols_pure_error_anova(fit.cal)\nlof.test\n# kable(lof.test,\n#       digits = c(0, 0, 0, 0, 2),\n#       caption = 'Tabla de test Carencia de Ajuste')\n\n```\n\nOk, para interpretar el test de carencia de ajuste nos fijaremos en la\nfila que dice \"_Lack of fit_\" y en el _p-value_ del test, el cual aparece\nbajo la columna _Pr(>F)_ = `r round(lof.test$pl, 3)`. La interpretación\ntradicional de una prueba estadística diría algo más o menos así:\n\n> Dado que el _p-value_ $> 0.05$, entonces, no hay evidencias en contra de la \n> hipótesis nula. El modelo lineal es adecuado para modelar los datos de\n> calibración.\n\nAlgunas consideraciones:\n\n1. ¿Dice en alguna parte que el modelo de calibración es lineal? Póngalo de\n_wallpaper_ en su pantalla: **NO**.\n2. Lo único que se puede extraer como conclusión es que el modelo lineal \nes adecuado, es razonable para modelar los datos de calibración. Nada más.\n3. Existen infinitos modelos de calibración que podrían ser idóneos, este test\nnos dice si el que hemos elegido para modelar los datos es razonable/adecuado, \nsin embargo, no nos dice que sea \"EL\" modelo perfecto.\n4. ¿Qué tiene de especial el famoso 0,05? Absolutamente *NADA*. ¿Qué concluiría\nUd. si el _p-value_ fuese 0,04999 ó 0,05001? Sería un test totalmente \ninconcluyente. \n5. Lamentablemente, esto es una dicotomía perversa que desde hace mucho \ntiempo ha sido objeto de varias críticas. Le invito a leer las siguientes\nreferencias sobre la interpretación y controversia de los _p-values_ en ciencia:\n\n- Ronald L. Wasserstein & Nicole A. Lazar (2016)\nThe ASA's Statement on p-Values: Context, Process, and Purpose \n_The American Statistician Volume 70, 2016 - Issue 2_ [link](http://amstat.tandfonline.com/doi/abs/10.1080/00031305.2016.1154108)\n\n- M.Baker Statisticians issue warning over misuse of P values\n_Nature **531**, 151 (10 March 2016)_ [link](http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503)\n\n- Singh Chawla D. Big names in statistics want to shake up much-maligned P value. _Nature. 2017 Jul 26;548(7665):16-17_ [link](https://www.nature.com/news/big-names-in-statistics-want-to-shake-up-much-maligned-p-value-1.22375?beta=false)\n\n\n\n\n\n\n\n\n> \"The p-value was never intended to be a substitute for scientific reasoning\" \n> Ron Wasserstein, Director Ejecutivo de la Asociación Americana de Estadística \n> ASA.\n\n\n\n\n## Test de Mandel ISO 8466-1\n\nEsta prueba estadística es bastante sencilla y está basada en la comparación\nentre el modelo de calibración lineal y un modelo alternativo. Por lo tanto, \nno es una prueba absoluta, sino relativa a la elección del modelo alternativo. Require al menos n = 6 calibrantes (sin replicado).\n\nEn general, el test de Mandel utiliza el modelo de calibración cuadrático para\ncompararlo con el modelo lineal:\n\n$$ y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^2$$\n\nLos detalles estadísticos pueden consultarse en la bibliografía.\n\n1. Primero calcule la suma de cuadrados de los residuos $SS_{r}$ para cada uno de \nlos modelos de acuerdo a la siguiente expresión:\n\n\\begin{equation}\n  SS_{r} = \\sum_{i = 1}^{n} e_{i}^2\n    (\\#eq:res)\n\\end{equation}\n\n\nDonde el residuo $e = y - \\hat{y}$.\n$y$ es la respuesta instrumental observada o experimental \n(áreas, absorbancias, etc.); $\\hat{y}$, es la respuesta instrumental que predice\nel modelo (lineal o o cuadrático) en cada una de las concentraciones de los\ncalibrantes. Si observa la ecuación \\@ref(eq:res) el concepto de residuo es el mismo para\ncualquier modelo de calibración, es decir, ¿cuánto difiere lo que se observa\nexperimentalmente con lo que predice el modelo?\n\nUn buen modelo tiene residuos pequeños.\nUn residuo grande para cierto de nivel de concentración implica que existe una\ngran diferencia entre lo observado y lo que predice el modelo, por lo tanto, nos\nguiará (en otro post) a detectar posibles valores anómalos o _outliers_.\n\n\n2. Calcule la diferencia entre ambas sumas de cuadrado de los residuos, la del\nmodelo no lineal $SS_{r}^{no-lin}$ y la correspondiente al modelo lineal\n$SS_{r}^{lin}$:\n\n\\begin{equation}\n  D = SS_{r}^{no-lin} -  SS_{r}^{lin}\n  (\\#eq:D)\n\\end{equation}\n\n3. Estime el estadístico F calculado:\n\n\\begin{equation}\n  F = \\frac{D}{SS_{r}^{no-lin}/(n - 3)}\n  (\\#eq:D)\n\\end{equation}\n\n3. Obtenga el F de tabla para 1 grado de libertad en el numerador y\n$n - 3$ para el denominador\n\n4. Compare el $F_{calculado}$ con el $F_{tabla}$ y decida en base a la siguiente\nregla:\n\n- Si $F_{calculado} < F_{tabla}$ se concluye que no hay evidencias en contra\nde la hipótesis nula de linealidad del modelo. ¿Quiere decir que el modelo de\ncalibración es exactamente lineal? Ya sabemos que **NO**. Rigen las mismas\nconsideraciones que que notamos en el test de carencia de ajuste.\n\n- Si $F_{calculado} > F_{tabla}$ se rechaza la hipótesis nula de linealidad\ndel modelo. Los datos no son consistentes con la hipótesis. Y aquí se abre\nuna caja de Pandora, pues esta conclusión también tiene muchas consideraciones\nestadísticas que se deben tener en cuenta para interpretarla apropiadamente las\ncuales, por ahora, no profundizaremos.\n\nLos pasos recién descritos son para llevar a cabo el Test de Mandel \"a mano\",\nafortunadamente los softwares estadísticos como `R` y Excel (sí ¡Excel!) tienen\nincorporada esta prueba estadística de linealidad. Veamos un ejemplo.\n\nLa tabla \\@ref(tab:datamandel) muestra los datos de calibración de Cu por AAS;\nla figura \\@ref(fig:plotmandel), la curva de calibración:\n\n```{r datamandel, echo = F}\nlibrary(kableExtra)\n\nset.seed(123)\nb0 <- -0.006\nb1 <- 0.008\nb2 <- -0.000025\nx <- seq(0, 100, 10)\ny <- b0 + b1*x + b2*x^2 + rnorm(length(x), 0, 0.00148)\ny <- round(y, 3)\nd <- data.frame(x, y)\n\n\nknitr::kable(spread(d, x, y),\n             caption = 'Curva de Calibración Cu',\n             booktabs = T,\n             align = 'c') %>% \n  kable_styling(full_width = F, position = 'left')\n\n\n```\n\n```{r plotmandel, echo = F, fig.cap = 'Curva de calibración Cu'}\nggplot(d, aes(x = x, y = y)) +\n  geom_point(pch = 19, col = 'red', size = 3) +\n  geom_smooth(method = 'lm', se = F) +\n  xlab('Cu [ppm]') +\n  ylab('UA') +\n  theme_bw()\n```\n\nA simple vista se observa la no linealidad de la curva de calibración. Veamos\nque nos dice el Test de Mandel en la siguiente tabla ANOVA:\n\n```{r mandeltest, comment = ''}\n\n# d: corresponde al data frame de los datos de calibración\n\nfit.lin <- lm(y ~ x, data = d) # Ajuste lineal.\nfit.nolin <- lm(y ~ x + I(x^2), data = d) # Ajuste no lineal cuadrático\n\nanova(fit.lin, fit.nolin)\n\n```\n\nEn la tabla el valor \n$F = `r round(anova(fit.lin, fit.nolin )$F[2], 0)`$ corresponde al \n$F_{calculado}$ el cual es comparado internamente con el $F_{tabla}$ \nentregando, finalmente, el _p-value_ \n$Pr(>F) = `r prettyNum(anova(fit.lin, fit.nolin )$'Pr(>F)'[2], digits = 3)`$. \nLa evidencia \nen contra de la hipótesis nula de linealidad es abrumadora.\n\n\n\n# Entonces, resumiendo ¿Por qué no puedo probar linealidad de la curva de calibración?\n\nPorque la decisión está basada en pruebas estadísticas, las cuáles tienen \nalgunas consideraciones para su correcta interpretación:\n\n1. Con estas pruebas estadísticas no se puede probar linealidad, lo que \npodemos concluir es que el modelo lineal es adecuado o razonable\npara modelar nuestros datos de calibración ¡nada más!.\n\n2. Es imposible que en un sistema físico-químico complejo como una llama o plasma/detector\n(ICP-MS) exista una relación \"perfectamente\" lineal entre absorbancia (cuentas) \ny concentración. Lo que hicieron Lambert & Beer (o cualquier científico que \nproponga un modelo de la naturaleza) fue proponer una simplificación \ndel sistema\ny representarlo mediante un modelo cuantitativo. \n\n3. Existen muchos modelos que se podrían ajustar muy bien \na nuestros datos de calibración,\npero en estadística existe el principio de parsimonia:\n\n> En igualdad de condiciones, la explicación más sencilla suele ser la más \nprobable\n\n¿Por qué complicarnos la existencia con un modelo hiper-super-parabólico-\ntangencial si el modelo lineal es razonable y adecuado para nuestros\npropósitos de cuantificación? Pero ojo:\n\n> \"Everything should be made as simple as possible, but no simpler\"\n> -- Albert Einstein\n\nEs aquí donde las pruebas estadísticas nos ayudan a decidir entre varios modelos\nplausibles.\n\n# En defensa del coeficiente de correlación\n\nEs cierto, el $r$ con \"muchos\" 9's no es una prueba formal de linealidad... \n¿quiere decir que el $r$ no es importante en Química\nAnalítica? Por supuesto que sí lo es. Anote:\n\n> El coeficiente de correlación está íntimamente ligado con la\n> incertidumbre de calibración. A mayor $r$ menor es la \n> incertidumbre de calibración.\n\nPuede profundizar en este aspecto consultando en:\n\nEllison, S.L.R. In defense of the correlation\ncoefficient. _Accred Qual Assur (2006) 11: 146._ \nhttps://doi.org/10.1007/s00769-006-0087-y \n\n\n# Por último... ¿y el $r^2$?\n\nAhhh, pero eso es otra cosa... hasta la próxima. \n\n\n# Bibliografía\n\n1. Lutz Brüggemann, Wolfgang Quapp, Rainer Wennrich **Test for non-linearity concerning linear calibrated chemical measurements** (2006) _Accreditation and Quality Assurance Volume 11, Issue 12, pp 625–631_\n\n2. J. M. Andrade and M. P. Gómez-Carracedo **Notes on the use of Mandel's test to check for nonlinearity in laboratory calibrations**\n_Anal. Methods, 2013,5, 1145-1149_\n---\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","theme":"cosmo","page-layout":"full","grid":{"sidebar-width":"300px","body-width":"1200px","margin-width":"300px","gutter-width":"0.5rem"},"title":"¿Cómo demuestro que mi curva de calibración es lineal?","date":"2017-08-23","lastmod":"2022-03-26T10:53:06-03:00"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}