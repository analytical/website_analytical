{
  "hash": "c76f05afe45d82ad221e205d9ebedf7b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"¡Mis datos no son normales! ¿Qué hago?...Cálmese, nunca lo fueron... ni lo serán\"\ndate: '2017-09-08'\nlastmod: '2022-03-26T12:30:05-03:00'\n---\n\nBueno, aquí va la primera piedra:\n\n> No existen datos experimentales normales\n\nSus datos obtenidos en el laboratorio no \"siguen\" ninguna distribución de \nprobabilidad. La naturaleza no \"sigue\" ninguna distribución de probabilidad.\n\n> La Normalidad es sólo una abstracción, es un modelo matemático \nde un fenómeno aleatorio.\n\nY como todo modelo, podría ser razonable para un conjunto de datos y totalmente\nequivocado para otro. Somos nosotros, los químicos/científicos, quienes \nproponemos modelos del sistema que estamos estudiando y a través de la \nexperimentación corroboramos o no estos modelos.\n\n\n\n\nTodos los tests estadísticos formales para evaluar la normalidad tampoco\nresponden en forma 100% certera si esta hipótesis es válida, pues\nestán afectos a los errores de tipo falso positivo (I) y falso negativo (II).\nPor lo tanto, las pruebas estadísticas en la práctica no confirman que los\ndatos experimentales sean Normales, sino que nos indican si el modelo Normal\nes razonable o no. Si lo es, actuamos como si \"fuesen\" normales y hacemos \ninferencia estadística a partir de las propiedades de la Normal.\n\nEl modelo Normal se describe en la ecuación @eq-normal y la figura\n\\@ref(fig:plotnormal) muestra la archiconocida forma de campana:\n\n$$\n  f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}}\\exp{-\\frac{1}{2}\\left(\\frac{x - \\mu}{\\sigma}\\right)^2}\n$${#eq-normal}\n\ndonde $\\sigma$ y $\\mu$ son la desviación estándar y media, respectivamente.\nNotar que la distribución Normal es aplicable sólo a variables **continuas**, \ntales como concentración, temperatura, masa, etc. No se puede aplicar \nla distribución normal a variables **discretas** como cuentas de células bajo \nun campo de microscopio, por ejemplo. Quizás algún microbiólogo está \nfamiliarizado con el uso de logaritmos en sus cálculos de incertidumbre, bueno,\nes porque se utilizan otros modelos de probabilidad para datos discretos (ufc), \ncomo el modelo Poisson.\n\nAdvierta también, que los posibles valores que puede tomar la variable $X$ \nestán en el no despreciable rango entre $-\\infty$ y $+\\infty$. ¿Ha comprado \nalgún estándar de calibración cuyo certificado indique una\npureza de $99.7 \\pm 0.5$ %? Raro ¿no? Bueno, pues el proveedor ha aplicado\nequivocadamente la distribución Normal a una variable que no es Normal: pureza\nquímica. En efecto, desde el punto de vista químico la pureza está confinada\nal intervalo $[0, 100]$ \\%, por lo tanto, no tiene sentido químico un certificado\nque indique $99.7 \\pm 0.5$ %. Para modelar pureza química es necesario utilizar\nuna distribución de probabilidad que esté restringida al intervalo $[0, 100]$ % \n(o $[0, 1]$) como, por ejemplo, la distribución Beta.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Distribución Normal con media = 0 y sd = 1 ](index_files/figure-html/plotnormal-1.png){width=672}\n:::\n:::\n\n\n\nExisten varios test para evaluar la palusibilidad de la normalidad de los datos, \npero en este post discutiremos sólo dos de ellos: El test de Shapiro-Wilk y el\nTest de Anderson-Darling.\n\nLa matemática detrás de estos tests no es muy digerible, por lo que simplemente\nlos ejemplificaremos con algunos datos reales y simulados. La ventaja de \nusar simulaciones es que \"creamos\" artificialmente datos de la distribución \nque se nos plazca y así verificar el desempeño de estos tests. Si recuerda, ya\nhabíamos utilizado la simulación cuando revisamos las pruebas de linealidad\nen este [post](https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/).\n\n\n> Antes de hacer cualquier prueba estadística de normalidad grafique los datos,\n> a través de un histograma y un gráfico de probabilidad Normal\n\nEstos gráficos le darán una primera aproximación para evaluar el supuesto de\nnormalidad. Todos los softwares estadísticos incorporan estos gráficos.\nA continuación los veremos en acción en datos normales simulados en \nlenguaje `R`, qué otro. El siguiente es el código para llevar a cabo esta\nsimulación de $n = 100$ datos normales:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123) # Con este comando nos aseguramos de generar siempre\n              # los mismos datos aleatorios. Sino, obviamente, todos\n              # generaríamos números distintos pues son aleatorios ¿no?\n\nn <- 100 # Número de datos a simular\nmu <- 10 # Media de los n = 100 datos\nsigma <- 1 # Desviación estándar de los n = 100 datos\n\n# Genera 100 dato normales con media mu y desviación estándar sigma\n# y guárdalos en el vector llamado x\nx <- rnorm(n, mu, sigma)\n```\n:::\n\n\nAl calcular la media y desviación estándar (muestral) de estos datos obtenemos \n$\\overline{x} = 10.1$ y $s = 0.9$ \"¿Pero cómo?\n¿No habíamos simulado una media de 10 y desviación estándar 1? \nEsto es una estafa\" _Keep calm_ recuerde que son aleatorios. \nLa figura @fig-normplot muestra a la izquierda el histograma y a la derecha \nel gráfico de normalidad (_QQ-Plot_) de los datos simulados:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Izquierda histograma, derecha gráfico de normalidad](index_files/figure-html/fig-normplot-1.png){#fig-normplot width=672}\n:::\n:::\n\n\nEl histograma muestra esa forma de campana característica de la distribución\nnormal. Quizás no conozca el gráfico de probabilidad normal o _QQ-Plot_, pero \nes la primera evidencia que un estadístico revisa para evaluar la hipótesis de\nnormalidad. Note que la \"mayoría\" de los datos está sobre una línea diagonal roja,\ncuando Ud. observe este patrón podría concluir que el modelo normal es \n**razonable** o adecuado para modelar sus datos. \n\n> ¿Son concluyentes estos gráficos?\nNo, en absoluto. Simplemente muestran que la normalidad es una hipótesis \nplausible.\n\nRecuerde que estos datos son simulados, por lo tanto, era esperable este \ncomportamiento. Pero sus datos experimentales son \"reales\", _a priori_ no sabe\nqué comportamiento podrían evidenciar, sólo puede plantear una hipótesis.\n\nApliquemos ahora los test \"formales\" de linealidad: test de Shapiro y\ntest de Anderson. Ambos tests intentan\nevaluar la hipótesis nula $H_{0}$ que los datos provienen de una\ndistribución Normal:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nortest) # Cargamos esta librería que contiene varios test de\n                 # Normalidad, entre ellos Anderson-Darling\n\n# Test de Shapiro-Wilk (no requiere librería nortest)\nshapiro.test(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  x\nW = 0.99388, p-value = 0.9349\n```\n\n\n:::\n\n```{.r .cell-code}\n# test de Anderson-Darling\nad.test(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAnderson-Darling normality test\n\ndata:  x\nA = 0.182, p-value = 0.9104\n```\n\n\n:::\n:::\n\n\nLa interpretación tradicional de las pruebas de hipótesis sería más o \nmenos la siguiente:\n\n> Ya que el _p-value_ > 0,05, entonces, no hay evidencia para rechazar la \n> hipótesis de normalidad de los datos. ¿Se conluye, entonces, que los\ndatos son normales? No. Simplemente, no tenemos la evidencia para rechzar la\nhipótesis.\n\nPor lo tanto, no es que los datos sean normales, sino que la hipótesis de\nnormalidad es razonable, por lo que actuaremos como si fuese cierto.\nObviamente, estos resultados eran esperables pues hemos \"creado\" datos \nnormales, pero recuerde que sus datos son \"reales\", no simulados. Hay otras\nconsideraciones de las pruebas de hipótesis que no mencionaremos por espacio, \npero que un post futuro discutiremos en profundidad. Especialmente, esta\nperversa dicotomía del _p-value_ < ó >  0,05 de la cual ya hicimos mención\nen este [post](https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/). \n\n> \"The p-value was never intended to be a substitute for scientific reasoning\" \n> Ron Wasserstein, Director Ejecutivo de la Asociación Americana de Estadística \n> ASA.\n\n_**Nota**: Para tamaños de muestra grandes ($n > 1000$), una pequeña desviación\nde la normalidad hará que los tests estadísticos acusen No Normalidad_\n\nCuando nos referimos a \"actuar como si fuese cierto\", estamos diciendo que todos\naquellos procedimientos estadísticos que suponen normalidad de los datos, \nfuncionarán de acuerdo a la teoría. ¿Cuáles son estos métodos estadísticos que\nrequieren normalidad de los datos?:\n\n1. Test de Student en todas sus variantes (es un test de sesgo)\n2. Test de Fisher para comparar varianzas (precisión analítica de 2 métodos)\n3. Curva de calibración lineal\n4. Máxima diferencia tolerable entre duplicados de análisis, discutido [aquí](https://www.analytical.cl/post/cual-maxima-diferencia-tolerable-entre-duplicados-analisis/)\n5. Análisis de varianza para evaluar varios métodos analíticos o analistas\n6. Intervalos de confianza para la media de concentraciones.\n7. Incertidumbre de métodos analíticos. El $k = 2$ asume normalidad de las \nconcentraciones.\n8. ... y un largo etc.\n\nOk, es cierto, a medida que aumenta el $n$ la suposición de normalidad es cada\nvez menos relevante. De hecho algunos de los tests mencionados arriba son \nmás o menos \"robustos\" a la suposición de normalidad.\n\n# ¿Qué observaríamos si la hipótesis de normalidad fuese totalmente inverosímil para modelar nuestros datos?\n\nSimulemos ahora datos no normales y veamos cuáles son los resultados tanto de los\ngráficos exploratorios como de las pruebas estadísticas formales:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simularemos m = 100 datos discretos de una distribución Poisson\n\nset.seed (123) # Para que pueda reproducir los datos\nm <- 100 # m = 100 datos\nlambda <- 5 # Parámetro de la distribución Poisson\n\n# Generar m = 100 datos de una distribución Poisson con parámtro lambda = 5\ny <- rpois(m, lambda)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\n{{% callout warning %}}\n¿No les parece familiar el QQ-Plot a aquellos que validan homogeneidad de peso en\nvalidación de procesos farmacéuticos? 1313{{% /callout %}}\n\nLa evidencia de los gráficos es abrumadora, los datos no son normales. Esto\nconcuerda con lo que muestran los tests estadísticos de normalidad:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Test de Shapiro-Wilk (no requiere librería nortets)\nshapiro.test(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  y\nW = 0.97077, p-value = 0.02531\n```\n\n\n:::\n\n```{.r .cell-code}\n# test de Anderson-Darling\nad.test(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAnderson-Darling normality test\n\ndata:  y\nA = 1.2355, p-value = 0.003072\n```\n\n\n:::\n:::\n\n\nComo era esperable, ambos tests confirman que la hipótesis de normalidad\nno es razonable para modelar los datos(_p-value_ < 0,05)\n\n# Si mis datos no son normales, entonces ¿Cómo los analizo?\n\nTranquilo(a), el mundo sigue girando. Existen varios métodos estadísticos \nque Ud. puede utilizar para analizar datos donde la hipótesis de normalidad\nno es razonable o se ha demostrado empíricamente que no es :\n\n1. **Bootstrap**: Utilizado, entre otros propósitos, para obtener intervalos de\nconfianza para datos no normales.\n2. **Tests no paramétricos**: Análogos a las pruebas paramétricas tradicionales \n(Test T, ANOVA, etc.)\n3. **Tests de permutaciones**: También son una excelente alternativa a las\npruebas paramétricas tradicionales y funcionan, incluso, para conjuntos \npequeños de datos. Son tests \"exactos\", pero necesitan que Ud. disponga de un \nbuen \"tarro\" (computador) pues son _computationally-intensive methods_.\n4. **Modelos lineales generalizados**: Idóneos para modelar datos discretos como\ncuentas de células (leucocitos, ufc, etc.) o variables dicotómicas \n(Conforme/No Conforme), etc.\n5. **Transformación de datos**: Especialmente útiles son la transformación de\nJohnson y la de Box-Cox.\n6. **Estadística Robusta**: No tan sólo son útiles para minimizar el \nefecto de valores anómalos (_outliers_), sino también para obener estimadores de \ndatos que no son normales.\n\nPara finalizar veamos en acción uno de estos métodos: Bootstrap. \nSin embargo, el detalle estadístico y su implementación los veremos en otro post, por ahora, \nsimplemente lo ejemplificaremos. La figura @fig-As muestra \nel histograma y el _QQ-Plot_ de normalidad correspondientes a datos de concentración de arsénico [ppm] muestreados en $n = 271$ pozos de agua en\nBangladesh:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Histograma y QQ-Plot datos de Arsénico [ppm] en n = 271 pozos en Bangladesh](index_files/figure-html/fig-As-1.png){#fig-As width=672}\n:::\n:::\n\n\nClaramente, ni si quiera es necesario hacer un test de normalidad, la evidencia\nque muestra la figura @fig-As en contra de la hipótesis de normalidad es abrumadora. El promedio de la concentración de As es \n$\\overline{x} = 125$ ppm y la \ndesviación estándar $s = 298$ ppm. Utilizando\nla fórmula usual para estimar un intervalo de confianza al 95% para la media\n$\\overline{x} \\pm t_{\\alpha/2, n - 1} s/\\sqrt{n}$ obtenemos \n[90, 161] ppm As. Sin embargo, la gran asimetría de los datos\nhace inverosímil el intervalo obtenido.\n\nAl aplicar el método _bootstrap_ obtenemos un intervalo para la media al 95% (BCa) entre [95, 164] ppm As, el cual es más\n\"correcto\" por si Ud. necesita informar este parámetro. La figura \n@fig-Asboot muestra el histograma y QQ-Plot de normalidad de\nel método de bootstrap. Advierta el Teorema Central del Límite en su \nmáxima expresión.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Histograma y QQ-Plot de las estimaciones de la media de los datos de As con N = 1000 remuestreos](index_files/figure-html/fig-Asboot-1.png){#fig-Asboot width=672}\n:::\n:::\n\n\nBueno estimado lector, nos vemos pronto. Saludos.\n\n# Bibliografía\n\n1. Ghasemi A, Zahediasl S. Normality Tests for Statistical Analysis: A Guide for Non-Statisticians. _International Journal of Endocrinology and Metabolism_. 2012;10(2):486-489. doi:10.5812/ijem.3505.\n\n2. Henry C. Thode _Testing For Normality_  CRC Press 2002\n\n3. [Is normality testing 'essentially useless'?](http://bit.ly/2pfPsRg)",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}