{
  "hash": "01efc35b46db2f7bcfef2083a444716f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: ¿Cómo detectar el efecto matriz en un método analítico?\ndate: '2017-11-01'\nlastmod: '2022-03-26T13:15:58-03:00'\n---\n\n\n\n\nHe vuelto a postear, después de una gira que me llevó por los cinco... \nmentira, fue por pura pega.\n\nEl famoso efecto matriz, algo tan etéreo como el _criterio analítico_.\nEl efecto matriz está íntimamente relacionado con las interferencias de la \nmatriz que de alguna forma aumentan o disminuyen la señal instrumental que, \nen teoría, es producida sólo por el analito de interés. \n\n\nPara evaluar y detectar el efecto matriz, debemos desempolvar algunos papers\nque nos enseñaron el famoso método de calibración con adición conocida o \nadición de estándar. En este método, la matriz es nuestro \nmedio de calibración. En vez de preparar los calibrantes en solventes puros o \nen solución ácida, utilizaremos la misma matriz para preparar (adicionar) \nel analito. De esta forma, la señal analítica de estos calibrantes, está \ncompuesta de la señal propia del analito así como también de los\ninterferentes, lo que permite corregir/minimizar sus efectos.\n\nExisten varias formas de implementar el método de adición conocida. Una muy\nbuena referencia es el excelente y pedagógico paper de M. Bader:\n\n> Morris Bader \"A systematic approach to standard addition methods in \ninstrumental analysis\" _J. Chem. Educ., 1980, 57 (10), p 703_\n\nEl método consiste en añadir cantidades conocidas del analito en solvente \npuro o solución ácida a volúmenes iguales de matriz. Finalmente, medir la respuesta \ninstrumental en una serie de\nadiciones crecientes tal como lo muestra la figura @fig-mosaplot:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Diseño experimental de la adición conocida. Cortesía de Lins4y via Wikimedia Commons](mosaplot.png){#fig-mosaplot width=1238}\n:::\n:::\n\n\n\n\nEs necesario que las adiciones de analito generen, en \nconjunto con la cantidad de analito presente en la muestra original, \nuna concentración\ntal que aún se encuentre en el rango lineal de calibración. De esta forma\nse otiene una curva tal como se observa en la figura @fig-adicion:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Preparación curva método de adición conocida](c0adicion.png){#fig-adicion width=316}\n:::\n:::\n\n\nLas unidades del eje $X$ pueden establecerse como _analito añadido_ o, \ntal como lo propone Bader en su paper, como múltiplos de un volumen\no cantidad fija del analito. Por lo tanto, en $x = 0$ se obtiene la \nseñal de la muestra problema a la cual no se le ha agregado el \nanalito, es decir, la señal original. En cada una de las adiciones\ndel estándar mediremos la señal instrumental de tal manera de \nobtener, y así lo esperamos, una relación lineal entre analito \nagregado $x$ y señal $y$ de la forma:\n\n\\begin{equation}\n  y = \\beta_{0} + \\beta_{1}x + \\epsilon\n    (\\#eq:calib)\n\\end{equation}\n\ndonde se asumen los mismos supuestos que discutimos en el caso de la\ncalibración lineal estándar(en solvente puro) y que puede recordar en este \n[post](https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/).\n\nLa concentración de la muestra problema $C_{0}$ se obtiene a partir de la \necuación @eq-c0:\n\n$$\n  C_{0} = \\frac{\\beta_{0}}{\\beta_{1}}\n$${#eq-c0}\n  \n\nLa incertidumbre de la concentración de la muestra problema $u(C_{0})$ se \ncalcula a partir de la ecuación:\n\n\n$$\n  u(C_{0}) = \\frac{\\sigma_{y/x}}{\\beta_{1}}\n  \\sqrt{\\frac{1}{n} + \\frac{\\overline{y}^2}\n  {\\beta_{1}\\sum_{i}^{n} (x_{i} - \\overline{x})^2}}\n$${#eq-uc0}\n\ndonde:\n\n- $\\sigma_{y/x}$ es la desviación estándar del error aleatorio $\\epsilon$\n- $n$ es el número de adiciones independientes del estándar\n- $\\overline{y}$ es el promedio de las señales instrumentales de las adiciones\n- $\\overline{x}$ es el promedio de las concentraciones \n\n\nComo puede apreciar, la expresión de la incertidumbre de calibración para el \nmétodo de adición conocida es muy\nsimilar a la correspondiente calibración estandar que discutimos en un \n[post anterior](https://www.analytical.cl/post/como-calcular-la-incertidumbre-de-una-curva-de-calibracion/).\n\nSi queremos minimizar esta incertidumbre podríamos aumentar el número de \nadiciones $n$ o aumentar el término $\\sum_{i}^{n} (x_{i} - \\overline{x})^2$. \nEste último término es interesante, pues nos dice que la incertidumbre de calibración \nde este método se minimiza utilizando un rango amplio de concentración de\nadición. Ellison demuestra que, dado que la propiedad\nde linealidad se mantiene, basta preparar dos puntos de calibración:\n\n- La muestra original sin adición ($x = 0$)\n- El extremo superior del rango lineal\n\nPor ejemplo, si por alguna razón se tuvieran que preparar $n = 6$ adiciones, lo\nque indica la ecuación @eq-uc0, es que sería mejor preparar tres puntos\nsin adición ($x = 0$) y tres en el extremos superior del rango lineal, tal \ncomo lo demuestra la figura @fig-doe\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Diseño de una curva de calibración con adición conocida para minimizar la incertidumbre](doeadicion.png){#fig-doe width=299}\n:::\n:::\n\n\nPara evaluar estadísticamente si existe un efecto matriz debemos \ncomparar la curva de calibración estándar (es decir, en solvente orgánico o en\nsolución ácida) con la curva de adición conocida. Si las pendientes de ambas\ncurvas son \"iguales\" podemos afirmar que no hay evidencia de efecto matriz tal\ncomo se muestra en la figura @fig-sinefecto. De modo contrario, si las \npendientes de ambas curvas difieren, entonces, existe un efecto matriz\nsignificativo, tal como lo indica la figura @fig-conefecto:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Sin efecto matriz: calibración estándar v/s adición conocida](sinefecto.png){#fig-sinefecto width=490}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Con efecto matriz: calibración estándar v/s adición conocida](conefecto.png){#fig-conefecto width=489}\n:::\n:::\n\n\n> Ahora, Ud. se preguntará ¿Cuál es la herramienta estadística para comparar dos\n> pendientes de curvas de calibración? \n\n¡Excelente pregunta Tu(x3)!\n\nAunque hay varias aproximaciones para hacer esta comparación, en este post\nutilizaremos el Análisis de Covarianza (ANCOVA) y lo implementaremos, como no, en lenguaje `R`. La siguiente tabla muestra los datos de calibración de clorpirifos\nen vino por GC-NPD, tanto en solvente puro como mediante el método de adición\nconocida en la muestra de vino:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Tabla datos de calibración clorpirifos](tabla_mosa.png){width=229}\n:::\n:::\n\n\nNote que en la caso de la calibración estándar, las unidades de\nconcentración están expresadas como $\\mu$g de clorpirifos por mL de solvente. \nEn cambio, en los datos de adición conocida están expresadas como $\\mu$g de \nclorpirifos añadidos en los mL de muestra original. Por lo tanto, \n$X = 0\\, \\mu\\text{g}/\\text{mL}_{\\text{vino}}$ representa la muestra sin adición.\nLa figura @fig-mosa muestra las curvas de calibración correspondientes.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Curvas de calibración](mosa.png){#fig-mosa width=517}\n:::\n:::\n\n\nApliquemos, ahora, el análisis de covarianza para evaluar si existen\ndiferencias significativas entre las pendientes. \n\nPrimero, ajustemos un modelo lineal para cada calibración:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Curva de calibración estándar\nx <- c(0, 0.1, 0.2, 0.3, 0.5, 1.0)\ny <- c(0, 80, 159, 245, 410, 795)\nfit.std <- lm(y ~ x)\n\n# Curva de adición conocida\nx.add <- c(0, 0.1, 0.2, 0.3, 0.4, 0.5)\ny.add <- c(75, 159, 240, 328, 410, 498)\nfit.add <- lm(y.add ~ x.add)\n\n# En R la expresión y ~ x significa 'y es modelado por x'\n```\n:::\n\n\nA continuación se muestran los análisis estadísticos para cada\ncurva:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit.std)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n     1      2      3      4      5      6 \n-2.489 -2.206 -2.924  3.359  8.924 -4.664 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    2.489      3.420   0.728    0.507    \nx            797.176      7.105 112.193 3.78e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.751 on 4 degrees of freedom\nMultiple R-squared:  0.9997,\tAdjusted R-squared:  0.9996 \nF-statistic: 1.259e+04 on 1 and 4 DF,  p-value: 3.785e-08\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit.add)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y.add ~ x.add)\n\nResiduals:\n      1       2       3       4       5       6 \n 1.1429  0.6857 -2.7714  0.7714 -1.6857  1.8571 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   73.857      1.463   50.49 9.21e-07 ***\nx.add        844.571      4.832  174.79 6.43e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.021 on 4 degrees of freedom\nMultiple R-squared:  0.9999,\tAdjusted R-squared:  0.9998 \nF-statistic: 3.055e+04 on 1 and 4 DF,  p-value: 6.426e-09\n```\n\n\n:::\n:::\n\n\n\nLa pendiente de la curva de calibración estándar es 797\ny la pendiente del método de adición es 845. \n¿Es esta diferencia significativa? Esta es la pregunta que responde el ANCOVA. Para implementar este test en `R`debemos hacer una pequeña\nmodificación a nuestra base de datos:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Consolidaremos los datos de calibración en una sola tabla llamada 'datos'\ndatos <- data.frame(X = c(x, x.add), \n                    Y = c(y, y.add), \n                    Calibracion = c(rep('Estandar', 6), rep('Adicion', 6)))\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> X </th>\n   <th style=\"text-align:left;\"> Y </th>\n   <th style=\"text-align:left;\"> Calibracion </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 0.0 </td>\n   <td style=\"text-align:left;\"> 0 </td>\n   <td style=\"text-align:left;\"> Estandar </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.1 </td>\n   <td style=\"text-align:left;\"> 80 </td>\n   <td style=\"text-align:left;\"> Estandar </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.2 </td>\n   <td style=\"text-align:left;\"> 159 </td>\n   <td style=\"text-align:left;\"> Estandar </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.3 </td>\n   <td style=\"text-align:left;\"> 245 </td>\n   <td style=\"text-align:left;\"> Estandar </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.5 </td>\n   <td style=\"text-align:left;\"> 410 </td>\n   <td style=\"text-align:left;\"> Estandar </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 1.0 </td>\n   <td style=\"text-align:left;\"> 795 </td>\n   <td style=\"text-align:left;\"> Estandar </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.0 </td>\n   <td style=\"text-align:left;\"> 75 </td>\n   <td style=\"text-align:left;\"> Adicion </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.1 </td>\n   <td style=\"text-align:left;\"> 159 </td>\n   <td style=\"text-align:left;\"> Adicion </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.2 </td>\n   <td style=\"text-align:left;\"> 240 </td>\n   <td style=\"text-align:left;\"> Adicion </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.3 </td>\n   <td style=\"text-align:left;\"> 328 </td>\n   <td style=\"text-align:left;\"> Adicion </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.4 </td>\n   <td style=\"text-align:left;\"> 410 </td>\n   <td style=\"text-align:left;\"> Adicion </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.5 </td>\n   <td style=\"text-align:left;\"> 498 </td>\n   <td style=\"text-align:left;\"> Adicion </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nUna vez consolidados los datos en una única tabla podemos aplicar el \nanálisis de covarianza en `R` con los siguientes comandos de la librería\n`car`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\n\n# Ajustamos un modelo con interceptos distintos y una pendiente para cada\n# calibración\n\nfit <- lm(Y ~ X + Calibracion + X:Calibracion, data = datos)\nAnova(fit, type = 'II')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnova Table (Type II tests)\n\nResponse: Y\n              Sum Sq Df   F value    Pr(>F)    \nX             540763  1 29108.930 1.558e-15 ***\nCalibracion    20535  1  1105.398 7.309e-10 ***\nX:Calibracion    310  1    16.699  0.003503 ** \nResiduals        149  8                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\nDe la tabla se observa que el _p-value_ de la comparación de las pendientes\nes $Pr(>F) = 0.0035$ el cual es menor\na 0.05 (`X:Calibracion`), por lo tanto, la diferencia observada entre las pendientes es, desde el punto de vista estadístico, significativa.\nEsto implica que existe un efecto matriz que no está corregido por la \ncalibración en solvente. En definitiva, para este tipo de muestra, \nsería apropiado\nutilizar el método de adición conocida para la determinación de clorpirifos \nen vino.\n\nAhora, esta conclusión debe ser complementada con el criterio químico y \nmetrológico. Recuerde que la desventaja del método de adición conocida\nes que es necesario hacer la adición muestra a muestra.  Lo que se concluye\ndel ANCOVA está basado en un criterio puramente estadístico.\n\nBueno estimado lector, espero haya disfrutado este post.\n\nEspero sus comentarios. Nos vemos.\n\n## Bibliografía\n\nEllison SL, Thompson M. **Standard additions: myth and reality**\n(2008) _Analyst 133(8):992-7._\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}