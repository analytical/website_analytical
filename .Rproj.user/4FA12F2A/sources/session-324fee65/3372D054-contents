---
title: ¿Cómo demuestro que mi curva de calibración es lineal?
author: 'Carlos Gómez'
date: '2017-08-23'
slug: como-demuestro-que-mi-curva-de-calibracion-es-lineal
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2022-03-26T10:53:06-03:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---


En este post intentaremos derribar el mito del coeficiente de correlación con
"muchos" 9's como prueba de linealidad. Además, presentaremos dos test
formales para evaluar el modelo de calibración lineal en química
analítica.

# Coeficiente de correlación

Este parámetro estadístico indica la fuerza y dirección de la relación de
dos variables cuantitativas, por ejemplo;

- Concentración ($x$) y Absorbancia ($y$)
- $log \text{ Concentración}$ y $E$ Potencial (Ecuación de Nernst)
- La edad de las ganadoras de Miss América con los asesinatos utilizando objetos 
calientes y vapor. ¡Cuidado con las correlaciones [espurias](http://tylervigen.com/spurious-correlations)!

Todos los químicos estamos familiarizados con la ecuación de Lambert-Beer,
la cual establece la archiconocida relación entre absorbancia y concentración
en métodos espectrofotométricos:

\begin{equation}
  \underbrace{A}_\text{y} = \underbrace{\epsilon \cdot b}_\text{$\beta_{1}$} \cdot
  \underbrace{C}_\text{x}
    (\#eq:lambert)
\end{equation}


De la ecuación \@ref(eq:lambert) se observa claramente la relación con el modelo
estándar de calibración lineal $y = \beta_{0} + \beta_{1}x$ asumiendo un
intercepto $\beta_{0} = 0$. Por lo tanto ¿por qué nos sorprende tanto 
encontrar un coeficiente de 
correlación alto en curvas de calibración espectrofotométricas? Era totalmente
esperable, pues hay un modelo físico-químico que sustenta el modelo lineal.

OK, de acuerdo. Este modelo físico-químico sólo es válido bajo ciertas 
condiciones (como todos los modelos), de hecho son conocidas las desviaciones 
de la ley de Lambert-Beer a altas concentraciones.



# Derribando el mito del r = 0,999...

Para comenzar, por favor, ponga atención a la figura \@ref(fig:anscombe)
denominada "El Cuarteto de Anscombe". La "gracia" de estos
datos de calibración es que todos tienen la misma pendiente, intercepto, 
error de calibración y... ¡coeficiente de correlación!

¿No me cree? Le dejo este [link](https://1drv.ms/x/s!AuF6FPVWruwDyKxMLQ2ngb99Eo3q7w?e=5jIW6e) 
para que descargue los datos en archivo Excel
y se convenza con sus propios ojos.



```{r anscombe, echo = F, warning=F, fig.cap = 'El Cuarteto de Ascombe'}

library(ggplot2)
library(gridExtra)

#correlation
cor1 <- format(cor(anscombe$x1, anscombe$y1), digits=3)
cor2 <- format(cor(anscombe$x2, anscombe$y2), digits=3)
cor3 <- format(cor(anscombe$x3, anscombe$y3), digits=3)
cor4 <- format(cor(anscombe$x4, anscombe$y4), digits=3)
 
#define the OLS regression
line1 <- lm(y1 ~ x1, data=anscombe)
line2 <- lm(y2 ~ x2, data=anscombe)
line3 <- lm(y3 ~ x3, data=anscombe)
line4 <- lm(y4 ~ x4, data=anscombe)
 
circle.size = 5
colors = list('red', '#0066CC', '#4BB14B', '#FCE638')
 
#plot1
plot1 <- ggplot(anscombe, aes(x=x1, y=y1)) + geom_point(size=circle.size, pch=21, fill=colors[[1]]) +
  geom_abline(intercept=line1$coefficients[1], slope=line1$coefficients[2]) +
  annotate("text", x = 10.5, y = 5, label = paste("correlación = ", cor1))
 
#plot2
plot2 <- ggplot(anscombe, aes(x=x2, y=y2)) + geom_point(size=circle.size, pch=21, fill=colors[[2]]) +
  geom_abline(intercept=line2$coefficients[1], slope=line2$coefficients[2]) +
  annotate("text", x = 10, y = 3, label = paste("correlación = ", cor2))
 
#plot3
plot3 <- ggplot(anscombe, aes(x=x3, y=y3)) + geom_point(size=circle.size, pch=21, fill=colors[[3]]) +
  geom_abline(intercept=line3$coefficients[1], slope=line3$coefficients[2]) +
  annotate("text", x = 10.5, y = 5, label = paste("correlación = ", cor3))
 
#plot4
plot4 <- ggplot(anscombe, aes(x=x4, y=y4)) + geom_point(size=circle.size, pch=21, fill=colors[[4]]) +
  geom_abline(intercept=line4$coefficients[1], slope=line4$coefficients[2]) +
  annotate("text", x = 12.5, y = 6, label = paste("correlación = ", cor4))
 
grid.arrange(plot1, plot2, plot3, plot4, top='El Cuarteto de Anscombe')

```




El punto que revela la figura \@ref(fig:anscombe) es que es posible obtener 
coeficientes de 
correlación "altos" inclusive con datos que, a simpe vista, no revelan
una relación lineal entre $X$ e $Y$. Es más, es posible obtener un alto
coeficiente de correlación donde no existe absolutamente ninguna 
correlación entre $X$ e $Y$ mediante un mal de diseño de la curva de 
calibración. Por ejemplo, en la figura \@ref(fig:influyente) se muestra a la izquierda
que la correlación entre $x$ e $y$ es prácticamente 0. Sin embargo, 
cuando incluimos un punto _influyente_, muy alejado de la nube de puntos a 
baja concentración, mágicamente el r = 1 (derecha).

> *Moraleja:* Trate, en lo posible, de diseñar la curva con los puntos 
> equiespaciados y evite los saltos de varios órdenes de magnitud de la 
> concentración. 

```{r influyente, echo = F, fig.cap = 'Punto inlfuyente en la calibración'}

set.seed(123)
x1 <- seq(0, 1, 0.1)
y1 <- rnorm(length(x1))
x2 <- c(x1, 100)
y2 <- c(y1, 100)

r1 <- cor(x1, y1)
r2 <- cor(x2, y2)

g1 <- ggplot(data.frame(x1, y1), aes(x1, y1)) +
  geom_point(pch = 19, col = 'red', size = 3) +
  geom_smooth(method = 'lm', se = F) +
  theme_bw() +
  xlab('x') +
  ylab('y') +
  annotate("text", x = 0.25, y = 0.5, 
           label = paste("correlación = ", round(r1, 2)))
  

g2 <- ggplot(data.frame(x2, y2), aes(x2, y2)) +
  geom_point(pch = 19, col = 'red', size = 3) +
  geom_smooth(method = 'lm', se = F) +
  theme_bw() +
  xlab('x') +
  ylab('y') +
  annotate("text", x = 50, y = 25, 
           label = paste("correlación = ", round(r2, 2)))

grid.arrange(g1, g2, top = 'Mal diseño de calibración', ncol = 2)

```


La linealidad tampoco es un parámetro cuantitativo, una curva con r = 0,999 no 
es más lineal que otra con r = 0,99. Observe la figura \@ref(fig:simplot), ambas curvas fueron simuladas en lenguaje `R` con el mismo intercepto y 
pendiente siguiendo estrictamente el modelo lineal 
$y = \beta_{0} + \beta_{1}x$, sin embargo, tienen coeficientes de 
correlación distintos. La curva de la izquierda no es más lineal que la de la
derecha ya que ambas fueron simuladas a partir del mismo modelo, la única
diferencia es que la de la derecha tiene una mayor dispersión de los puntos, pero
no por ello es "menos lineal", de hecho ambas lo son, pues fueron simuladas.

```{r sim}

set.seed(123) # Es para que Ud. obtenga los mismos 
              # resultados en su simulación en R
              

b0 <- 1  # Intercepto = 1
b1 <- 10 # Pendiente = 10
s <- 1   # Desviación estándar de calibración

# Simulamos el mismo modelo lineal 
x <- 1:10 # Calibrantes
y1 <- b0 + b1*x + rnorm(10, 0, s) # Absorbancias con 
                                  # error = s = 1
y2 <- b0 + b1*x + rnorm(10, 0, 10*s) # Absorbancias con 
                                     # error = 10*s = 10

```

```{r simplot, fig.cap = 'Simulación de curvas perfectamente lineales', echo = F}

cor1 <- cor(x, y1)
cor2 <- cor(x, y2)

lin1 <- ggplot(data.frame(x, y1), aes(x, y1)) + 
  geom_point(pch = 19, col = 'red', size = 3) +
  geom_smooth(method = 'lm', se = F) +
  theme_bw() +
  xlab('x') +
  ylab('y') +
  annotate("text", x = 5, y = 30, 
           label = paste("correlación = ", round(cor1, 3)))

lin2 <- ggplot(data.frame(x, y2), aes(x, y2)) + 
  geom_point(pch = 19, col = 'red', size = 3) +
  geom_smooth(method = 'lm', se = F) +
  theme_bw() +
  xlab('x') +
  ylab('y') +
  annotate("text", x = 5, y = 30, 
           label = paste("correlación = ", round(cor2, 3)))

grid.arrange(lin1, lin2, ncol = 2)

```



# Test formales de linealidad

Existen varios tests estadísticos formales para evaluar el supuesto de 
linealidad de la curva de calibración. Sin embargo, en este post veremos dos
que son los más utilizados en Química Analítica y son sugeridos por 
normativas internacionales (para presentárselos a los amables auditores).

Si bien no es estrictamente riguroso, para simplificar el concepto, diremos que
ambos tests estadísticos intentan dirimir entre dos hipótesis:

- $H_{0}$ (a.k.a Hipótesis Nula) : El modelo lineal es adecuado para describir 
los datos de calibración
- $H_{1}$ (a.k.a Hipótesis alternativa): El modelo lineal **NO** es adecuado para 
describir los datos de calibración

También debemos hacer la siguiente acotación: En **estadística** 
un modelo lineal es
aquel en que sus parámetros son lineales. Por ejemplo, la curva de calibración lineal
clásica $y = \beta_{0} + \beta_{1}x$ tanto $\beta_{0}$  y $\beta_{1}$ son 
lineales. Sin embargo, en un modelo exponencial $y = \gamma_{0} e^{\gamma_{1}x}$
el coeficiente $\gamma_{1}$ no lo es.

Dicho esto, el modelo cuadrático de calibración
$y = \beta_{0} + \beta_{1}x + \beta_{2}x^2$ **es lineal** desde el punto de vista
estrictamente estadístico. Sin embargo, debido al arraigo del concepto de
linealidad en química analítica no modificaremos su interpretación.


## Test de carencia de ajuste (_Lack of fit_) ISO 11095


Este test está basado en comparar dos estimadores del error aleatorio:

1. Error puro o experimental
2. Error de carencia de ajuste o _lack of fit_

Es decir, necesitamos un estimador del error aleatorio totalmente independiente
del error del modelo de calibración que queremos ajustar. Para estimar este
error, la prueba de carencia de ajuste exige que hagamos replicados de cada uno
de los calibrantes.

> Pero tienen que ser replicados verdaderos. No es válido inyectar varias veces
el mismo estándar en el equipo. Prepárelos independientemente.

Si los dos estimadores del error aleatorio son similares, entonces el modelo
de calibración que acabamos de ajustar es adecuado para modelar los 
datos experimentales. ¿Cuán similares tienen que ser? Lo probaremos con un test
F. Los detalles algebraicos son latosos-engorrosos y pueden ser consultados 
en la bibliografía. Sólo indicaremos cómo hacer este test de linealidad en 
lenguaje `R`, como no. (¿Y en Excel cuándo?)


La tabla \@ref(tab:lof) muestra los datos de calibración de cloranfenicol en matriz leche
obtenida por GC/MS-NCI 
(_Gas Chromatography/Mass Spectrometry - Negative Chemical Ionization_ ...¡Qué 
tiempos aquellos!). Note que cada nivel de calibración está preparado en 
triplicado totalizando n = 15 calibrantes independientes. 
La figura \@ref(fig:lofplot) muestra la curva de calibración.

```{r lof, echo = F, warning=F, message=F}
options(knitr.table.format = 'html') 


library(knitr)
library(tidyverse)
library(kableExtra)
library(broom)

set.seed(123)
x.caf <- rep(seq(0:0.5, by = 0.25), each = 3)
y.caf <- 200 + 30000*x.caf + rnorm(length(x.caf), 0, 200)
Replicado <- factor(rep(1:3, 5))

data.caf <- data.frame(Replicado, x.caf, y.caf)

kable(data.caf %>% spread(., x.caf, y.caf),
      digits = 0,
      align = 'c',
      caption = 'Calibración CAF [ug/kg]') %>%
  kable_styling(full_width = T)      

```

```{r lofplot, echo = F, fig.cap = 'Curva de calibración CAF. Test de carencia de ajuste'}

ggplot(data.caf, aes(x = x.caf, y = y.caf)) +
  geom_point(pch = 21, col = 'red', size = 3) +
  geom_smooth(method = 'lm', se = F) +
  theme_bw() +
  xlab('Concentración CAF [ug/kg]') +
  ylab('Area')

```

La tabla \@ref(tab:lofcal) muestra el análisis estadístico de 
esta calibración:

<!-- Ancho de las tabla -->
<style type="text/css">
.table {

    width: 100%;
    
}
</style>

```{r lofcal, echo = F}

fit.cal <- lm(y.caf ~ x.caf, data = data.caf)
kable(tidy(fit.cal),
      digits = c(0, 0, 0, 0, 3),
      caption = 'Pendiente e intercepto de calibración',
      booktabs = T)

```

Por ahora no nos detendremos en el análisis de la tabla (eso quedará para otro post). Haremos directamente el Test de Carencia de Ajuste (_lack of fit_) en
`R` el cual se muestra en la tabla \@ref(tab:loftest):

```{r lofalr3, echo = T, message=F, warning=F, eval = F}

library(olsrr) # Cargamos el package 'olsrr' para aplicar el test lack-of-fit
ols_pure_error_anova(fit.cal)

```


```{r loftest, echo = F, message=F, warning=F}

options(knitr.kable.NA = '')

library(olsrr)
lof.test <- ols_pure_error_anova(fit.cal)
lof.test
# kable(lof.test,
#       digits = c(0, 0, 0, 0, 2),
#       caption = 'Tabla de test Carencia de Ajuste')

```

Ok, para interpretar el test de carencia de ajuste nos fijaremos en la
fila que dice "_Lack of fit_" y en el _p-value_ del test, el cual aparece
bajo la columna _Pr(>F)_ = `r round(lof.test$pl, 3)`. La interpretación
tradicional de una prueba estadística diría algo más o menos así:

> Dado que el _p-value_ $> 0.05$, entonces, no hay evidencias en contra de la 
> hipótesis nula. El modelo lineal es adecuado para modelar los datos de
> calibración.

Algunas consideraciones:

1. ¿Dice en alguna parte que el modelo de calibración es lineal? Póngalo de
_wallpaper_ en su pantalla: **NO**.
2. Lo único que se puede extraer como conclusión es que el modelo lineal 
es adecuado, es razonable para modelar los datos de calibración. Nada más.
3. Existen infinitos modelos de calibración que podrían ser idóneos, este test
nos dice si el que hemos elegido para modelar los datos es razonable/adecuado, 
sin embargo, no nos dice que sea "EL" modelo perfecto.
4. ¿Qué tiene de especial el famoso 0,05? Absolutamente *NADA*. ¿Qué concluiría
Ud. si el _p-value_ fuese 0,04999 ó 0,05001? Sería un test totalmente 
inconcluyente. 
5. Lamentablemente, esto es una dicotomía perversa que desde hace mucho 
tiempo ha sido objeto de varias críticas. Le invito a leer las siguientes
referencias sobre la interpretación y controversia de los _p-values_ en ciencia:

- Ronald L. Wasserstein & Nicole A. Lazar (2016)
The ASA's Statement on p-Values: Context, Process, and Purpose 
_The American Statistician Volume 70, 2016 - Issue 2_ [link](http://amstat.tandfonline.com/doi/abs/10.1080/00031305.2016.1154108)

- M.Baker Statisticians issue warning over misuse of P values
_Nature **531**, 151 (10 March 2016)_ [link](http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503)

- Singh Chawla D. Big names in statistics want to shake up much-maligned P value. _Nature. 2017 Jul 26;548(7665):16-17_ [link](https://www.nature.com/news/big-names-in-statistics-want-to-shake-up-much-maligned-p-value-1.22375?beta=false)








> "The p-value was never intended to be a substitute for scientific reasoning" 
> Ron Wasserstein, Director Ejecutivo de la Asociación Americana de Estadística 
> ASA.




## Test de Mandel ISO 8466-1

Esta prueba estadística es bastante sencilla y está basada en la comparación
entre el modelo de calibración lineal y un modelo alternativo. Por lo tanto, 
no es una prueba absoluta, sino relativa a la elección del modelo alternativo. Require al menos n = 6 calibrantes (sin replicado).

En general, el test de Mandel utiliza el modelo de calibración cuadrático para
compararlo con el modelo lineal:

$$ y = \beta_{0} + \beta_{1}x + \beta_{2}x^2$$

Los detalles estadísticos pueden consultarse en la bibliografía.

1. Primero calcule la suma de cuadrados de los residuos $SS_{r}$ para cada uno de 
los modelos de acuerdo a la siguiente expresión:

\begin{equation}
  SS_{r} = \sum_{i = 1}^{n} e_{i}^2
    (\#eq:res)
\end{equation}


Donde el residuo $e = y - \hat{y}$.
$y$ es la respuesta instrumental observada o experimental 
(áreas, absorbancias, etc.); $\hat{y}$, es la respuesta instrumental que predice
el modelo (lineal o o cuadrático) en cada una de las concentraciones de los
calibrantes. Si observa la ecuación \@ref(eq:res) el concepto de residuo es el mismo para
cualquier modelo de calibración, es decir, ¿cuánto difiere lo que se observa
experimentalmente con lo que predice el modelo?

Un buen modelo tiene residuos pequeños.
Un residuo grande para cierto de nivel de concentración implica que existe una
gran diferencia entre lo observado y lo que predice el modelo, por lo tanto, nos
guiará (en otro post) a detectar posibles valores anómalos o _outliers_.


2. Calcule la diferencia entre ambas sumas de cuadrado de los residuos, la del
modelo no lineal $SS_{r}^{no-lin}$ y la correspondiente al modelo lineal
$SS_{r}^{lin}$:

\begin{equation}
  D = SS_{r}^{no-lin} -  SS_{r}^{lin}
  (\#eq:D)
\end{equation}

3. Estime el estadístico F calculado:

\begin{equation}
  F = \frac{D}{SS_{r}^{no-lin}/(n - 3)}
  (\#eq:D)
\end{equation}

3. Obtenga el F de tabla para 1 grado de libertad en el numerador y
$n - 3$ para el denominador

4. Compare el $F_{calculado}$ con el $F_{tabla}$ y decida en base a la siguiente
regla:

- Si $F_{calculado} < F_{tabla}$ se concluye que no hay evidencias en contra
de la hipótesis nula de linealidad del modelo. ¿Quiere decir que el modelo de
calibración es exactamente lineal? Ya sabemos que **NO**. Rigen las mismas
consideraciones que que notamos en el test de carencia de ajuste.

- Si $F_{calculado} > F_{tabla}$ se rechaza la hipótesis nula de linealidad
del modelo. Los datos no son consistentes con la hipótesis. Y aquí se abre
una caja de Pandora, pues esta conclusión también tiene muchas consideraciones
estadísticas que se deben tener en cuenta para interpretarla apropiadamente las
cuales, por ahora, no profundizaremos.

Los pasos recién descritos son para llevar a cabo el Test de Mandel "a mano",
afortunadamente los softwares estadísticos como `R` y Excel (sí ¡Excel!) tienen
incorporada esta prueba estadística de linealidad. Veamos un ejemplo.

La tabla \@ref(tab:datamandel) muestra los datos de calibración de Cu por AAS;
la figura \@ref(fig:plotmandel), la curva de calibración:

```{r datamandel, echo = F}
library(kableExtra)

set.seed(123)
b0 <- -0.006
b1 <- 0.008
b2 <- -0.000025
x <- seq(0, 100, 10)
y <- b0 + b1*x + b2*x^2 + rnorm(length(x), 0, 0.00148)
y <- round(y, 3)
d <- data.frame(x, y)


knitr::kable(spread(d, x, y),
             caption = 'Curva de Calibración Cu',
             booktabs = T,
             align = 'c') %>% 
  kable_styling(full_width = F, position = 'left')


```

```{r plotmandel, echo = F, fig.cap = 'Curva de calibración Cu'}
ggplot(d, aes(x = x, y = y)) +
  geom_point(pch = 19, col = 'red', size = 3) +
  geom_smooth(method = 'lm', se = F) +
  xlab('Cu [ppm]') +
  ylab('UA') +
  theme_bw()
```

A simple vista se observa la no linealidad de la curva de calibración. Veamos
que nos dice el Test de Mandel en la siguiente tabla ANOVA:

```{r mandeltest, comment = ''}

# d: corresponde al data frame de los datos de calibración

fit.lin <- lm(y ~ x, data = d) # Ajuste lineal.
fit.nolin <- lm(y ~ x + I(x^2), data = d) # Ajuste no lineal cuadrático

anova(fit.lin, fit.nolin)

```

En la tabla el valor 
$F = `r round(anova(fit.lin, fit.nolin )$F[2], 0)`$ corresponde al 
$F_{calculado}$ el cual es comparado internamente con el $F_{tabla}$ 
entregando, finalmente, el _p-value_ 
$Pr(>F) = `r prettyNum(anova(fit.lin, fit.nolin )$'Pr(>F)'[2], digits = 3)`$. 
La evidencia 
en contra de la hipótesis nula de linealidad es abrumadora.



# Entonces, resumiendo ¿Por qué no puedo probar linealidad de la curva de calibración?

Porque la decisión está basada en pruebas estadísticas, las cuáles tienen 
algunas consideraciones para su correcta interpretación:

1. Con estas pruebas estadísticas no se puede probar linealidad, lo que 
podemos concluir es que el modelo lineal es adecuado o razonable
para modelar nuestros datos de calibración ¡nada más!.

2. Es imposible que en un sistema físico-químico complejo como una llama o plasma/detector
(ICP-MS) exista una relación "perfectamente" lineal entre absorbancia (cuentas) 
y concentración. Lo que hicieron Lambert & Beer (o cualquier científico que 
proponga un modelo de la naturaleza) fue proponer una simplificación 
del sistema
y representarlo mediante un modelo cuantitativo. 

3. Existen muchos modelos que se podrían ajustar muy bien 
a nuestros datos de calibración,
pero en estadística existe el principio de parsimonia:

> En igualdad de condiciones, la explicación más sencilla suele ser la más 
probable

¿Por qué complicarnos la existencia con un modelo hiper-super-parabólico-
tangencial si el modelo lineal es razonable y adecuado para nuestros
propósitos de cuantificación? Pero ojo:

> "Everything should be made as simple as possible, but no simpler"
> -- Albert Einstein

Es aquí donde las pruebas estadísticas nos ayudan a decidir entre varios modelos
plausibles.

# En defensa del coeficiente de correlación

Es cierto, el $r$ con "muchos" 9's no es una prueba formal de linealidad... 
¿quiere decir que el $r$ no es importante en Química
Analítica? Por supuesto que sí lo es. Anote:

> El coeficiente de correlación está íntimamente ligado con la
> incertidumbre de calibración. A mayor $r$ menor es la 
> incertidumbre de calibración.

Puede profundizar en este aspecto consultando en:

Ellison, S.L.R. In defense of the correlation
coefficient. _Accred Qual Assur (2006) 11: 146._ 
https://doi.org/10.1007/s00769-006-0087-y 


# Por último... ¿y el $r^2$?

Ahhh, pero eso es otra cosa... hasta la próxima. 


# Bibliografía

1. Lutz Brüggemann, Wolfgang Quapp, Rainer Wennrich **Test for non-linearity concerning linear calibrated chemical measurements** (2006) _Accreditation and Quality Assurance Volume 11, Issue 12, pp 625–631_

2. J. M. Andrade and M. P. Gómez-Carracedo **Notes on the use of Mandel's test to check for nonlinearity in laboratory calibrations**
_Anal. Methods, 2013,5, 1145-1149_