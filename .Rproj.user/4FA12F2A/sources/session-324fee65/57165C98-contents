---
title: '¿Cuál es la máxima diferencia tolerable entre duplicados de análisis?'
author: ''
date: '2017-08-28'
slug: cual-maxima-diferencia-tolerable-entre-duplicados-analisis
categories: []
tags: []
subtitle: ''
summary: 'En este post presentaremos dos métodos estadísticos para establecer la máxima diferencia tolerable entre duplicados de análisis. Este criterio de aceptación nos dará una una base para la construcción de cartas control de precisión'
authors: []
lastmod: '2022-03-26T11:49:47-03:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---


Un día cualquiera en un laboratorio que aún no establece criterios de aceptación
de precisión:

- Duplicado 1 = 25.56 % Cu
- Duplicado 2 = 25.66 % Cu
- Diferencia = 0.10 % Cu

La diferencia observada ¿es aceptable para el laboratorio?

Para responder a esta pregunta debemos considerar varias cosas:

1. ¿Los duplicados fueron realizados en condiciones de repetibilidad o 
reproducibilidad?
2. ¿Existe alguna normativa al respecto que se deba cumplir?
3. ¿Cuál es la metodología analítica? No es lo mismo determinar Cu en 
concentrado de cobre por electrogravimetría (método primario) que por 
Fluorescencia de Rayos X.
4. ¿Cuál es la incertidumbre del método analítico?
5. ¿Existe algún acuerdo a nivel comercial sobre estas diferencias?

Para abordar este problema tendremos que hace la suposición que 
los duplicados fueron obtenidos en condiciones de repetibilidad, es decir: mismo
analista, mismo día, mismo instrumento, etc. Bajo esta premisa hay varias formas
de estimar la máxima diferencia tolerable entre duplicados de análisis.

_**Nota**: En realidad, los conceptos que mostraremos a continuación son 
completamente análogos para estimar la máxima diferencia tolerable en 
condiciones de reproducibilidad. Sin embargo, dedicaremos otro post a ese tema 
específico._

El concepto estadístico clave para establecer la tolerancia entre duplicados
es el límite de repetibilidad $r$.

# Límite de repetibilidad $r$ ISO 5725

La guía ISO 5725 define el límite de repetibilidad $r$ de la siguiente manera:

$$
r = 2.8\cdot s_{r}
$$
y corresponde a la máxima diferencia, en valor absoluto, que puede
tolerarse entre duplicados de análisis, obtenidos bajo condiciones de
repetibilidad con un 95% de confianza. Veamos:

- $s_{r}$ es la desviación estándar de repetibilidad, la cual da cuenta de
la dispersión de las diferencias entre duplicados. Ya explicaremos cómo 
calcular este parámetro.

- El factor **2.8**: aquí les exijo una prueba de fe mis hermanos, me tienen que 
creer porque si quieren la demostración, aumentaría mucho la viscosidad 
de este post . A _grosso modo_, el factor
2.8 tiene que ver con el 95% de confianza, nos indica que cuando se establece 
la máxima diferencia 
tolerable, está permitido que el 5% de los duplicados estén fuera del 
límite $r$, y aún el 
sistema analítico se encontraría bajo _Control Estadístico_.


# ¿Cómo obtenemos la precisión de repetibilidad $s_{r}$?

Existen varios métodos estadísticos para abordar la estimación de la 
desviación estándar de repetibililidad $s_{r}$, sin embargo, en este post
nos enfocaremos en los dos más utilizados en química analítica:

1. Estimación basada en el registro histórico de duplicados de análisis.

2. La estimación mediante estudios de precisión siguiendo las directrices de la
guía ISO 5725.

No describiremos todos los detalles de cada uno de los diseños experimentales
expuestos en estas guías, más bien, ejemplificaremos el cálculo de la desviación
estándar de repetibilidad $s_{r}$:

# Método de estimación en base a datos históricos de duplicados

Obviamente necesitamos crear una base de datos con los registros de análisis
de muestras en duplicados en condiciones de repetibilidad. Estas muestras 
pueden corresponder a muestras de clientes, materiales de referencia primarios
o secundarios, muestras control, etc. Lo importante es que ambos duplicados 
cumplan con las condiciones de repetibilidad. La tabla \@ref(tab:bdsr) es un
ejemplo de una base de datos a utilizar en este método:

```{r bdsr, echo = F, message=F, warning=F}
library(knitr)
library(kableExtra)
library(tidyverse)
library(readxl)
# library(xlsx)

options(knitr.table.format = 'html',
        knitr.kable.NA = '') 



dup <- read_excel('base_datos_duplicados.xlsx', sheet = 'duplicados')
d <- dup$dup1 - dup$dup2
sr <- sqrt(sum(d^2)/(2*dim(dup)[1]))


kable(head(dup),
      digits = 2,
      align = 'c',
      caption = 'Base de datos histórica de duplicados (sólo los primeros  6 datos)',
      col.names = c('ID', 'Duplicado 1', 'Duplicado 2')) %>% 
    kable_styling(full_width = T)      

# write.xlsx(dup, file = 'base_datos_duplicados.xlsx', row.names = F)

```

Puede descargar esta base de datos desde este [link](https://1drv.ms/x/s!AuF6FPVWruwDyb4zAv7amIDqVpCvYA?e=5oqkgc). 
Y ahora la pregunta del millón:
¿Cuántas muestras en duplicado necesito? Si bien es posible obtener un cálculo
"exacto" del número de muestras $n$, esto está fuera del alcance de este post. 
Sin embargo, podemos decir que $n > 25$ es un número inicial adecuado. 

Una vez construida la base de datos, se puede obtener una estimación de $s_{r}$ 
mediante la ecuación \@ref(eq:srdup):

\begin{equation}
  s_{r} = \sqrt{\frac{\sum_{i = 1}^{n} (x_{i1} - x_{i2})^2}{2n}}
  (\#eq:srdup)
\end{equation}


Esta ecuación puede ser fácilmente implementada en Excel pero en este post,
como no, haremos los cálculos en lenguaje R. Pero antes, observe la figura
\@ref(fig:dup) la cual muestra un gráfico de dispersión entre Duplicado 1 ($X$)
y Duplicado 2 ($Y$). En este caso el orden es irrelevante. Si ajustáramos un
modelo lineal entre ambas variables ¿Qué valores de pendiente e intercepto
deberíamos obtener?

```{r dup, echo = F, fig.cap = 'Gráfico de dispersión entre duplicados'}

library(ggplot2)

ggplot(dup, aes(x = dup1, y = dup2)) +
  geom_point(pch = 16, alpha = 0.3, col = 'blue', size = 2) +
  theme_bw() +
  xlab('Duplicado 1') +
  ylab('Duplicado 2') +
  geom_abline(slope = 1, intercept = 0, col = 'red')
  

```



> ¡Correcto! Pendiente $\beta_{1} = 1$ e intercepto $\beta_{0} = 0$. La línea
roja representa esta recta teórica.
> Note también que la dispersión de los datos es constante en todo el rango
> de concentración, propiedad denominada **Homocedasticidad**.

Esta propiedad es deseable, sin embargo, no todos los sistemas analíticos la 
poseen. En sí misma no es una problema, sin embargo, si la varibilidad de los
duplicados aumenta con la concentración (_heterocedasticidad_)
tendremos que modelar esta variabilidad
en función de la concentración en forma explícita o segmentar el rango, lo cual
veremos en otro post.

También advierta la presencia de datos alejados de la diagonal, es decir, 
diferencias entre duplicados grandes. ¿Qué hacemos
con ellos?¿Los mantenemos o los eliminamos? 

Si los eliminamos, y realmente 
reflejaran la variabilidad del método, entonces subestimaríamos la 
máxima diferencia tolerable entre duplicados, aumentando la frecuencia de 
alertas de duplicados no conformes (nos ponemos la soga al cuello solitos). 
Si los mantenemos, y realmente fueron _errores_ puntuales de medición, 
sobreestimaríamos la tolerancia y la carta control sería de poca utilidad 
(mágicamente todos los datos caerían siempre dentro del los límites).
Este tema lo abordaremos en otro post (llevo una lista).

Como dato "anecdótico" en las operaciones de _trading_  en el mercado mundial
de concentrado de cobre, la máxima diferencia tolerable entre resultados de
distintos laboratorios (a.k.a exportador v/s importador) es 0,20 % Cu. Si la
diferencia supera este límite, ambos negociadores se van a un arbitraje 
(multiplique 0,2 % Cu por la millones de toneladas que se transan en el mercado...a 
$X$ US/libra no es un asunto trivial).


Utilizando los datos históricos estimamos una desviación 
estándar de repetibilidad de $s_{r} = `r round(sr, 2)`$ % Cu. Por lo tanto,
el límite de repetibilidad es obtenido de la ecuación \@ref(eq:limr):

\begin{eqnarray}
  r &=& 2.8\cdot s_{r} \\
  r &=& 2.8\cdot `r round(sr, 2)` \\
  r &=& `r round(2.8*sr, 2)`\, \text{% Cu}
  (\#eq:limr)
\end{eqnarray}

> **Interpretación**: La máxima diferencia tolerable, en valor absoluto,
> entre duplicados de análisis en condiciones de repetibilidad es
> $r = `r round(2.8*sr, 2)`$ % Cu.

Entonces, dados los datos iniciales:

- Duplicado 1 = 25.56 % Cu
- Duplicado 2 = 25.66 % Cu
- Diferencia = 0.10 % Cu

La diferencia encontrada entre duplicados 
$\Delta = 0.1 < `r round(2.8*sr, 2)`$ % Cu, por lo tanto, se acepta 
la diferencia entre duplicados, es un dato de QAQC conforme.

¿Y qué hacemos si no tenemos datos históricos de duplicados? Por favor, 
continue leyendo.

# Estimación mediante estudios de precisión siguiendo las directrices de la guía ISO 5725

Cuando no existen datos históricos, la guía ISO 5725 sugiere llevar a cabo
un diseño experimental en el cual se estudien diversos factores que podrían,
eventualmente, tener un efecto importante en la precisión del método analítico. 
Por ejemplo:

- Analistas distintos
- Equipos de medición (cromatógrafos, AAS, etc.)
- Días distintos
- Etc.

El "problema" de esta aproximación es que a medida que crece el número de
factores, el tamaño del diseño experimental (a.k.a número de experientos) crece
en forma rápida incluso, en algunos diseños, en forma exponencial.

La ventaja de este método es que permite estimar en un único estudio la precisión
de repetibilidad, reproducibilidad y la precisión intermedia, es decir, 
entre-analistas, entre-equipos, etc. La otra ventaja es que permite estimar los
denominados componentes de varianza "¿Y?" -- se preguntará.
Bueno, los componentes de varianza nos indican cuál es el factor que más aporta
a la variabilidad del sistema analítico ¿será la variabilidad entre-analistas?
¿o los distintos equipos que dispone el laboratorio? De esta forma Ud. podrá
focalizar los esfuerzos y recursos en mejorar la precisión del método sólo 
en aquellos factores que más aporten a la variabilidad total.

Veamos en qué consiste este método de estimación de precisión en base al 
estudio del factor **Analista**. Existen varios diseños experimentales para 
evaluar este factor, sin embargo, en este post comenzaremos con algo 
_light_:

> Estimaremos la precisión de reptibilidad y reproducibilidad del método 
volumétrico para la determinación de Cu en concentrado de cobre, 
en un laboratorio donde $n = 4$ analistas son igualmente 
competentes para llevar a cabo el análisis, siguiendo el mismo
instructivo.

Para abordar este objetivo, proponemos el siguiente diseño experimental:

![Diseño Experimental](doe.png){width=700px}

1. Una única muestra será analizada por los $n = 4$ analistas.
2. Cada analista realizará el análisis en quintuplicado $j = 5$
3. Los $k = n\cdot j = 20$ análisis deben ser obtenidos en 
condiciones de repetibilidad

Si bien podríamos publicar una enciclopedia de posts sobre diseño experimental
en química, surgen algunas preguntas sobre este diseño en particular:

- ¿Por qué una única muestra? Porque si cada analista recibiera una muestra
distinta, entonces la precisión del factor analista estaría "contaminada" 
con la variabilidad entre muestras, la cual no nos interesa en este 
estudio.

- ¿Y si una única muestra no es suficiente para llevar a cabo los 20 
análisis? Existen otros diseños experimentales denominados _anidados_ que 
permiten estimar la precisión utilizando muestras distintas.

- ¿Por qué los análisis de cada analista deben ser obtenidos en condiciones 
de repetibilidad? Porque no queremos que otro factor no controlado (por ejemplo, 
equipos distintos) influya en la estimación de la precisión entre-analistas.

- En lo posible, aumente el número de analistas en vez de hacer muchos 
replicados. Es mejor 5 analistas en triplicado, que 3 en quintuplicado.

- "La" muestra podría corresponder a una muestra del cliente. No es necesario
que sea un material de referencia, sin embargo, esta
muestra debe ser lo suficientemente homogénea... ¡Ah, eso es trampa!
¿Cómo demostramos que la muestra es homogénea? Le doy un dato, anote:

> Si su muestra es material particulado, le tengo malas noticias: No existen
las muestras homogéneas de este tipo de material (gracias a san Pierre Gy 
por el dato).

Como mencionamos anteriormente podríamos postear _ad infinitum_ sobre diseño
de exprimentos en química, sin embargo, la banda ancha es finita así que 
vamos al grano. La tabla \@ref(tab:doe) muestra los datos experimentales 
del estudio de precisión propuesto:

```{r doe, echo = F}

set.seed(1994)
analista <- rep(paste('Analista', 1:4), each = 5)
concentracion <- c(rnorm(15, 25, 0.20), rnorm(5, 24.9, 0.20))
Replicado <- rep(1:5, 4)
precision <- data.frame(analista, Replicado, concentracion)

kable(precision %>% 
        spread(., analista, concentracion),
      digits = 2,
      caption = 'Resultados de estudio de precisión [% Cu]',
      align = 'c')


```

Antes de llevar a cabo el análisis estadístico formal, observemos la figura
\@ref(fig:doeplot) la cual muestra el valor promedio de cada analista 
$\pm$ 1 desviación estándar. Ella nos indica que, aparentemente, los resultados 
entre los analistas son bastante consistentes.

```{r doeplot, fig.cap = 'Boxplot estudio de precisión', echo = F}

summary.precision <- precision %>% 
  group_by(analista) %>% 
  summarise(n = n(),
          m = mean(concentracion),
          s = sd(concentracion),
          se = s/sqrt(n),
          ic = qt(0.975, n - 1)*se)

ggplot(summary.precision, aes(x = analista, y = m)) +
  geom_point(pch = 19, col = 'red') +
  geom_errorbar(aes(ymin = m - s, ymax = m + s), width = 0.1) +
  theme_bw() +
  ylab('% Cu')

```


> Ahora bien ¿Cómo, entonces, estimamos la precisión de repetibilidad y 
> reproducibilidad a partir de la tabla \@ref(tab:doe)? Fácil, con el 
todopoderoso Análisis de Varianza (ANOVA).

No detallaremos la matemática detrás de esta poderosa técnica, sin embargo, 
diremos simplemente que el ANOVA es un método cuyo propósito es particionar
la variabilidad total de un conjunto de datos en componentes que intentan
explicarla. Aplicada a nuestro caso, utilizaremos ANOVA para particionar 
la variabilidad total de los 20 resultados de % Cu entre dos componentes:

- El factor analista
- La repetiblidad del método analítico.

para lo cual seguiremos paso a paso las instrucciones de la guía ISO 5725.
En primer lugar obtendremos la tabla ANOVA mediante lenguaje `R`:

```{r aov, echo = F, warning=F}

library(broom)
aov.precision <- aov(concentracion ~ analista, data = precision)
s2r.doe <- tidy(aov.precision)[2, 4]
MS.ana <- tidy(aov.precision)[1, 4]
s2ana <- (MS.ana- s2r.doe)/5
sR <- sqrt(s2r.doe + s2ana)


kable(tidy(aov.precision),
      digits = c(0, 0, 2, 2, 2, 2),
      col.names = c('Origen Variación', 
                    'g.l', 'SQ', 'MS', 'F calculado', 'p-value'),
      align = 'lcccccc',
      caption = 'Tabla ANOVA precisión')

```

Las tablas ANOVA muy similares en casi todos los softwares estadísticos 
profesionales... y en Excel también. Entonces:

- Repetibilidad $s_{r}$: Es simplemente la raíz cuadrada del término
$MS$ de los **Residuos**. En la nomenclatura de ANOVA es lo que se conoce como
variabilidad dentro (_within_). Para los datos de la tabla \@ref(tab:doe) se obtiene 
$s_{r} = \sqrt{\text{MS}_{Residuals}} = \sqrt{`r round(s2r.doe, 2)`} = `r round(sqrt(s2r.doe), 2)`$
% Cu.

- Precisión intermedia o variabilidad entre-analistas $s_{analista}$: 
¡No tan rápido! 
No es la raíz cuadrada de $MS$ del factor analista. Debemos hacer el 
siguiente cálculo adicional:

\begin{eqnarray}
  s_{analista} &=& \sqrt{\frac{MS_{analista} - MS_{Residuals}}{j}} \\
  s_{analista} &=& \sqrt{\frac{`r round(MS.ana, 2)` - `r round(s2r.doe, 2)`}{5}} \\
  s_{analista} &=& `r round(sqrt(s2ana), 2)`\, \text{% Cu} 
\end{eqnarray}

donde $j = 5$ es el número de replicados que hizo cada analista

- Reproducibilidad $s_{R}$: Es simplemente la combinación en cuadratura de 
las precisiones arriba calculadas.

\begin{eqnarray}
  s_{R} &=& \sqrt{s_{r}^{2} + s_{analista}^2}\\
  s_{R} &=& `r round(sR, 2)`\, \text{% Cu}
\end{eqnarray}


Por lo tanto, con estos datos podemos calcular el límite de repetibilidad
sin necesidad de tener una base de datos histórica de duplicados. En este
caso $r = 2.8 s_{r} = `r round(2.8*sR, 2)`$ % Cu.

> ¿Y si quisiera establecer la máxima diferencia tolerable entre analistas?

Nos vemos en el siguiente post.


# _Bonus track_ : Breve historia del factor 2.8

Sea $x_{1}$ y $x_{2}$ los duplicados de análisis  1 y 2, respectivamente. 
Cada uno de ellos "sigue" una distribución Normal con media $\mu$ y 
varianza $V = \sigma_{r}^2$ y, además, entre ellos son _independientes_,
entonces se cumple lo siguiente:

1. la diferencia entre duplicados $\Delta = x_{1} - x_{2}$ sigue una distribución Normal con media 0 y 
varianza $V_{\Delta} = V(x_{1} - x_{2}) = V(x_{1}) + V(x_{2}) = 
2\sigma_{r}^2$.

2. Si la varianza de las diferencias es $V_{\Delta} = 2\sigma_{r}^2$, entonces la 
desviación estándar es $\sqrt{2} \sigma_{r}$. 

3. Por lo tanto, si quisiéramos construir un intervalo de 
confianza al 95% para la diferencia entre duplicados obtendríamos
$\Delta \pm 2\sqrt{2} \sigma_{r}$. El 2 es por que para una distribución Normal se
sabe que entre la media $\pm$ 2 la desviación estándar se encuentran aproximadamente
el 95% de las observaciones.

4. $s_{r}$ es la estimación de $\sigma_{r}$, la cual es fija pero desconocida.

5. Como $\sqrt{2}\approx 1,41$ entonces, con un 95% de confianza, la
diferencia se encuentra
entre $\Delta \pm 2\cdot 1,41 \cdot s_{r} = 2.8\cdot s_{r}$. Ahora imágineme como 
el mago Tamariz al final de sus actos tocando el violín ¡chiararaaá! (Si eres
_old school_ sabrás quien es el mago Tamariz. Si eres _millenial_ mira este [video](https://www.youtube.com/watch?v=zcSqG2v-MZQ)).


# Bibliografía

1. ISO 5725 -- 3:1994 Accuracy (trueness and precision) of measurement methods and results -- Part 3: Intermediate measures of the precision of a standard measurement method

2. Michael Thompson, Bertil Magnusson Methodology in internal quality control of 
chemical analysis  _Accreditation and Quality Assurance August 2013, Volume 18, 
Issue 4, pp 271–278_
